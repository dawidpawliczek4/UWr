{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ulhVYI86xhZ"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "**Submission deadlines:**\n",
        "\n",
        "  - Tuesday groups: 22.04.2025\n",
        "  - Friday groups: 18.04.2025\n",
        "\n",
        "**Points:** Aim to get 10 points + 4 extra\n",
        "\n",
        "## Submission instructions\n",
        "The class is held on-site in lab rooms. Please prepare you notebook on your computer or anywhere in the cloud (try using DeepNote or Google Colab).\n",
        "\n",
        "Make sure you know all the questions and answers, and that the notebook contains results; before presentation do `Runtime -> Restart and run all`\n",
        "\n",
        "![Alt text](data:image/png;base64,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)\n",
        "\n",
        "We provide starter code, however you are not required to use it as long as you properly solve the tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pq455pMGbe2"
      },
      "source": [
        "\n",
        "# Classify the Oxford Flowers dataset (Weight & Biases) [6p]\n",
        "\n",
        "In this task, you will train a convolutional neural network to classify images of flowers from the [Oxford Flowers 102 dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/). The dataset consists of 102 flower categories, and each class has between 40 and 258 images. The images have large scale, pose, and light variations. In addition, there are categories that have large variations within the category and several very similar categories.\n",
        "\n",
        "    \n",
        "The dataset is available in `torchvision.datasets.Flowers102` class; see [Flowers102.html](https://pytorch.org/vision/main/generated/torchvision.datasets.Flowers102.html). You can use the following code to load the dataset:\n",
        "\n",
        "```python\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "dataset = torchvision.datasets.Flowers102(root='./data', download=True, transform=transforms.ToTensor())\n",
        "```\n",
        "\n",
        "**Hint**: The default split of the dataset is 1020, 1020 and 6149 images for training, validation and test sets respectively.\n",
        "If you can handle the bigger training dataset, you can experiment by taking up to 80% of the test set for training.\n",
        "\n",
        "\n",
        "In this task you should run several experiments to classify the images.\n",
        "In order to track the experiments, you can use the `Weight & Biases` library; see the [documentation](https://docs.wandb.ai/quickstart) for more details.\n",
        "\n",
        "Implement your code as a single Python script or a Jupyter notebook. Remember to log the experiment configuration, hyperparameters, and results (e.g., training loss, validation loss, accuracy and test loss, accuracy).\n",
        "For logging, you can use the `wandb.log` function to log the metrics and hyperparameters. You can also log the model architecture, training curves, and other relevant information.\n",
        "\n",
        "* 1. **[1p]**:\n",
        "    * Your task is to implement a convolutional neural network from scratch using PyTorch.\n",
        "    * Your CNN should consist of convolutional layers (Conv2D), pooling layers (MaxPooling2D), activation layers (e.g., ReLU), and fully connected layers (if needed).\n",
        "    \n",
        "* 2. **[2p]**:\n",
        "    * Train your CNN on different training set sized (10%, 20%, 50%, 80%, 100%) and evaluate the performance on the validation set and test set.\n",
        "        * Report the accuracy and loss on the validation set and test set for each training set size.\n",
        "    * Train your CNN on the full training set plus 20%, 50% and 80% of the test set and evaluate the performance on the validation set and the remaining test set.\n",
        "        * Report the accuracy and loss on the validation set and remaining test set for each training set size.\n",
        "    * Compare the performance of your CNN on the different training set sizes and analyze the results.\n",
        "\n",
        "* 3. **[1p]**:\n",
        "    * Implement a baseline AlexNet model using PyTorch.\n",
        "    * Training AlexNet may take a long time, so try to use GPU acceleration if available.\n",
        "\n",
        "* 4. **[1p]**:\n",
        "    * Input normalization: experiment with different input normalization techniques (e.g., mean subtraction, standardization) and analyze their impact on the model's performance.\n",
        "\n",
        "* 5. **[2p]**:\n",
        "    * Experiment with different hyperparameters such as learning rate, batch size, number of epochs, and optimizer choice (e.g., SGD, Adam).\n",
        "\n",
        "* 6. **[2p]**:\n",
        "    * Modify your CNN architecture to include batch normalization and dropout layers.\n",
        "    * Experiment with different dropout rates and analyze their impact on the model's performance.\n",
        "\n",
        "* 7. **[1p]**:\n",
        "    * Implement data augmentation techniques such as random rotations, shifts, flips, and zooms on the training dataset.\n",
        "    * Train your CNN with augmented data and compare the performance with the baseline model trained on the original data.\n",
        "\n",
        "* 8. ***[2p extra points]***:\n",
        "    * Implement residual connections in your CNN architecture; see the [ResNet paper](https://arxiv.org/abs/1512.03385) for more details.\n",
        "    * Implement inception modules in your CNN architecture; see the [GoogLeNet paper](https://arxiv.org/abs/1409.4842) for more details.\n",
        "                \n",
        "\n",
        "Analyze the results obtained from different experiments.\n",
        "Discuss the effects of varying training set size, hyperparameters, batch normalization, dropout, and data augmentation on the CNN's performance.\n",
        "Provide insights into how these factors influence model training, convergence, and generalization.\n",
        "\n",
        "Use the `Weight & Biases` reports to present your findings in a comprehensive report or presentation; see the [documentation](https://docs.wandb.ai/quickstart) for more details.\n",
        "\n",
        "**[2p extra]**: present your findings (for each task) in a report format in Weight & Biases.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS4jVCxkNB7D",
        "outputId": "5f61c970-549c-41cc-f7c0-f2975bed2707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "_xkrW4MFNGLL",
        "outputId": "9da1893a-813a-4bd1-a71c-320662f0e043"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdawidpawliczek4\u001b[0m (\u001b[33mdawidpawliczek4-university-of-wroc-aw\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "PROJECT_NAME = \"assignment3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VjT76VW4vh4",
        "outputId": "7ac60024-373a-4442-dd17-7412b54b5eab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e26241a62f0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0Dobtb57fG0"
      },
      "outputs": [],
      "source": [
        "# Define a transform to resize and crop the images to a uniform size\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),  # Resize the shorter side to 256\n",
        "    transforms.CenterCrop(224),  # Crop the center to 224x224\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_dataset = torchvision.datasets.Flowers102(root='./data', split=\"test\", download=True, transform=transform)\n",
        "val_dataset = torchvision.datasets.Flowers102(root='./data', split=\"val\", download=True, transform=transform)\n",
        "train_dataset = torchvision.datasets.Flowers102(root='./data', split=\"train\", download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTYFmMfb7jzo"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "flowers102_loaders = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader,\n",
        "    'test': test_loader\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUHsObwM8yMb"
      },
      "outputs": [],
      "source": [
        "class SimpleConvAndMlp(torch.nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # same as padding='same'\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # add dropout to reduce overfitting\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, Out, Targets):\n",
        "        return F.cross_entropy(Out, Targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjELpOia9gL8"
      },
      "outputs": [],
      "source": [
        "def compute_err_rate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    errors = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            out = model(x)\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            errors += (predicted != y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return errors / total\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, data_loaders, optimizer, num_epochs, device):\n",
        "    model.to(device)\n",
        "    iter_ = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x,y in data_loaders['train']:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = model.loss(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predictions = out.max(dim=1)\n",
        "            batch_err_rate = (predictions != y).sum().item() / out.size(0)\n",
        "\n",
        "            if iter_ % 10 == 0:\n",
        "                print(\n",
        "                    \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%\".format(\n",
        "                        iter_,\n",
        "                        loss.item(),\n",
        "                        batch_err_rate * 100.0,\n",
        "                    )\n",
        "                )\n",
        "            iter_ += 1\n",
        "\n",
        "\n",
        "        val_err_rate = compute_err_rate(model, data_loaders['val'], device)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Error Rate: {val_err_rate*100:.2f}%\")\n",
        "        wandb.log({ \"epoch\": epoch+1, \"val/err\": val_err_rate*100, })\n",
        "\n",
        "    test_err_rate = compute_err_rate(model, data_loaders['test'], device)\n",
        "    print(f\"Test Error Rate: {test_err_rate*100:.2f}%\")\n",
        "    wandb.log({ \"test/err\": test_err_rate})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tymNTjm-_OhP",
        "outputId": "1a317b0c-665b-48ae-8cf5-07baf7afe656"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simplecnn-mix-first-version</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/v2vhg7p2' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/v2vhg7p2</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_103201-v2vhg7p2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_103210-3tx1zjg1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/3tx1zjg1' target=\"_blank\">run-simplecnn-mix-first-version</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/3tx1zjg1' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/3tx1zjg1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch      0  | loss  5.71 | err rate 96.88%\n",
            "Minibatch     10  | loss  4.94 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.57 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.57 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 96.67%\n",
            "Minibatch     40  | loss  4.19 | err rate 100.00%\n",
            "Minibatch     50  | loss  4.13 | err rate 96.88%\n",
            "Minibatch     60  | loss  4.00 | err rate 93.75%\n",
            "Epoch 2/10, Validation Error Rate: 91.18%\n",
            "Minibatch     70  | loss  3.52 | err rate 71.88%\n",
            "Minibatch     80  | loss  4.01 | err rate 90.62%\n",
            "Minibatch     90  | loss  3.54 | err rate 78.12%\n",
            "Epoch 3/10, Validation Error Rate: 86.27%\n",
            "Minibatch    100  | loss  3.11 | err rate 75.00%\n",
            "Minibatch    110  | loss  2.89 | err rate 71.88%\n",
            "Minibatch    120  | loss  3.17 | err rate 81.25%\n",
            "Epoch 4/10, Validation Error Rate: 82.16%\n",
            "Minibatch    130  | loss  2.89 | err rate 75.00%\n",
            "Minibatch    140  | loss  2.57 | err rate 68.75%\n",
            "Minibatch    150  | loss  2.36 | err rate 59.38%\n",
            "Epoch 5/10, Validation Error Rate: 79.51%\n",
            "Minibatch    160  | loss  2.16 | err rate 56.25%\n",
            "Minibatch    170  | loss  2.30 | err rate 65.62%\n",
            "Minibatch    180  | loss  2.29 | err rate 50.00%\n",
            "Minibatch    190  | loss  2.19 | err rate 56.25%\n",
            "Epoch 6/10, Validation Error Rate: 79.12%\n",
            "Minibatch    200  | loss  1.97 | err rate 53.12%\n",
            "Minibatch    210  | loss  1.54 | err rate 46.88%\n",
            "Minibatch    220  | loss  2.10 | err rate 46.88%\n",
            "Epoch 7/10, Validation Error Rate: 77.35%\n",
            "Minibatch    230  | loss  1.02 | err rate 25.00%\n",
            "Minibatch    240  | loss  1.67 | err rate 37.50%\n",
            "Minibatch    250  | loss  1.44 | err rate 34.38%\n",
            "Epoch 8/10, Validation Error Rate: 77.45%\n",
            "Minibatch    260  | loss  1.24 | err rate 37.50%\n",
            "Minibatch    270  | loss  1.18 | err rate 31.25%\n",
            "Minibatch    280  | loss  1.43 | err rate 53.12%\n",
            "Epoch 9/10, Validation Error Rate: 74.71%\n",
            "Minibatch    290  | loss  0.62 | err rate 18.75%\n",
            "Minibatch    300  | loss  1.08 | err rate 28.12%\n",
            "Minibatch    310  | loss  1.41 | err rate 34.38%\n",
            "Epoch 10/10, Validation Error Rate: 77.16%\n",
            "Test Error Rate: 78.18%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▆▅▃▃▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.78175</td></tr><tr><td>val/err</td><td>77.15686</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simplecnn-mix-first-version</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/3tx1zjg1' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/3tx1zjg1</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_103210-3tx1zjg1/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"run-simplecnn-mix-first-version\",\n",
        "    config={\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "model = SimpleConvAndMlp()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for name, p in model.named_parameters():\n",
        "        if \"weight\" in name and len(p.shape) >= 2:\n",
        "            torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "        elif \"bias\" in name:\n",
        "            p.zero_()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "train_model(model, flowers102_loaders, optimizer, 10, 'cuda')\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RlAo4c2afd2"
      },
      "source": [
        "## zad 2 - different sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emhsXCrRaXfc"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),  # Resize the shorter side to 256\n",
        "    transforms.CenterCrop(224),  # Crop the center to 224x224\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = torchvision.datasets.Flowers102(root='./data', download=True, transform=transform)\n",
        "total = len(dataset)\n",
        "train_size = int(0.8 * total)\n",
        "val_size = int(0.1 * total)\n",
        "test_size = total - train_size - val_size\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-pAj4gv0apZz",
        "outputId": "224395eb-2a75-47da-84c0-051965da68c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>val/err</td><td>▃▆██▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>val/err</td><td>96.07843</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-training-fraction-0.2</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/7c6ce8cn' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/7c6ce8cn</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_103849-7c6ce8cn/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_103907-tj48a1vr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/tj48a1vr' target=\"_blank\">simplecnn-training-fraction-0.1</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/tj48a1vr' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/tj48a1vr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch      0  | loss  5.97 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 98.04%\n",
            "Epoch 2/10, Validation Error Rate: 100.00%\n",
            "Epoch 3/10, Validation Error Rate: 99.02%\n",
            "Minibatch     10  | loss  3.54 | err rate 87.50%\n",
            "Epoch 4/10, Validation Error Rate: 98.04%\n",
            "Epoch 5/10, Validation Error Rate: 98.04%\n",
            "Epoch 6/10, Validation Error Rate: 98.04%\n",
            "Minibatch     20  | loss  1.59 | err rate 35.29%\n",
            "Epoch 7/10, Validation Error Rate: 95.10%\n",
            "Epoch 8/10, Validation Error Rate: 94.12%\n",
            "Epoch 9/10, Validation Error Rate: 97.06%\n",
            "Epoch 10/10, Validation Error Rate: 95.10%\n",
            "Test Error Rate: 90.20%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>▆█▇▆▆▆▂▁▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.90196</td></tr><tr><td>val/err</td><td>95.09804</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-training-fraction-0.1</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/tj48a1vr' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/tj48a1vr</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_103907-tj48a1vr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_103925-xsb1wjll</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xsb1wjll' target=\"_blank\">simplecnn-training-fraction-0.2</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xsb1wjll' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xsb1wjll</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch      0  | loss  5.89 | err rate 93.75%\n",
            "Epoch 1/10, Validation Error Rate: 99.02%\n",
            "Minibatch     10  | loss  4.43 | err rate 100.00%\n",
            "Epoch 2/10, Validation Error Rate: 99.02%\n",
            "Epoch 3/10, Validation Error Rate: 95.10%\n",
            "Minibatch     20  | loss  3.67 | err rate 87.50%\n",
            "Epoch 4/10, Validation Error Rate: 94.12%\n",
            "Epoch 5/10, Validation Error Rate: 95.10%\n",
            "Minibatch     30  | loss  2.86 | err rate 65.62%\n",
            "Epoch 6/10, Validation Error Rate: 90.20%\n",
            "Minibatch     40  | loss  2.77 | err rate 71.88%\n",
            "Epoch 7/10, Validation Error Rate: 89.22%\n",
            "Epoch 8/10, Validation Error Rate: 92.16%\n",
            "Minibatch     50  | loss  1.83 | err rate 59.38%\n",
            "Epoch 9/10, Validation Error Rate: 88.24%\n",
            "Epoch 10/10, Validation Error Rate: 86.27%\n",
            "Test Error Rate: 89.22%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>██▆▅▆▃▃▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.89216</td></tr><tr><td>val/err</td><td>86.27451</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-training-fraction-0.2</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xsb1wjll' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xsb1wjll</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_103925-xsb1wjll/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_103948-av3gk2j0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/av3gk2j0' target=\"_blank\">simplecnn-training-fraction-0.5</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/av3gk2j0' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/av3gk2j0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch      0  | loss  5.59 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.44 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 99.02%\n",
            "Minibatch     20  | loss  4.20 | err rate 93.75%\n",
            "Epoch 2/10, Validation Error Rate: 98.04%\n",
            "Minibatch     30  | loss  3.68 | err rate 81.25%\n",
            "Epoch 3/10, Validation Error Rate: 93.14%\n",
            "Minibatch     40  | loss  3.23 | err rate 71.88%\n",
            "Minibatch     50  | loss  3.11 | err rate 81.25%\n",
            "Epoch 4/10, Validation Error Rate: 93.14%\n",
            "Minibatch     60  | loss  2.29 | err rate 50.00%\n",
            "Epoch 5/10, Validation Error Rate: 90.20%\n",
            "Minibatch     70  | loss  1.87 | err rate 46.88%\n",
            "Epoch 6/10, Validation Error Rate: 94.12%\n",
            "Minibatch     80  | loss  1.41 | err rate 34.38%\n",
            "Minibatch     90  | loss  1.48 | err rate 37.50%\n",
            "Epoch 7/10, Validation Error Rate: 92.16%\n",
            "Minibatch    100  | loss  1.16 | err rate 34.38%\n",
            "Epoch 8/10, Validation Error Rate: 87.25%\n",
            "Minibatch    110  | loss  0.85 | err rate 25.00%\n",
            "Epoch 9/10, Validation Error Rate: 88.24%\n",
            "Minibatch    120  | loss  0.43 | err rate  9.38%\n",
            "Epoch 10/10, Validation Error Rate: 86.27%\n",
            "Test Error Rate: 85.29%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▇▅▅▃▅▄▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.85294</td></tr><tr><td>val/err</td><td>86.27451</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-training-fraction-0.5</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/av3gk2j0' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/av3gk2j0</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_103948-av3gk2j0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_104024-5ghjppwt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/5ghjppwt' target=\"_blank\">simplecnn-training-fraction-0.8</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/5ghjppwt' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/5ghjppwt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch      0  | loss  5.41 | err rate 93.75%\n",
            "Minibatch     10  | loss  5.49 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.82 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 97.06%\n",
            "Minibatch     30  | loss  4.31 | err rate 96.88%\n",
            "Minibatch     40  | loss  4.09 | err rate 90.62%\n",
            "Epoch 2/10, Validation Error Rate: 95.10%\n",
            "Minibatch     50  | loss  3.63 | err rate 90.62%\n",
            "Minibatch     60  | loss  3.53 | err rate 84.38%\n",
            "Epoch 3/10, Validation Error Rate: 89.22%\n",
            "Minibatch     70  | loss  3.45 | err rate 90.62%\n",
            "Minibatch     80  | loss  3.32 | err rate 78.12%\n",
            "Epoch 4/10, Validation Error Rate: 86.27%\n",
            "Minibatch     90  | loss  2.68 | err rate 78.12%\n",
            "Minibatch    100  | loss  3.14 | err rate 78.12%\n",
            "Epoch 5/10, Validation Error Rate: 83.33%\n",
            "Minibatch    110  | loss  2.60 | err rate 65.62%\n",
            "Minibatch    120  | loss  2.19 | err rate 46.88%\n",
            "Epoch 6/10, Validation Error Rate: 82.35%\n",
            "Minibatch    130  | loss  2.06 | err rate 65.62%\n",
            "Minibatch    140  | loss  1.75 | err rate 43.75%\n",
            "Epoch 7/10, Validation Error Rate: 81.37%\n",
            "Minibatch    150  | loss  1.26 | err rate 37.50%\n",
            "Minibatch    160  | loss  1.41 | err rate 46.88%\n",
            "Epoch 8/10, Validation Error Rate: 77.45%\n",
            "Minibatch    170  | loss  1.28 | err rate 34.38%\n",
            "Minibatch    180  | loss  1.08 | err rate 37.50%\n",
            "Epoch 9/10, Validation Error Rate: 75.49%\n",
            "Minibatch    190  | loss  0.95 | err rate 18.75%\n",
            "Minibatch    200  | loss  0.85 | err rate 25.00%\n",
            "Epoch 10/10, Validation Error Rate: 77.45%\n",
            "Test Error Rate: 85.29%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▇▅▅▄▃▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.85294</td></tr><tr><td>val/err</td><td>77.45098</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-training-fraction-0.8</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/5ghjppwt' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/5ghjppwt</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_104024-5ghjppwt/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_104113-bbo9sdaa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bbo9sdaa' target=\"_blank\">simplecnn-training-fraction-1.0</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bbo9sdaa' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bbo9sdaa</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch      0  | loss  5.77 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.14 | err rate 96.88%\n",
            "Minibatch     20  | loss  4.73 | err rate 93.75%\n",
            "Epoch 1/10, Validation Error Rate: 97.06%\n",
            "Minibatch     30  | loss  4.43 | err rate 90.62%\n",
            "Minibatch     40  | loss  3.82 | err rate 87.50%\n",
            "Minibatch     50  | loss  4.15 | err rate 93.75%\n",
            "Epoch 2/10, Validation Error Rate: 95.10%\n",
            "Minibatch     60  | loss  3.62 | err rate 87.50%\n",
            "Minibatch     70  | loss  3.85 | err rate 87.50%\n",
            "Epoch 3/10, Validation Error Rate: 90.20%\n",
            "Minibatch     80  | loss  2.97 | err rate 65.62%\n",
            "Minibatch     90  | loss  3.19 | err rate 93.75%\n",
            "Minibatch    100  | loss  2.98 | err rate 87.50%\n",
            "Epoch 4/10, Validation Error Rate: 92.16%\n",
            "Minibatch    110  | loss  2.89 | err rate 71.88%\n",
            "Minibatch    120  | loss  2.71 | err rate 71.88%\n",
            "Epoch 5/10, Validation Error Rate: 89.22%\n",
            "Minibatch    130  | loss  2.60 | err rate 65.62%\n",
            "Minibatch    140  | loss  2.03 | err rate 56.25%\n",
            "Minibatch    150  | loss  2.31 | err rate 65.62%\n",
            "Epoch 6/10, Validation Error Rate: 81.37%\n",
            "Minibatch    160  | loss  1.71 | err rate 46.88%\n",
            "Minibatch    170  | loss  2.39 | err rate 65.62%\n",
            "Minibatch    180  | loss  1.96 | err rate 65.62%\n",
            "Epoch 7/10, Validation Error Rate: 87.25%\n",
            "Minibatch    190  | loss  1.63 | err rate 43.75%\n",
            "Minibatch    200  | loss  1.89 | err rate 50.00%\n",
            "Epoch 8/10, Validation Error Rate: 81.37%\n",
            "Minibatch    210  | loss  1.41 | err rate 40.62%\n",
            "Minibatch    220  | loss  2.07 | err rate 53.12%\n",
            "Minibatch    230  | loss  1.95 | err rate 53.12%\n",
            "Epoch 9/10, Validation Error Rate: 83.33%\n",
            "Minibatch    240  | loss  1.05 | err rate 28.12%\n",
            "Minibatch    250  | loss  1.32 | err rate 46.88%\n",
            "Epoch 10/10, Validation Error Rate: 83.33%\n",
            "Test Error Rate: 81.37%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▇▅▆▄▁▄▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.81373</td></tr><tr><td>val/err</td><td>83.33333</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-training-fraction-1.0</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bbo9sdaa' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bbo9sdaa</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_104113-bbo9sdaa/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "fractions = [0.1, 0.2, 0.5, 0.8, 1.0]\n",
        "for frac in fractions:\n",
        "    wandb.init(\n",
        "      project=PROJECT_NAME,\n",
        "      name=f\"simplecnn-training-fraction-{frac}\",\n",
        "      config={\n",
        "          \"optimizer\": \"adam\",\n",
        "          \"lr\": 1e-3,\n",
        "          \"weight_decay\": 1e-4,\n",
        "          \"initializer\": \"kaiming_normal\",\n",
        "          \"epochs\": 10,\n",
        "          \"batch_size\": 32,\n",
        "          \"num_classes\": 10\n",
        "      }\n",
        "    )\n",
        "\n",
        "    k = int(frac * len(train_ds))\n",
        "    lengths = [k, len(train_ds) - k]\n",
        "    sub_train, _ = random_split(train_ds, lengths)\n",
        "\n",
        "    train_loader = DataLoader(sub_train, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,    batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    flowers102_loaders = {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader,\n",
        "        'test': test_loader\n",
        "    }\n",
        "\n",
        "    model = SimpleConvAndMlp()\n",
        "    with torch.no_grad():\n",
        "      for name, p in model.named_parameters():\n",
        "          if \"weight\" in name and len(p.shape) >= 2:\n",
        "              torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "          elif \"bias\" in name:\n",
        "              p.zero_()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    train_model(model, flowers102_loaders, optimizer, 10, 'cuda')\n",
        "    wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHp7q_dfiLtP"
      },
      "source": [
        "## zad 2.2 - adding data to training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOTJmeuki16C"
      },
      "outputs": [],
      "source": [
        "# Define a transform to resize and crop the images to a uniform size\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),  # Resize the shorter side to 256\n",
        "    transforms.CenterCrop(224),  # Crop the center to 224x224\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_dataset = torchvision.datasets.Flowers102(root='./data', split=\"test\", download=True, transform=transform)\n",
        "val_dataset = torchvision.datasets.Flowers102(root='./data', split=\"val\", download=True, transform=transform)\n",
        "train_dataset = torchvision.datasets.Flowers102(root='./data', split=\"train\", download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jHvr2uP_iO22",
        "outputId": "00705aea-79ac-4382-ce1b-1355ef65c91c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_104444-ejyd5u2i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ejyd5u2i' target=\"_blank\">simplecnn-add-data-to-train-0.2</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ejyd5u2i' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ejyd5u2i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fraction:  0.2\n",
            "Minibatch      0  | loss  6.51 | err rate 96.88%\n",
            "Minibatch     10  | loss  4.71 | err rate 96.88%\n",
            "Minibatch     20  | loss  4.72 | err rate 100.00%\n",
            "Minibatch     30  | loss  4.79 | err rate 96.88%\n",
            "Minibatch     40  | loss  4.27 | err rate 90.62%\n",
            "Minibatch     50  | loss  4.56 | err rate 100.00%\n",
            "Minibatch     60  | loss  4.55 | err rate 100.00%\n",
            "Minibatch     70  | loss  3.99 | err rate 88.89%\n",
            "Epoch 1/10, Validation Error Rate: 94.31%\n",
            "Minibatch     80  | loss  4.03 | err rate 90.62%\n",
            "Minibatch     90  | loss  4.37 | err rate 96.88%\n",
            "Minibatch    100  | loss  3.88 | err rate 90.62%\n",
            "Minibatch    110  | loss  3.57 | err rate 90.62%\n",
            "Minibatch    120  | loss  3.89 | err rate 93.75%\n",
            "Minibatch    130  | loss  3.73 | err rate 100.00%\n",
            "Minibatch    140  | loss  3.64 | err rate 90.62%\n",
            "Epoch 2/10, Validation Error Rate: 86.57%\n",
            "Minibatch    150  | loss  3.14 | err rate 84.38%\n",
            "Minibatch    160  | loss  2.94 | err rate 71.88%\n",
            "Minibatch    170  | loss  2.75 | err rate 78.12%\n",
            "Minibatch    180  | loss  2.78 | err rate 75.00%\n",
            "Minibatch    190  | loss  3.09 | err rate 62.50%\n",
            "Minibatch    200  | loss  3.00 | err rate 78.12%\n",
            "Minibatch    210  | loss  2.61 | err rate 71.88%\n",
            "Epoch 3/10, Validation Error Rate: 79.22%\n",
            "Minibatch    220  | loss  3.07 | err rate 81.25%\n",
            "Minibatch    230  | loss  2.82 | err rate 62.50%\n",
            "Minibatch    240  | loss  2.30 | err rate 65.62%\n",
            "Minibatch    250  | loss  2.72 | err rate 68.75%\n",
            "Minibatch    260  | loss  2.68 | err rate 62.50%\n",
            "Minibatch    270  | loss  2.30 | err rate 59.38%\n",
            "Minibatch    280  | loss  2.40 | err rate 65.62%\n",
            "Epoch 4/10, Validation Error Rate: 75.20%\n",
            "Minibatch    290  | loss  2.02 | err rate 56.25%\n",
            "Minibatch    300  | loss  2.66 | err rate 78.12%\n",
            "Minibatch    310  | loss  2.21 | err rate 62.50%\n",
            "Minibatch    320  | loss  2.24 | err rate 50.00%\n",
            "Minibatch    330  | loss  2.53 | err rate 68.75%\n",
            "Minibatch    340  | loss  3.01 | err rate 62.50%\n",
            "Minibatch    350  | loss  2.23 | err rate 56.25%\n",
            "Epoch 5/10, Validation Error Rate: 70.69%\n",
            "Minibatch    360  | loss  1.85 | err rate 53.12%\n",
            "Minibatch    370  | loss  2.06 | err rate 56.25%\n",
            "Minibatch    380  | loss  1.84 | err rate 46.88%\n",
            "Minibatch    390  | loss  2.06 | err rate 59.38%\n",
            "Minibatch    400  | loss  2.11 | err rate 53.12%\n",
            "Minibatch    410  | loss  2.21 | err rate 53.12%\n",
            "Minibatch    420  | loss  2.78 | err rate 71.88%\n",
            "Epoch 6/10, Validation Error Rate: 67.55%\n",
            "Minibatch    430  | loss  1.24 | err rate 34.38%\n",
            "Minibatch    440  | loss  1.77 | err rate 50.00%\n",
            "Minibatch    450  | loss  1.53 | err rate 40.62%\n",
            "Minibatch    460  | loss  1.74 | err rate 50.00%\n",
            "Minibatch    470  | loss  1.64 | err rate 43.75%\n",
            "Minibatch    480  | loss  1.71 | err rate 59.38%\n",
            "Minibatch    490  | loss  1.64 | err rate 43.75%\n",
            "Epoch 7/10, Validation Error Rate: 65.98%\n",
            "Minibatch    500  | loss  1.40 | err rate 43.75%\n",
            "Minibatch    510  | loss  1.66 | err rate 53.12%\n",
            "Minibatch    520  | loss  1.47 | err rate 34.38%\n",
            "Minibatch    530  | loss  1.59 | err rate 50.00%\n",
            "Minibatch    540  | loss  1.09 | err rate 21.88%\n",
            "Minibatch    550  | loss  1.76 | err rate 53.12%\n",
            "Minibatch    560  | loss  1.90 | err rate 50.00%\n",
            "Epoch 8/10, Validation Error Rate: 65.29%\n",
            "Minibatch    570  | loss  1.67 | err rate 50.00%\n",
            "Minibatch    580  | loss  1.54 | err rate 34.38%\n",
            "Minibatch    590  | loss  1.74 | err rate 43.75%\n",
            "Minibatch    600  | loss  1.60 | err rate 46.88%\n",
            "Minibatch    610  | loss  1.24 | err rate 37.50%\n",
            "Minibatch    620  | loss  1.54 | err rate 40.62%\n",
            "Minibatch    630  | loss  1.21 | err rate 28.12%\n",
            "Epoch 9/10, Validation Error Rate: 63.04%\n",
            "Minibatch    640  | loss  0.97 | err rate 28.12%\n",
            "Minibatch    650  | loss  1.33 | err rate 43.75%\n",
            "Minibatch    660  | loss  0.87 | err rate 28.12%\n",
            "Minibatch    670  | loss  0.85 | err rate 25.00%\n",
            "Minibatch    680  | loss  1.51 | err rate 46.88%\n",
            "Minibatch    690  | loss  1.22 | err rate 34.38%\n",
            "Minibatch    700  | loss  1.66 | err rate 34.38%\n",
            "Epoch 10/10, Validation Error Rate: 62.25%\n",
            "Test Error Rate: 62.26%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▆▅▄▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.62256</td></tr><tr><td>val/err</td><td>62.2549</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-add-data-to-train-0.2</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ejyd5u2i' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ejyd5u2i</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_104444-ejyd5u2i/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_104933-ufddqsik</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ufddqsik' target=\"_blank\">simplecnn-add-data-to-train-0.5</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ufddqsik' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ufddqsik</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fraction:  0.5\n",
            "Minibatch      0  | loss  6.11 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.17 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.63 | err rate 87.50%\n",
            "Minibatch     30  | loss  4.29 | err rate 96.88%\n",
            "Minibatch     40  | loss  4.34 | err rate 96.88%\n",
            "Minibatch     50  | loss  4.64 | err rate 100.00%\n",
            "Minibatch     60  | loss  4.23 | err rate 96.88%\n",
            "Minibatch     70  | loss  4.35 | err rate 90.62%\n",
            "Minibatch     80  | loss  4.17 | err rate 90.62%\n",
            "Minibatch     90  | loss  4.12 | err rate 93.75%\n",
            "Minibatch    100  | loss  4.18 | err rate 87.50%\n",
            "Minibatch    110  | loss  4.25 | err rate 93.75%\n",
            "Minibatch    120  | loss  3.80 | err rate 84.38%\n",
            "Minibatch    130  | loss  3.81 | err rate 87.50%\n",
            "Minibatch    140  | loss  4.36 | err rate 93.75%\n",
            "Minibatch    150  | loss  4.14 | err rate 96.88%\n",
            "Minibatch    160  | loss  3.95 | err rate 90.62%\n",
            "Epoch 1/10, Validation Error Rate: 90.88%\n",
            "Minibatch    170  | loss  3.58 | err rate 87.50%\n",
            "Minibatch    180  | loss  3.82 | err rate 96.88%\n",
            "Minibatch    190  | loss  3.73 | err rate 90.62%\n",
            "Minibatch    200  | loss  2.94 | err rate 62.50%\n",
            "Minibatch    210  | loss  2.84 | err rate 75.00%\n",
            "Minibatch    220  | loss  2.56 | err rate 65.62%\n",
            "Minibatch    230  | loss  3.14 | err rate 78.12%\n",
            "Minibatch    240  | loss  2.84 | err rate 81.25%\n",
            "Minibatch    250  | loss  2.81 | err rate 84.38%\n",
            "Minibatch    260  | loss  3.14 | err rate 75.00%\n",
            "Minibatch    270  | loss  3.04 | err rate 78.12%\n",
            "Minibatch    280  | loss  3.07 | err rate 68.75%\n",
            "Minibatch    290  | loss  2.74 | err rate 75.00%\n",
            "Minibatch    300  | loss  3.30 | err rate 78.12%\n",
            "Minibatch    310  | loss  2.38 | err rate 56.25%\n",
            "Minibatch    320  | loss  2.44 | err rate 59.38%\n",
            "Minibatch    330  | loss  2.91 | err rate 81.25%\n",
            "Epoch 2/10, Validation Error Rate: 75.39%\n",
            "Minibatch    340  | loss  2.79 | err rate 75.00%\n",
            "Minibatch    350  | loss  2.20 | err rate 53.12%\n",
            "Minibatch    360  | loss  2.37 | err rate 65.62%\n",
            "Minibatch    370  | loss  2.57 | err rate 62.50%\n",
            "Minibatch    380  | loss  2.59 | err rate 62.50%\n",
            "Minibatch    390  | loss  2.29 | err rate 65.62%\n",
            "Minibatch    400  | loss  2.30 | err rate 56.25%\n",
            "Minibatch    410  | loss  2.09 | err rate 53.12%\n",
            "Minibatch    420  | loss  2.20 | err rate 59.38%\n",
            "Minibatch    430  | loss  2.88 | err rate 68.75%\n",
            "Minibatch    440  | loss  2.21 | err rate 68.75%\n",
            "Minibatch    450  | loss  2.54 | err rate 68.75%\n",
            "Minibatch    460  | loss  2.32 | err rate 62.50%\n",
            "Minibatch    470  | loss  2.69 | err rate 68.75%\n",
            "Minibatch    480  | loss  2.74 | err rate 71.88%\n",
            "Minibatch    490  | loss  2.38 | err rate 65.62%\n",
            "Minibatch    500  | loss  3.14 | err rate 72.73%\n",
            "Epoch 3/10, Validation Error Rate: 67.35%\n",
            "Minibatch    510  | loss  2.12 | err rate 53.12%\n",
            "Minibatch    520  | loss  2.19 | err rate 53.12%\n",
            "Minibatch    530  | loss  2.37 | err rate 71.88%\n",
            "Minibatch    540  | loss  1.77 | err rate 50.00%\n",
            "Minibatch    550  | loss  1.92 | err rate 46.88%\n",
            "Minibatch    560  | loss  1.26 | err rate 40.62%\n",
            "Minibatch    570  | loss  2.18 | err rate 65.62%\n",
            "Minibatch    580  | loss  1.86 | err rate 50.00%\n",
            "Minibatch    590  | loss  1.65 | err rate 46.88%\n",
            "Minibatch    600  | loss  2.09 | err rate 53.12%\n",
            "Minibatch    610  | loss  1.52 | err rate 40.62%\n",
            "Minibatch    620  | loss  2.01 | err rate 56.25%\n",
            "Minibatch    630  | loss  1.97 | err rate 65.62%\n",
            "Minibatch    640  | loss  1.83 | err rate 43.75%\n",
            "Minibatch    650  | loss  1.97 | err rate 56.25%\n",
            "Minibatch    660  | loss  1.74 | err rate 40.62%\n",
            "Epoch 4/10, Validation Error Rate: 61.86%\n",
            "Minibatch    670  | loss  1.46 | err rate 37.50%\n",
            "Minibatch    680  | loss  1.58 | err rate 40.62%\n",
            "Minibatch    690  | loss  2.14 | err rate 59.38%\n",
            "Minibatch    700  | loss  2.02 | err rate 53.12%\n",
            "Minibatch    710  | loss  1.95 | err rate 62.50%\n",
            "Minibatch    720  | loss  1.65 | err rate 46.88%\n",
            "Minibatch    730  | loss  2.06 | err rate 56.25%\n",
            "Minibatch    740  | loss  1.77 | err rate 53.12%\n",
            "Minibatch    750  | loss  1.08 | err rate 34.38%\n",
            "Minibatch    760  | loss  1.84 | err rate 43.75%\n",
            "Minibatch    770  | loss  1.88 | err rate 50.00%\n",
            "Minibatch    780  | loss  1.19 | err rate 37.50%\n",
            "Minibatch    790  | loss  1.24 | err rate 31.25%\n",
            "Minibatch    800  | loss  1.16 | err rate 34.38%\n",
            "Minibatch    810  | loss  1.48 | err rate 31.25%\n",
            "Minibatch    820  | loss  1.30 | err rate 43.75%\n",
            "Minibatch    830  | loss  1.90 | err rate 53.12%\n",
            "Epoch 5/10, Validation Error Rate: 61.08%\n",
            "Minibatch    840  | loss  1.84 | err rate 37.50%\n",
            "Minibatch    850  | loss  1.13 | err rate 40.62%\n",
            "Minibatch    860  | loss  1.58 | err rate 43.75%\n",
            "Minibatch    870  | loss  1.34 | err rate 31.25%\n",
            "Minibatch    880  | loss  0.92 | err rate 28.12%\n",
            "Minibatch    890  | loss  1.99 | err rate 50.00%\n",
            "Minibatch    900  | loss  1.45 | err rate 40.62%\n",
            "Minibatch    910  | loss  2.00 | err rate 46.88%\n",
            "Minibatch    920  | loss  1.58 | err rate 40.62%\n",
            "Minibatch    930  | loss  2.12 | err rate 59.38%\n",
            "Minibatch    940  | loss  1.54 | err rate 43.75%\n",
            "Minibatch    950  | loss  1.09 | err rate 37.50%\n",
            "Minibatch    960  | loss  1.28 | err rate 31.25%\n",
            "Minibatch    970  | loss  1.75 | err rate 37.50%\n",
            "Minibatch    980  | loss  1.45 | err rate 43.75%\n",
            "Minibatch    990  | loss  1.27 | err rate 43.75%\n",
            "Minibatch   1000  | loss  1.64 | err rate 46.88%\n",
            "Epoch 6/10, Validation Error Rate: 55.29%\n",
            "Minibatch   1010  | loss  1.22 | err rate 28.12%\n",
            "Minibatch   1020  | loss  0.56 | err rate 12.50%\n",
            "Minibatch   1030  | loss  1.43 | err rate 34.38%\n",
            "Minibatch   1040  | loss  1.23 | err rate 40.62%\n",
            "Minibatch   1050  | loss  1.40 | err rate 31.25%\n",
            "Minibatch   1060  | loss  1.13 | err rate 34.38%\n",
            "Minibatch   1070  | loss  1.02 | err rate 25.00%\n",
            "Minibatch   1080  | loss  1.47 | err rate 40.62%\n",
            "Minibatch   1090  | loss  1.33 | err rate 43.75%\n",
            "Minibatch   1100  | loss  0.69 | err rate 12.50%\n",
            "Minibatch   1110  | loss  1.46 | err rate 34.38%\n",
            "Minibatch   1120  | loss  1.34 | err rate 50.00%\n",
            "Minibatch   1130  | loss  1.15 | err rate 28.12%\n",
            "Minibatch   1140  | loss  1.35 | err rate 43.75%\n",
            "Minibatch   1150  | loss  0.88 | err rate 25.00%\n",
            "Minibatch   1160  | loss  1.37 | err rate 40.62%\n",
            "Epoch 7/10, Validation Error Rate: 55.88%\n",
            "Minibatch   1170  | loss  0.99 | err rate 28.12%\n",
            "Minibatch   1180  | loss  0.83 | err rate 25.00%\n",
            "Minibatch   1190  | loss  1.24 | err rate 43.75%\n",
            "Minibatch   1200  | loss  0.82 | err rate 21.88%\n",
            "Minibatch   1210  | loss  1.15 | err rate 34.38%\n",
            "Minibatch   1220  | loss  0.79 | err rate 21.88%\n",
            "Minibatch   1230  | loss  0.85 | err rate 18.75%\n",
            "Minibatch   1240  | loss  0.90 | err rate 18.75%\n",
            "Minibatch   1250  | loss  0.93 | err rate 21.88%\n",
            "Minibatch   1260  | loss  1.04 | err rate 34.38%\n",
            "Minibatch   1270  | loss  1.08 | err rate 28.12%\n",
            "Minibatch   1280  | loss  0.87 | err rate 21.88%\n",
            "Minibatch   1290  | loss  0.77 | err rate 15.62%\n",
            "Minibatch   1300  | loss  1.42 | err rate 37.50%\n",
            "Minibatch   1310  | loss  0.74 | err rate 21.88%\n",
            "Minibatch   1320  | loss  1.03 | err rate 31.25%\n",
            "Minibatch   1330  | loss  0.83 | err rate 21.88%\n",
            "Epoch 8/10, Validation Error Rate: 54.71%\n",
            "Minibatch   1340  | loss  0.39 | err rate  9.38%\n",
            "Minibatch   1350  | loss  0.81 | err rate 25.00%\n",
            "Minibatch   1360  | loss  0.43 | err rate 18.75%\n",
            "Minibatch   1370  | loss  0.42 | err rate 15.62%\n",
            "Minibatch   1380  | loss  0.70 | err rate 18.75%\n",
            "Minibatch   1390  | loss  1.13 | err rate 28.12%\n",
            "Minibatch   1400  | loss  0.88 | err rate 31.25%\n",
            "Minibatch   1410  | loss  1.25 | err rate 34.38%\n",
            "Minibatch   1420  | loss  1.22 | err rate 37.50%\n",
            "Minibatch   1430  | loss  0.88 | err rate 25.00%\n",
            "Minibatch   1440  | loss  0.82 | err rate 25.00%\n",
            "Minibatch   1450  | loss  0.89 | err rate 31.25%\n",
            "Minibatch   1460  | loss  0.86 | err rate 15.62%\n",
            "Minibatch   1470  | loss  0.72 | err rate 15.62%\n",
            "Minibatch   1480  | loss  0.68 | err rate 25.00%\n",
            "Minibatch   1490  | loss  0.80 | err rate 25.00%\n",
            "Minibatch   1500  | loss  0.89 | err rate 31.25%\n",
            "Epoch 9/10, Validation Error Rate: 53.63%\n",
            "Minibatch   1510  | loss  0.52 | err rate 12.50%\n",
            "Minibatch   1520  | loss  0.40 | err rate  6.25%\n",
            "Minibatch   1530  | loss  0.57 | err rate 18.75%\n",
            "Minibatch   1540  | loss  0.73 | err rate 12.50%\n",
            "Minibatch   1550  | loss  0.35 | err rate 12.50%\n",
            "Minibatch   1560  | loss  0.65 | err rate 18.75%\n",
            "Minibatch   1570  | loss  0.83 | err rate 25.00%\n",
            "Minibatch   1580  | loss  0.98 | err rate 25.00%\n",
            "Minibatch   1590  | loss  0.86 | err rate 28.12%\n",
            "Minibatch   1600  | loss  0.51 | err rate 15.62%\n",
            "Minibatch   1610  | loss  0.66 | err rate 18.75%\n",
            "Minibatch   1620  | loss  0.45 | err rate 12.50%\n",
            "Minibatch   1630  | loss  0.57 | err rate 15.62%\n",
            "Minibatch   1640  | loss  0.81 | err rate 21.88%\n",
            "Minibatch   1650  | loss  0.54 | err rate 18.75%\n",
            "Minibatch   1660  | loss  1.13 | err rate 28.12%\n",
            "Epoch 10/10, Validation Error Rate: 57.84%\n",
            "Test Error Rate: 45.37%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▅▄▃▂▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.45366</td></tr><tr><td>val/err</td><td>57.84314</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-add-data-to-train-0.5</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ufddqsik' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ufddqsik</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_104933-ufddqsik/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_105811-i5k6mym6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/i5k6mym6' target=\"_blank\">simplecnn-add-data-to-train-0.8</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/i5k6mym6' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/i5k6mym6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fraction:  0.8\n",
            "Minibatch      0  | loss  5.80 | err rate 96.88%\n",
            "Minibatch     10  | loss  4.87 | err rate 93.75%\n",
            "Minibatch     20  | loss  4.51 | err rate 90.62%\n",
            "Minibatch     30  | loss  4.04 | err rate 84.38%\n",
            "Minibatch     40  | loss  4.27 | err rate 96.88%\n",
            "Minibatch     50  | loss  3.83 | err rate 78.12%\n",
            "Minibatch     60  | loss  4.16 | err rate 87.50%\n",
            "Minibatch     70  | loss  3.84 | err rate 90.62%\n",
            "Minibatch     80  | loss  4.13 | err rate 81.25%\n",
            "Minibatch     90  | loss  4.00 | err rate 90.62%\n",
            "Minibatch    100  | loss  4.06 | err rate 81.25%\n",
            "Minibatch    110  | loss  4.13 | err rate 84.38%\n",
            "Minibatch    120  | loss  4.16 | err rate 93.75%\n",
            "Minibatch    130  | loss  3.89 | err rate 93.75%\n",
            "Minibatch    140  | loss  3.81 | err rate 93.75%\n",
            "Minibatch    150  | loss  3.91 | err rate 87.50%\n",
            "Minibatch    160  | loss  3.97 | err rate 100.00%\n",
            "Minibatch    170  | loss  3.63 | err rate 84.38%\n",
            "Minibatch    180  | loss  3.67 | err rate 93.75%\n",
            "Minibatch    190  | loss  3.58 | err rate 87.50%\n",
            "Minibatch    200  | loss  3.61 | err rate 87.50%\n",
            "Minibatch    210  | loss  3.80 | err rate 93.75%\n",
            "Minibatch    220  | loss  4.07 | err rate 90.62%\n",
            "Minibatch    230  | loss  3.65 | err rate 78.12%\n",
            "Minibatch    240  | loss  3.75 | err rate 84.38%\n",
            "Minibatch    250  | loss  3.53 | err rate 90.62%\n",
            "Minibatch    260  | loss  3.69 | err rate 93.75%\n",
            "Minibatch    270  | loss  3.29 | err rate 78.12%\n",
            "Minibatch    280  | loss  3.55 | err rate 90.62%\n",
            "Minibatch    290  | loss  3.82 | err rate 93.75%\n",
            "Minibatch    300  | loss  3.42 | err rate 75.00%\n",
            "Minibatch    310  | loss  3.81 | err rate 78.12%\n",
            "Minibatch    320  | loss  4.52 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 85.59%\n",
            "Minibatch    330  | loss  2.60 | err rate 65.62%\n",
            "Minibatch    340  | loss  2.69 | err rate 75.00%\n",
            "Minibatch    350  | loss  2.93 | err rate 81.25%\n",
            "Minibatch    360  | loss  2.79 | err rate 78.12%\n",
            "Minibatch    370  | loss  2.28 | err rate 53.12%\n",
            "Minibatch    380  | loss  2.83 | err rate 62.50%\n",
            "Minibatch    390  | loss  3.06 | err rate 84.38%\n",
            "Minibatch    400  | loss  3.13 | err rate 81.25%\n",
            "Minibatch    410  | loss  1.95 | err rate 53.12%\n",
            "Minibatch    420  | loss  2.65 | err rate 59.38%\n",
            "Minibatch    430  | loss  2.32 | err rate 65.62%\n",
            "Minibatch    440  | loss  2.25 | err rate 56.25%\n",
            "Minibatch    450  | loss  2.44 | err rate 65.62%\n",
            "Minibatch    460  | loss  2.42 | err rate 62.50%\n",
            "Minibatch    470  | loss  2.57 | err rate 65.62%\n",
            "Minibatch    480  | loss  2.26 | err rate 53.12%\n",
            "Minibatch    490  | loss  2.13 | err rate 56.25%\n",
            "Minibatch    500  | loss  2.61 | err rate 59.38%\n",
            "Minibatch    510  | loss  2.45 | err rate 68.75%\n",
            "Minibatch    520  | loss  2.33 | err rate 68.75%\n",
            "Minibatch    530  | loss  1.92 | err rate 46.88%\n",
            "Minibatch    540  | loss  2.63 | err rate 71.88%\n",
            "Minibatch    550  | loss  2.41 | err rate 71.88%\n",
            "Minibatch    560  | loss  2.02 | err rate 53.12%\n",
            "Minibatch    570  | loss  2.40 | err rate 68.75%\n",
            "Minibatch    580  | loss  2.85 | err rate 68.75%\n",
            "Minibatch    590  | loss  2.22 | err rate 50.00%\n",
            "Minibatch    600  | loss  1.87 | err rate 46.88%\n",
            "Minibatch    610  | loss  2.13 | err rate 56.25%\n",
            "Minibatch    620  | loss  2.16 | err rate 62.50%\n",
            "Minibatch    630  | loss  1.80 | err rate 53.12%\n",
            "Minibatch    640  | loss  2.28 | err rate 56.25%\n",
            "Epoch 2/10, Validation Error Rate: 69.51%\n",
            "Minibatch    650  | loss  2.16 | err rate 56.25%\n",
            "Minibatch    660  | loss  1.49 | err rate 40.62%\n",
            "Minibatch    670  | loss  2.25 | err rate 68.75%\n",
            "Minibatch    680  | loss  2.08 | err rate 56.25%\n",
            "Minibatch    690  | loss  1.92 | err rate 53.12%\n",
            "Minibatch    700  | loss  2.48 | err rate 78.12%\n",
            "Minibatch    710  | loss  1.79 | err rate 46.88%\n",
            "Minibatch    720  | loss  2.12 | err rate 65.62%\n",
            "Minibatch    730  | loss  1.79 | err rate 46.88%\n",
            "Minibatch    740  | loss  2.00 | err rate 62.50%\n",
            "Minibatch    750  | loss  1.77 | err rate 43.75%\n",
            "Minibatch    760  | loss  1.90 | err rate 59.38%\n",
            "Minibatch    770  | loss  2.71 | err rate 71.88%\n",
            "Minibatch    780  | loss  1.73 | err rate 46.88%\n",
            "Minibatch    790  | loss  2.16 | err rate 43.75%\n",
            "Minibatch    800  | loss  2.04 | err rate 50.00%\n",
            "Minibatch    810  | loss  1.64 | err rate 50.00%\n",
            "Minibatch    820  | loss  1.74 | err rate 50.00%\n",
            "Minibatch    830  | loss  1.82 | err rate 56.25%\n",
            "Minibatch    840  | loss  1.95 | err rate 46.88%\n",
            "Minibatch    850  | loss  2.01 | err rate 50.00%\n",
            "Minibatch    860  | loss  2.23 | err rate 56.25%\n",
            "Minibatch    870  | loss  1.55 | err rate 43.75%\n",
            "Minibatch    880  | loss  2.04 | err rate 53.12%\n",
            "Minibatch    890  | loss  1.72 | err rate 46.88%\n",
            "Minibatch    900  | loss  1.51 | err rate 43.75%\n",
            "Minibatch    910  | loss  1.63 | err rate 37.50%\n",
            "Minibatch    920  | loss  1.54 | err rate 50.00%\n",
            "Minibatch    930  | loss  2.23 | err rate 43.75%\n",
            "Minibatch    940  | loss  1.38 | err rate 50.00%\n",
            "Minibatch    950  | loss  1.26 | err rate 31.25%\n",
            "Minibatch    960  | loss  1.80 | err rate 50.00%\n",
            "Epoch 3/10, Validation Error Rate: 61.37%\n",
            "Minibatch    970  | loss  1.49 | err rate 40.62%\n",
            "Minibatch    980  | loss  1.54 | err rate 37.50%\n",
            "Minibatch    990  | loss  0.99 | err rate 31.25%\n",
            "Minibatch   1000  | loss  1.10 | err rate 31.25%\n",
            "Minibatch   1010  | loss  1.29 | err rate 40.62%\n",
            "Minibatch   1020  | loss  1.29 | err rate 46.88%\n",
            "Minibatch   1030  | loss  1.26 | err rate 40.62%\n",
            "Minibatch   1040  | loss  1.35 | err rate 40.62%\n",
            "Minibatch   1050  | loss  1.69 | err rate 50.00%\n",
            "Minibatch   1060  | loss  1.43 | err rate 40.62%\n",
            "Minibatch   1070  | loss  1.34 | err rate 28.12%\n",
            "Minibatch   1080  | loss  1.66 | err rate 50.00%\n",
            "Minibatch   1090  | loss  1.31 | err rate 40.62%\n",
            "Minibatch   1100  | loss  1.84 | err rate 53.12%\n",
            "Minibatch   1110  | loss  1.31 | err rate 34.38%\n",
            "Minibatch   1120  | loss  1.73 | err rate 53.12%\n",
            "Minibatch   1130  | loss  1.46 | err rate 37.50%\n",
            "Minibatch   1140  | loss  1.46 | err rate 40.62%\n",
            "Minibatch   1150  | loss  0.93 | err rate 21.88%\n",
            "Minibatch   1160  | loss  1.38 | err rate 40.62%\n",
            "Minibatch   1170  | loss  1.48 | err rate 50.00%\n",
            "Minibatch   1180  | loss  1.30 | err rate 34.38%\n",
            "Minibatch   1190  | loss  1.64 | err rate 40.62%\n",
            "Minibatch   1200  | loss  1.27 | err rate 25.00%\n",
            "Minibatch   1210  | loss  1.22 | err rate 31.25%\n",
            "Minibatch   1220  | loss  1.73 | err rate 43.75%\n",
            "Minibatch   1230  | loss  1.18 | err rate 37.50%\n",
            "Minibatch   1240  | loss  1.37 | err rate 37.50%\n",
            "Minibatch   1250  | loss  2.21 | err rate 43.75%\n",
            "Minibatch   1260  | loss  1.54 | err rate 43.75%\n",
            "Minibatch   1270  | loss  1.52 | err rate 37.50%\n",
            "Minibatch   1280  | loss  1.21 | err rate 34.38%\n",
            "Epoch 4/10, Validation Error Rate: 53.92%\n",
            "Minibatch   1290  | loss  1.25 | err rate 37.50%\n",
            "Minibatch   1300  | loss  1.35 | err rate 31.25%\n",
            "Minibatch   1310  | loss  1.06 | err rate 21.88%\n",
            "Minibatch   1320  | loss  1.42 | err rate 37.50%\n",
            "Minibatch   1330  | loss  1.29 | err rate 37.50%\n",
            "Minibatch   1340  | loss  1.18 | err rate 37.50%\n",
            "Minibatch   1350  | loss  1.03 | err rate 28.12%\n",
            "Minibatch   1360  | loss  1.45 | err rate 46.88%\n",
            "Minibatch   1370  | loss  1.27 | err rate 50.00%\n",
            "Minibatch   1380  | loss  1.27 | err rate 43.75%\n",
            "Minibatch   1390  | loss  0.93 | err rate 31.25%\n",
            "Minibatch   1400  | loss  1.08 | err rate 28.12%\n",
            "Minibatch   1410  | loss  0.83 | err rate 21.88%\n",
            "Minibatch   1420  | loss  1.22 | err rate 31.25%\n",
            "Minibatch   1430  | loss  1.15 | err rate 34.38%\n",
            "Minibatch   1440  | loss  0.93 | err rate 25.00%\n",
            "Minibatch   1450  | loss  0.64 | err rate 28.12%\n",
            "Minibatch   1460  | loss  1.26 | err rate 34.38%\n",
            "Minibatch   1470  | loss  1.27 | err rate 37.50%\n",
            "Minibatch   1480  | loss  1.18 | err rate 40.62%\n",
            "Minibatch   1490  | loss  1.23 | err rate 31.25%\n",
            "Minibatch   1500  | loss  0.93 | err rate 25.00%\n",
            "Minibatch   1510  | loss  0.97 | err rate 25.00%\n",
            "Minibatch   1520  | loss  0.81 | err rate 25.00%\n",
            "Minibatch   1530  | loss  1.48 | err rate 34.38%\n",
            "Minibatch   1540  | loss  1.19 | err rate 37.50%\n",
            "Minibatch   1550  | loss  0.93 | err rate 25.00%\n",
            "Minibatch   1560  | loss  1.32 | err rate 28.12%\n",
            "Minibatch   1570  | loss  0.99 | err rate 25.00%\n",
            "Minibatch   1580  | loss  0.87 | err rate 31.25%\n",
            "Minibatch   1590  | loss  1.10 | err rate 31.25%\n",
            "Minibatch   1600  | loss  1.28 | err rate 21.88%\n",
            "Epoch 5/10, Validation Error Rate: 51.37%\n",
            "Minibatch   1610  | loss  1.06 | err rate 34.38%\n",
            "Minibatch   1620  | loss  1.28 | err rate 37.50%\n",
            "Minibatch   1630  | loss  1.00 | err rate 28.12%\n",
            "Minibatch   1640  | loss  1.11 | err rate 34.38%\n",
            "Minibatch   1650  | loss  0.78 | err rate 31.25%\n",
            "Minibatch   1660  | loss  0.66 | err rate 21.88%\n",
            "Minibatch   1670  | loss  0.56 | err rate 12.50%\n",
            "Minibatch   1680  | loss  0.82 | err rate 28.12%\n",
            "Minibatch   1690  | loss  0.59 | err rate 15.62%\n",
            "Minibatch   1700  | loss  0.53 | err rate 18.75%\n",
            "Minibatch   1710  | loss  0.99 | err rate 28.12%\n",
            "Minibatch   1720  | loss  1.02 | err rate 28.12%\n",
            "Minibatch   1730  | loss  1.25 | err rate 31.25%\n",
            "Minibatch   1740  | loss  0.65 | err rate 31.25%\n",
            "Minibatch   1750  | loss  1.13 | err rate 28.12%\n",
            "Minibatch   1760  | loss  0.60 | err rate 18.75%\n",
            "Minibatch   1770  | loss  0.92 | err rate 21.88%\n",
            "Minibatch   1780  | loss  0.82 | err rate 25.00%\n",
            "Minibatch   1790  | loss  0.91 | err rate 28.12%\n",
            "Minibatch   1800  | loss  0.76 | err rate 21.88%\n",
            "Minibatch   1810  | loss  1.03 | err rate 28.12%\n",
            "Minibatch   1820  | loss  0.85 | err rate 18.75%\n",
            "Minibatch   1830  | loss  1.22 | err rate 37.50%\n",
            "Minibatch   1840  | loss  0.60 | err rate  6.25%\n",
            "Minibatch   1850  | loss  0.69 | err rate 15.62%\n",
            "Minibatch   1860  | loss  0.71 | err rate 21.88%\n",
            "Minibatch   1870  | loss  0.39 | err rate  6.25%\n",
            "Minibatch   1880  | loss  0.99 | err rate 21.88%\n",
            "Minibatch   1890  | loss  1.13 | err rate 31.25%\n",
            "Minibatch   1900  | loss  0.91 | err rate 28.12%\n",
            "Minibatch   1910  | loss  1.04 | err rate 31.25%\n",
            "Minibatch   1920  | loss  1.00 | err rate 28.12%\n",
            "Epoch 6/10, Validation Error Rate: 54.31%\n",
            "Minibatch   1930  | loss  0.46 | err rate 15.62%\n",
            "Minibatch   1940  | loss  0.91 | err rate 25.00%\n",
            "Minibatch   1950  | loss  0.67 | err rate 21.88%\n",
            "Minibatch   1960  | loss  0.60 | err rate 15.62%\n",
            "Minibatch   1970  | loss  0.64 | err rate 28.12%\n",
            "Minibatch   1980  | loss  0.57 | err rate 18.75%\n",
            "Minibatch   1990  | loss  1.33 | err rate 18.75%\n",
            "Minibatch   2000  | loss  0.60 | err rate 15.62%\n",
            "Minibatch   2010  | loss  0.73 | err rate 21.88%\n",
            "Minibatch   2020  | loss  0.46 | err rate 15.62%\n",
            "Minibatch   2030  | loss  0.46 | err rate  9.38%\n",
            "Minibatch   2040  | loss  0.71 | err rate 18.75%\n",
            "Minibatch   2050  | loss  0.71 | err rate 18.75%\n",
            "Minibatch   2060  | loss  0.61 | err rate 15.62%\n",
            "Minibatch   2070  | loss  0.58 | err rate 21.88%\n",
            "Minibatch   2080  | loss  0.45 | err rate  9.38%\n",
            "Minibatch   2090  | loss  0.74 | err rate 21.88%\n",
            "Minibatch   2100  | loss  0.73 | err rate 15.62%\n",
            "Minibatch   2110  | loss  0.82 | err rate 21.88%\n",
            "Minibatch   2120  | loss  0.58 | err rate 18.75%\n",
            "Minibatch   2130  | loss  0.61 | err rate 18.75%\n",
            "Minibatch   2140  | loss  0.58 | err rate 12.50%\n",
            "Minibatch   2150  | loss  0.67 | err rate 25.00%\n",
            "Minibatch   2160  | loss  1.14 | err rate 31.25%\n",
            "Minibatch   2170  | loss  0.84 | err rate 21.88%\n",
            "Minibatch   2180  | loss  0.63 | err rate 18.75%\n",
            "Minibatch   2190  | loss  0.91 | err rate 25.00%\n",
            "Minibatch   2200  | loss  1.08 | err rate 25.00%\n",
            "Minibatch   2210  | loss  1.17 | err rate 28.12%\n",
            "Minibatch   2220  | loss  1.01 | err rate 28.12%\n",
            "Minibatch   2230  | loss  0.37 | err rate  9.38%\n",
            "Minibatch   2240  | loss  0.75 | err rate 18.75%\n",
            "Epoch 7/10, Validation Error Rate: 50.29%\n",
            "Minibatch   2250  | loss  0.73 | err rate 25.00%\n",
            "Minibatch   2260  | loss  1.23 | err rate 46.88%\n",
            "Minibatch   2270  | loss  0.66 | err rate 18.75%\n",
            "Minibatch   2280  | loss  0.65 | err rate 21.88%\n",
            "Minibatch   2290  | loss  0.75 | err rate 12.50%\n",
            "Minibatch   2300  | loss  0.34 | err rate  6.25%\n",
            "Minibatch   2310  | loss  0.45 | err rate  9.38%\n",
            "Minibatch   2320  | loss  0.34 | err rate 12.50%\n",
            "Minibatch   2330  | loss  0.38 | err rate 12.50%\n",
            "Minibatch   2340  | loss  0.48 | err rate 15.62%\n",
            "Minibatch   2350  | loss  0.48 | err rate 18.75%\n",
            "Minibatch   2360  | loss  0.71 | err rate 25.00%\n",
            "Minibatch   2370  | loss  0.54 | err rate 15.62%\n",
            "Minibatch   2380  | loss  0.43 | err rate 12.50%\n",
            "Minibatch   2390  | loss  0.49 | err rate 18.75%\n",
            "Minibatch   2400  | loss  0.46 | err rate 12.50%\n",
            "Minibatch   2410  | loss  0.47 | err rate  9.38%\n",
            "Minibatch   2420  | loss  0.34 | err rate  9.38%\n",
            "Minibatch   2430  | loss  0.68 | err rate 21.88%\n",
            "Minibatch   2440  | loss  0.65 | err rate 18.75%\n",
            "Minibatch   2450  | loss  0.48 | err rate 12.50%\n",
            "Minibatch   2460  | loss  0.51 | err rate  9.38%\n",
            "Minibatch   2470  | loss  0.62 | err rate 12.50%\n",
            "Minibatch   2480  | loss  0.38 | err rate 12.50%\n",
            "Minibatch   2490  | loss  0.45 | err rate  9.38%\n",
            "Minibatch   2500  | loss  0.30 | err rate  9.38%\n",
            "Minibatch   2510  | loss  0.92 | err rate 28.12%\n",
            "Minibatch   2520  | loss  0.48 | err rate 15.62%\n",
            "Minibatch   2530  | loss  0.79 | err rate 21.88%\n",
            "Minibatch   2540  | loss  0.41 | err rate  9.38%\n",
            "Minibatch   2550  | loss  0.48 | err rate  9.38%\n",
            "Minibatch   2560  | loss  1.00 | err rate 18.75%\n",
            "Epoch 8/10, Validation Error Rate: 51.08%\n",
            "Minibatch   2570  | loss  0.60 | err rate 18.75%\n",
            "Minibatch   2580  | loss  0.81 | err rate 25.00%\n",
            "Minibatch   2590  | loss  0.57 | err rate 25.00%\n",
            "Minibatch   2600  | loss  0.31 | err rate  3.12%\n",
            "Minibatch   2610  | loss  0.48 | err rate 12.50%\n",
            "Minibatch   2620  | loss  0.60 | err rate 18.75%\n",
            "Minibatch   2630  | loss  0.50 | err rate 18.75%\n",
            "Minibatch   2640  | loss  0.26 | err rate  3.12%\n",
            "Minibatch   2650  | loss  0.31 | err rate  9.38%\n",
            "Minibatch   2660  | loss  0.77 | err rate 25.00%\n",
            "Minibatch   2670  | loss  0.46 | err rate 21.88%\n",
            "Minibatch   2680  | loss  0.40 | err rate 15.62%\n",
            "Minibatch   2690  | loss  0.68 | err rate 21.88%\n",
            "Minibatch   2700  | loss  0.33 | err rate  6.25%\n",
            "Minibatch   2710  | loss  0.39 | err rate  9.38%\n",
            "Minibatch   2720  | loss  0.57 | err rate 15.62%\n",
            "Minibatch   2730  | loss  0.72 | err rate 18.75%\n",
            "Minibatch   2740  | loss  0.93 | err rate 28.12%\n",
            "Minibatch   2750  | loss  0.65 | err rate 21.88%\n",
            "Minibatch   2760  | loss  0.66 | err rate 21.88%\n",
            "Minibatch   2770  | loss  0.41 | err rate  9.38%\n",
            "Minibatch   2780  | loss  0.80 | err rate 15.62%\n",
            "Minibatch   2790  | loss  0.34 | err rate 12.50%\n",
            "Minibatch   2800  | loss  0.78 | err rate 18.75%\n",
            "Minibatch   2810  | loss  0.34 | err rate  9.38%\n",
            "Minibatch   2820  | loss  0.53 | err rate 15.62%\n",
            "Minibatch   2830  | loss  0.55 | err rate 12.50%\n",
            "Minibatch   2840  | loss  0.38 | err rate 12.50%\n",
            "Minibatch   2850  | loss  0.29 | err rate  9.38%\n",
            "Minibatch   2860  | loss  0.31 | err rate  3.12%\n",
            "Minibatch   2870  | loss  0.82 | err rate 18.75%\n",
            "Minibatch   2880  | loss  0.42 | err rate 18.75%\n",
            "Epoch 9/10, Validation Error Rate: 48.24%\n",
            "Minibatch   2890  | loss  0.16 | err rate  6.25%\n",
            "Minibatch   2900  | loss  0.07 | err rate  0.00%\n",
            "Minibatch   2910  | loss  0.69 | err rate 18.75%\n",
            "Minibatch   2920  | loss  0.18 | err rate  3.12%\n",
            "Minibatch   2930  | loss  0.31 | err rate  9.38%\n",
            "Minibatch   2940  | loss  0.25 | err rate  9.38%\n",
            "Minibatch   2950  | loss  0.20 | err rate  3.12%\n",
            "Minibatch   2960  | loss  0.54 | err rate 12.50%\n",
            "Minibatch   2970  | loss  0.13 | err rate  3.12%\n",
            "Minibatch   2980  | loss  0.69 | err rate  9.38%\n",
            "Minibatch   2990  | loss  0.18 | err rate  3.12%\n",
            "Minibatch   3000  | loss  0.40 | err rate 12.50%\n",
            "Minibatch   3010  | loss  0.42 | err rate 15.62%\n",
            "Minibatch   3020  | loss  0.10 | err rate  3.12%\n",
            "Minibatch   3030  | loss  0.44 | err rate 18.75%\n",
            "Minibatch   3040  | loss  0.30 | err rate  9.38%\n",
            "Minibatch   3050  | loss  0.19 | err rate  3.12%\n",
            "Minibatch   3060  | loss  0.36 | err rate  6.25%\n",
            "Minibatch   3070  | loss  0.25 | err rate  3.12%\n",
            "Minibatch   3080  | loss  0.13 | err rate  3.12%\n",
            "Minibatch   3090  | loss  0.51 | err rate 12.50%\n",
            "Minibatch   3100  | loss  0.15 | err rate  6.25%\n",
            "Minibatch   3110  | loss  0.68 | err rate 21.88%\n",
            "Minibatch   3120  | loss  0.24 | err rate  6.25%\n",
            "Minibatch   3130  | loss  0.38 | err rate  6.25%\n",
            "Minibatch   3140  | loss  0.32 | err rate  6.25%\n",
            "Minibatch   3150  | loss  0.62 | err rate 18.75%\n",
            "Minibatch   3160  | loss  0.12 | err rate  0.00%\n",
            "Minibatch   3170  | loss  0.47 | err rate 15.62%\n",
            "Minibatch   3180  | loss  0.52 | err rate  9.38%\n",
            "Minibatch   3190  | loss  0.36 | err rate 15.62%\n",
            "Minibatch   3200  | loss  0.64 | err rate 18.75%\n",
            "Epoch 10/10, Validation Error Rate: 50.78%\n",
            "Test Error Rate: 24.39%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▅▃▂▂▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.2439</td></tr><tr><td>val/err</td><td>50.78431</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">simplecnn-add-data-to-train-0.8</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/i5k6mym6' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/i5k6mym6</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_105811-i5k6mym6/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "add_fracs = [0.2, 0.5, 0.8]\n",
        "for frac in add_fracs:\n",
        "  wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=f\"simplecnn-add-data-to-train-{frac}\",\n",
        "    config={\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"model\": \"simple\",\n",
        "        \"epochs\": 10,\n",
        "    }\n",
        "  )\n",
        "  k = int(frac * len(test_dataset))\n",
        "  used_dataset, remaining_test_dataset = random_split(test_dataset, [k, len(test_dataset) - k])\n",
        "  train_dataset = ConcatDataset([train_dataset, used_dataset])\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "  test_loader = DataLoader(remaining_test_dataset, batch_size=32, shuffle=False)\n",
        "  flowers102_loaders = {\n",
        "      'train': train_loader,\n",
        "      'val': val_loader,\n",
        "      'test': test_loader\n",
        "  }\n",
        "\n",
        "  model = SimpleConvAndMlp()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for name, p in model.named_parameters():\n",
        "        if \"weight\" in name and len(p.shape) >= 2:\n",
        "            torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "        elif \"bias\" in name:\n",
        "            p.zero_()\n",
        "\n",
        "  print(\"fraction: \", frac)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "  train_model(model, flowers102_loaders, optimizer, 10, 'cuda')\n",
        "  wandb.finish()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyYghXGrUHxC"
      },
      "source": [
        "## zad 3 - alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS8nZAGVXOvc"
      },
      "outputs": [],
      "source": [
        "def train_model(model, data_loaders, optimizer, schudler, num_epochs, device):\n",
        "    model.to(device)\n",
        "    iter_ = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x,y in data_loaders['train']:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = model.loss(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predictions = out.max(dim=1)\n",
        "            batch_err_rate = (predictions != y).sum().item() / out.size(0)\n",
        "\n",
        "            if iter_ % 10 == 0:\n",
        "                print(\n",
        "                    \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%\".format(\n",
        "                        iter_,\n",
        "                        loss.item(),\n",
        "                        batch_err_rate * 100.0,\n",
        "                    )\n",
        "                )\n",
        "            iter_ += 1\n",
        "\n",
        "\n",
        "        val_err_rate = compute_err_rate(model, data_loaders['val'], device)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Error Rate: {val_err_rate*100:.2f}%\")\n",
        "        wandb.log({ \"epoch\": epoch+1, \"val/err\": val_err_rate*100, })\n",
        "        scheduler.step()\n",
        "\n",
        "    test_err_rate = compute_err_rate(model, data_loaders['test'], device)\n",
        "    print(f\"Test Error Rate: {test_err_rate*100:.2f}%\")\n",
        "    wandb.log({ \"test/err\": test_err_rate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmPPK9qzULXz"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, num_classes=102):\n",
        "    super(AlexNet, self).__init__()\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "      nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),  # 224×224 → 55×55\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),                  # → 27×27\n",
        "      nn.Conv2d(64, 192, kernel_size=5, padding=2),           # → 27×27\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),                  # → 13×13\n",
        "      nn.Conv2d(192, 384, kernel_size=3, padding=1),          # → 13×13\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(384, 256, kernel_size=3, padding=1),          # → 13×13\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(256, 256, kernel_size=3, padding=1),          # → 13×13\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2)                   # → 6×6\n",
        "    )\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.5),\n",
        "      nn.Linear(256 * 6 * 6, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(p=0.5),\n",
        "      nn.Linear(4096, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Linear(4096, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "  def loss(self, Out, Target):\n",
        "    return F.cross_entropy(Out, Target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ka4BjaxGVSlK",
        "outputId": "567eaa5f-47ab-486b-9a89-806462023586"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>██▆▇▆▅▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.93625</td></tr><tr><td>val/err</td><td>94.80392</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-alexnet</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/9k7tepmx' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/9k7tepmx</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_103035-9k7tepmx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_103458-p607uhyk</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/p607uhyk' target=\"_blank\">run-alexnet</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/p607uhyk' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/p607uhyk</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss  7.22 | err rate 96.88%\n",
            "Minibatch     10  | loss  4.66 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.62 | err rate 100.00%\n",
            "Minibatch     30  | loss  4.63 | err rate 100.00%\n",
            "Epoch 1/50, Validation Error Rate: 99.41%\n",
            "Minibatch     40  | loss  4.62 | err rate 93.75%\n",
            "Minibatch     50  | loss  4.63 | err rate 96.88%\n",
            "Minibatch     60  | loss  4.63 | err rate 100.00%\n",
            "Epoch 2/50, Validation Error Rate: 97.65%\n",
            "Minibatch     70  | loss  4.62 | err rate 100.00%\n",
            "Minibatch     80  | loss  4.63 | err rate 96.88%\n",
            "Minibatch     90  | loss  4.63 | err rate 100.00%\n",
            "Epoch 3/50, Validation Error Rate: 97.84%\n",
            "Minibatch    100  | loss  4.61 | err rate 93.75%\n",
            "Minibatch    110  | loss  4.62 | err rate 100.00%\n",
            "Minibatch    120  | loss  4.63 | err rate 100.00%\n",
            "Epoch 4/50, Validation Error Rate: 98.73%\n",
            "Minibatch    130  | loss  4.38 | err rate 100.00%\n",
            "Minibatch    140  | loss  4.55 | err rate 100.00%\n",
            "Minibatch    150  | loss  4.55 | err rate 100.00%\n",
            "Epoch 5/50, Validation Error Rate: 98.43%\n",
            "Minibatch    160  | loss  4.47 | err rate 96.88%\n",
            "Minibatch    170  | loss  4.48 | err rate 96.88%\n",
            "Minibatch    180  | loss  4.26 | err rate 96.88%\n",
            "Minibatch    190  | loss  4.32 | err rate 100.00%\n",
            "Epoch 6/50, Validation Error Rate: 97.16%\n",
            "Minibatch    200  | loss  4.32 | err rate 96.88%\n",
            "Minibatch    210  | loss  4.46 | err rate 93.75%\n",
            "Minibatch    220  | loss  4.36 | err rate 93.75%\n",
            "Epoch 7/50, Validation Error Rate: 95.78%\n",
            "Minibatch    230  | loss  4.37 | err rate 93.75%\n",
            "Minibatch    240  | loss  4.34 | err rate 93.75%\n",
            "Minibatch    250  | loss  4.10 | err rate 96.88%\n",
            "Epoch 8/50, Validation Error Rate: 95.78%\n",
            "Minibatch    260  | loss  4.22 | err rate 96.88%\n",
            "Minibatch    270  | loss  4.43 | err rate 96.88%\n",
            "Minibatch    280  | loss  4.14 | err rate 93.75%\n",
            "Epoch 9/50, Validation Error Rate: 93.82%\n",
            "Minibatch    290  | loss  4.02 | err rate 90.62%\n",
            "Minibatch    300  | loss  3.95 | err rate 90.62%\n",
            "Minibatch    310  | loss  4.19 | err rate 93.75%\n",
            "Epoch 10/50, Validation Error Rate: 92.94%\n",
            "Minibatch    320  | loss  4.07 | err rate 96.88%\n",
            "Minibatch    330  | loss  3.28 | err rate 78.12%\n",
            "Minibatch    340  | loss  3.99 | err rate 90.62%\n",
            "Minibatch    350  | loss  3.84 | err rate 90.62%\n",
            "Epoch 11/50, Validation Error Rate: 92.94%\n",
            "Minibatch    360  | loss  3.57 | err rate 90.62%\n",
            "Minibatch    370  | loss  3.55 | err rate 90.62%\n",
            "Minibatch    380  | loss  3.48 | err rate 81.25%\n",
            "Epoch 12/50, Validation Error Rate: 91.96%\n",
            "Minibatch    390  | loss  3.26 | err rate 71.88%\n",
            "Minibatch    400  | loss  3.28 | err rate 84.38%\n",
            "Minibatch    410  | loss  2.93 | err rate 78.12%\n",
            "Epoch 13/50, Validation Error Rate: 89.71%\n",
            "Minibatch    420  | loss  2.80 | err rate 65.62%\n",
            "Minibatch    430  | loss  3.02 | err rate 71.88%\n",
            "Minibatch    440  | loss  3.07 | err rate 78.12%\n",
            "Epoch 14/50, Validation Error Rate: 89.22%\n",
            "Minibatch    450  | loss  1.85 | err rate 43.75%\n",
            "Minibatch    460  | loss  2.35 | err rate 65.62%\n",
            "Minibatch    470  | loss  2.53 | err rate 71.88%\n",
            "Epoch 15/50, Validation Error Rate: 90.10%\n",
            "Minibatch    480  | loss  2.24 | err rate 62.50%\n",
            "Minibatch    490  | loss  2.23 | err rate 62.50%\n",
            "Minibatch    500  | loss  2.40 | err rate 71.88%\n",
            "Minibatch    510  | loss  2.83 | err rate 71.88%\n",
            "Epoch 16/50, Validation Error Rate: 86.96%\n",
            "Minibatch    520  | loss  2.04 | err rate 46.88%\n",
            "Minibatch    530  | loss  1.52 | err rate 40.62%\n",
            "Minibatch    540  | loss  2.35 | err rate 56.25%\n",
            "Epoch 17/50, Validation Error Rate: 86.76%\n",
            "Minibatch    550  | loss  1.67 | err rate 50.00%\n",
            "Minibatch    560  | loss  1.51 | err rate 46.88%\n",
            "Minibatch    570  | loss  1.87 | err rate 50.00%\n",
            "Epoch 18/50, Validation Error Rate: 88.24%\n",
            "Minibatch    580  | loss  1.39 | err rate 31.25%\n",
            "Minibatch    590  | loss  1.97 | err rate 46.88%\n",
            "Minibatch    600  | loss  1.14 | err rate 40.62%\n",
            "Epoch 19/50, Validation Error Rate: 85.49%\n",
            "Minibatch    610  | loss  1.13 | err rate 25.00%\n",
            "Minibatch    620  | loss  1.10 | err rate 34.38%\n",
            "Minibatch    630  | loss  0.87 | err rate 15.62%\n",
            "Epoch 20/50, Validation Error Rate: 88.73%\n",
            "Minibatch    640  | loss  1.23 | err rate 34.38%\n",
            "Minibatch    650  | loss  0.98 | err rate 21.88%\n",
            "Minibatch    660  | loss  1.14 | err rate 25.00%\n",
            "Minibatch    670  | loss  1.05 | err rate 31.25%\n",
            "Epoch 21/50, Validation Error Rate: 85.10%\n",
            "Minibatch    680  | loss  0.99 | err rate 21.88%\n",
            "Minibatch    690  | loss  1.03 | err rate 34.38%\n",
            "Minibatch    700  | loss  0.62 | err rate 15.62%\n",
            "Epoch 22/50, Validation Error Rate: 88.33%\n",
            "Minibatch    710  | loss  0.37 | err rate  6.25%\n",
            "Minibatch    720  | loss  0.25 | err rate  6.25%\n",
            "Minibatch    730  | loss  0.28 | err rate  9.38%\n",
            "Epoch 23/50, Validation Error Rate: 86.18%\n",
            "Minibatch    740  | loss  0.20 | err rate  6.25%\n",
            "Minibatch    750  | loss  0.65 | err rate 12.50%\n",
            "Minibatch    760  | loss  0.53 | err rate  6.25%\n",
            "Epoch 24/50, Validation Error Rate: 86.67%\n",
            "Minibatch    770  | loss  0.13 | err rate  3.12%\n",
            "Minibatch    780  | loss  0.21 | err rate  6.25%\n",
            "Minibatch    790  | loss  0.41 | err rate  9.38%\n",
            "Epoch 25/50, Validation Error Rate: 88.73%\n",
            "Minibatch    800  | loss  0.12 | err rate  0.00%\n",
            "Minibatch    810  | loss  0.32 | err rate  6.25%\n",
            "Minibatch    820  | loss  0.86 | err rate 18.75%\n",
            "Minibatch    830  | loss  0.80 | err rate 18.75%\n",
            "Epoch 26/50, Validation Error Rate: 85.20%\n",
            "Minibatch    840  | loss  0.26 | err rate  9.38%\n",
            "Minibatch    850  | loss  0.07 | err rate  0.00%\n",
            "Minibatch    860  | loss  0.45 | err rate 15.62%\n",
            "Epoch 27/50, Validation Error Rate: 86.76%\n",
            "Minibatch    870  | loss  0.28 | err rate  9.38%\n",
            "Minibatch    880  | loss  0.17 | err rate  3.12%\n",
            "Minibatch    890  | loss  1.51 | err rate 18.75%\n",
            "Epoch 28/50, Validation Error Rate: 86.27%\n",
            "Minibatch    900  | loss  0.10 | err rate  0.00%\n",
            "Minibatch    910  | loss  0.34 | err rate  6.25%\n",
            "Minibatch    920  | loss  0.23 | err rate  6.25%\n",
            "Epoch 29/50, Validation Error Rate: 85.59%\n",
            "Minibatch    930  | loss  0.08 | err rate  3.12%\n",
            "Minibatch    940  | loss  0.45 | err rate  9.38%\n",
            "Minibatch    950  | loss  0.34 | err rate 12.50%\n",
            "Epoch 30/50, Validation Error Rate: 86.86%\n",
            "Minibatch    960  | loss  0.09 | err rate  3.12%\n",
            "Minibatch    970  | loss  0.03 | err rate  0.00%\n",
            "Minibatch    980  | loss  0.24 | err rate  6.25%\n",
            "Minibatch    990  | loss  0.07 | err rate  3.12%\n",
            "Epoch 31/50, Validation Error Rate: 86.08%\n",
            "Minibatch   1000  | loss  0.02 | err rate  0.00%\n",
            "Minibatch   1010  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1020  | loss  0.03 | err rate  0.00%\n",
            "Epoch 32/50, Validation Error Rate: 85.98%\n",
            "Minibatch   1030  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1040  | loss  0.05 | err rate  0.00%\n",
            "Minibatch   1050  | loss  0.01 | err rate  0.00%\n",
            "Epoch 33/50, Validation Error Rate: 85.88%\n",
            "Minibatch   1060  | loss  0.03 | err rate  0.00%\n",
            "Minibatch   1070  | loss  0.03 | err rate  0.00%\n",
            "Minibatch   1080  | loss  0.01 | err rate  0.00%\n",
            "Epoch 34/50, Validation Error Rate: 85.59%\n",
            "Minibatch   1090  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1100  | loss  0.06 | err rate  3.12%\n",
            "Minibatch   1110  | loss  0.00 | err rate  0.00%\n",
            "Epoch 35/50, Validation Error Rate: 85.49%\n",
            "Minibatch   1120  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1130  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1140  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1150  | loss  0.00 | err rate  0.00%\n",
            "Epoch 36/50, Validation Error Rate: 85.00%\n",
            "Minibatch   1160  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1170  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1180  | loss  0.01 | err rate  0.00%\n",
            "Epoch 37/50, Validation Error Rate: 84.71%\n",
            "Minibatch   1190  | loss  0.04 | err rate  0.00%\n",
            "Minibatch   1200  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1210  | loss  0.01 | err rate  0.00%\n",
            "Epoch 38/50, Validation Error Rate: 84.71%\n",
            "Minibatch   1220  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1230  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1240  | loss  0.01 | err rate  0.00%\n",
            "Epoch 39/50, Validation Error Rate: 84.51%\n",
            "Minibatch   1250  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1260  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1270  | loss  0.01 | err rate  0.00%\n",
            "Epoch 40/50, Validation Error Rate: 84.51%\n",
            "Minibatch   1280  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1290  | loss  0.05 | err rate  3.12%\n",
            "Minibatch   1300  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1310  | loss  0.00 | err rate  0.00%\n",
            "Epoch 41/50, Validation Error Rate: 84.41%\n",
            "Minibatch   1320  | loss  0.02 | err rate  0.00%\n",
            "Minibatch   1330  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1340  | loss  0.00 | err rate  0.00%\n",
            "Epoch 42/50, Validation Error Rate: 84.41%\n",
            "Minibatch   1350  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1360  | loss  0.05 | err rate  0.00%\n",
            "Minibatch   1370  | loss  0.00 | err rate  0.00%\n",
            "Epoch 43/50, Validation Error Rate: 84.61%\n",
            "Minibatch   1380  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1390  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1400  | loss  0.00 | err rate  0.00%\n",
            "Epoch 44/50, Validation Error Rate: 84.41%\n",
            "Minibatch   1410  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1420  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1430  | loss  0.00 | err rate  0.00%\n",
            "Epoch 45/50, Validation Error Rate: 84.41%\n",
            "Minibatch   1440  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1450  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1460  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1470  | loss  0.00 | err rate  0.00%\n",
            "Epoch 46/50, Validation Error Rate: 84.51%\n",
            "Minibatch   1480  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1490  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1500  | loss  0.00 | err rate  0.00%\n",
            "Epoch 47/50, Validation Error Rate: 84.61%\n",
            "Minibatch   1510  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1520  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1530  | loss  0.00 | err rate  0.00%\n",
            "Epoch 48/50, Validation Error Rate: 84.51%\n",
            "Minibatch   1540  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1550  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1560  | loss  0.00 | err rate  0.00%\n",
            "Epoch 49/50, Validation Error Rate: 84.51%\n",
            "Minibatch   1570  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1580  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1590  | loss  0.00 | err rate  0.00%\n",
            "Epoch 50/50, Validation Error Rate: 84.51%\n",
            "Test Error Rate: 88.03%\n"
          ]
        }
      ],
      "source": [
        "model = AlexNet()\n",
        "\n",
        "# init features\n",
        "with torch.no_grad():\n",
        "  for name, p in model.named_parameters():\n",
        "    if \"weight\" in name and len(p.shape) >= 2:\n",
        "        torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "    elif \"bias\" in name:\n",
        "        p.zero_()\n",
        "\n",
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"run-alexnet\",\n",
        "    config={\n",
        "        \"optimizer\": \"SGD\",\n",
        "        \"lr\": 0.01,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"epochs\": 50,\n",
        "        \"batch_size\": 32,\n",
        "        \"momentum\": 0.9,\n",
        "        \"scheduler\": \"StepLR, step=30, gamma=0.1\"\n",
        "    }\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4, momentum=0.9,)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "train_model(model, flowers102_loaders, optimizer, scheduler, 50, 'cuda')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sphwkZsHg1MT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y63v-Lq1g13N"
      },
      "source": [
        "overtrain fix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywcsWGZ6hGD9"
      },
      "outputs": [],
      "source": [
        "mean= [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "test_dataset = torchvision.datasets.Flowers102(root='./data', split=\"test\", download=True, transform=transform)\n",
        "val_dataset = torchvision.datasets.Flowers102(root='./data', split=\"val\", download=True, transform=transform)\n",
        "train_dataset = torchvision.datasets.Flowers102(root='./data', split=\"train\", download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx7IYjlphM93"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "flowers102_loaders = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader,\n",
        "    'test': test_loader\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2wevZxwhXeq"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, num_classes=102):\n",
        "    super(AlexNet, self).__init__()\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "      nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),  # 224×224 → 55×55\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),                  # → 27×27\n",
        "      nn.Conv2d(64, 192, kernel_size=5, padding=2),           # → 27×27\n",
        "      nn.BatchNorm2d(192), #we add batchnorm\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),                  # → 13×13\n",
        "      nn.Conv2d(192, 384, kernel_size=3, padding=1),          # → 13×13\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(384, 256, kernel_size=3, padding=1),          # → 13×13\n",
        "      nn.BatchNorm2d(256), #we add batchnorm\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(256, 256, kernel_size=3, padding=1),          # → 13×13\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2)                   # → 6×6\n",
        "    )\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.5),\n",
        "      nn.Linear(256 * 6 * 6, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(p=0.5),\n",
        "      nn.Linear(4096, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Linear(4096, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "  def loss(self, Out, Target):\n",
        "    return F.cross_entropy(Out, Target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFYBbSk_iHCW"
      },
      "outputs": [],
      "source": [
        "def compute_err_rate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    errors = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            out = model(x)\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            errors += (predicted != y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return errors / total\n",
        "\n",
        "def compute_val_loss(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            # redukcja sum, żeby potem podzielić przez liczbę próbek\n",
        "            loss = F.cross_entropy(out, y, reduction='sum')\n",
        "            total_loss += loss.item()\n",
        "            total_samples += y.size(0)\n",
        "    # średnia strata na jeden przykład\n",
        "    return total_loss / total_samples\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, data_loaders, optimizer, schudler, num_epochs, device):\n",
        "    model.to(device)\n",
        "    iter_ = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x,y in data_loaders['train']:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = model.loss(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predictions = out.max(dim=1)\n",
        "            batch_err_rate = (predictions != y).sum().item() / out.size(0)\n",
        "\n",
        "            if iter_ % 10 == 0:\n",
        "                print(\n",
        "                    \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%\".format(\n",
        "                        iter_,\n",
        "                        loss.item(),\n",
        "                        batch_err_rate * 100.0,\n",
        "                    )\n",
        "                )\n",
        "            iter_ += 1\n",
        "\n",
        "\n",
        "        val_err_rate = compute_err_rate(model, data_loaders['val'], device)\n",
        "        val_loss = compute_val_loss(model, data_loaders['val'], device)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Error Rate: {val_err_rate*100:.2f}%\")\n",
        "        wandb.log({ \"epoch\": epoch+1, \"val/err\": val_err_rate*100, \"val/loss\": val_loss})\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    test_err_rate = compute_err_rate(model, data_loaders['test'], device)\n",
        "    print(f\"Test Error Rate: {test_err_rate*100:.2f}%\")\n",
        "    wandb.log({ \"test/err\": test_err_rate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LK6Dp7kAhof2",
        "outputId": "003647c6-30e2-4c87-8af2-729edd09bf39"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▅▅▆▆▇▁▂▂▃▃▅▆▇▇▇▂▃▃▄▄▅▅▇▁▁▂▄▇▁▃▄▅▅▇█</td></tr><tr><td>test/err</td><td>█▇▇▁▃</td></tr><tr><td>val/err</td><td>██▇▆▆▆▆▆▆▆▆█▇█▇███▇▇█████▇██▆▆▅▆▆▆▄▄▄▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>test/err</td><td>0.92157</td></tr><tr><td>val/err</td><td>85.29412</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-001</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/a6olqmb7' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/a6olqmb7</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_110154-a6olqmb7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_112532-f84si7j6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/f84si7j6' target=\"_blank\">run-alexnet-overtrain-fix</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/f84si7j6' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/f84si7j6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss  8.87 | err rate 100.00%\n",
            "Minibatch     10  | loss  6.90 | err rate 96.88%\n",
            "Minibatch     20  | loss  5.61 | err rate 93.75%\n",
            "Minibatch     30  | loss  4.89 | err rate 93.75%\n",
            "Epoch 1/40, Validation Error Rate: 94.51%\n",
            "Minibatch     40  | loss  4.12 | err rate 87.50%\n",
            "Minibatch     50  | loss  3.40 | err rate 84.38%\n",
            "Minibatch     60  | loss  3.41 | err rate 84.38%\n",
            "Epoch 2/40, Validation Error Rate: 86.18%\n",
            "Minibatch     70  | loss  2.71 | err rate 56.25%\n",
            "Minibatch     80  | loss  2.72 | err rate 62.50%\n",
            "Minibatch     90  | loss  2.42 | err rate 65.62%\n",
            "Epoch 3/40, Validation Error Rate: 80.10%\n",
            "Minibatch    100  | loss  1.53 | err rate 31.25%\n",
            "Minibatch    110  | loss  2.17 | err rate 50.00%\n",
            "Minibatch    120  | loss  1.72 | err rate 40.62%\n",
            "Epoch 4/40, Validation Error Rate: 76.47%\n",
            "Minibatch    130  | loss  1.59 | err rate 40.62%\n",
            "Minibatch    140  | loss  0.76 | err rate 18.75%\n",
            "Minibatch    150  | loss  1.01 | err rate 34.38%\n",
            "Epoch 5/40, Validation Error Rate: 75.59%\n",
            "Minibatch    160  | loss  0.67 | err rate 21.88%\n",
            "Minibatch    170  | loss  0.48 | err rate  6.25%\n",
            "Minibatch    180  | loss  0.68 | err rate 15.62%\n",
            "Minibatch    190  | loss  0.38 | err rate  9.38%\n",
            "Epoch 6/40, Validation Error Rate: 74.71%\n",
            "Minibatch    200  | loss  0.51 | err rate  9.38%\n",
            "Minibatch    210  | loss  0.31 | err rate 12.50%\n",
            "Minibatch    220  | loss  0.19 | err rate  6.25%\n",
            "Epoch 7/40, Validation Error Rate: 74.61%\n",
            "Minibatch    230  | loss  0.08 | err rate  3.12%\n",
            "Minibatch    240  | loss  0.08 | err rate  0.00%\n",
            "Minibatch    250  | loss  0.03 | err rate  0.00%\n",
            "Epoch 8/40, Validation Error Rate: 70.29%\n",
            "Minibatch    260  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    270  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    280  | loss  0.02 | err rate  0.00%\n",
            "Epoch 9/40, Validation Error Rate: 69.02%\n",
            "Minibatch    290  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    300  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    310  | loss  0.01 | err rate  0.00%\n",
            "Epoch 10/40, Validation Error Rate: 69.02%\n",
            "Minibatch    320  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    330  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    340  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    350  | loss  0.02 | err rate  0.00%\n",
            "Epoch 11/40, Validation Error Rate: 68.33%\n",
            "Minibatch    360  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    370  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    380  | loss  0.01 | err rate  0.00%\n",
            "Epoch 12/40, Validation Error Rate: 68.43%\n",
            "Minibatch    390  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    400  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    410  | loss  0.01 | err rate  0.00%\n",
            "Epoch 13/40, Validation Error Rate: 68.04%\n",
            "Minibatch    420  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    430  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    440  | loss  0.01 | err rate  0.00%\n",
            "Epoch 14/40, Validation Error Rate: 68.04%\n",
            "Minibatch    450  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    460  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    470  | loss  0.01 | err rate  0.00%\n",
            "Epoch 15/40, Validation Error Rate: 68.04%\n",
            "Minibatch    480  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    490  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    500  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    510  | loss  0.01 | err rate  0.00%\n",
            "Epoch 16/40, Validation Error Rate: 68.04%\n",
            "Minibatch    520  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    530  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    540  | loss  0.01 | err rate  0.00%\n",
            "Epoch 17/40, Validation Error Rate: 68.14%\n",
            "Minibatch    550  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    560  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    570  | loss  0.01 | err rate  0.00%\n",
            "Epoch 18/40, Validation Error Rate: 68.14%\n",
            "Minibatch    580  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    590  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    600  | loss  0.01 | err rate  0.00%\n",
            "Epoch 19/40, Validation Error Rate: 68.14%\n",
            "Minibatch    610  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    620  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    630  | loss  0.01 | err rate  0.00%\n",
            "Epoch 20/40, Validation Error Rate: 68.14%\n",
            "Minibatch    640  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    650  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    660  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    670  | loss  0.01 | err rate  0.00%\n",
            "Epoch 21/40, Validation Error Rate: 68.14%\n",
            "Minibatch    680  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    690  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    700  | loss  0.01 | err rate  0.00%\n",
            "Epoch 22/40, Validation Error Rate: 68.14%\n",
            "Minibatch    710  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    720  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    730  | loss  0.01 | err rate  0.00%\n",
            "Epoch 23/40, Validation Error Rate: 68.14%\n",
            "Minibatch    740  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    750  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    760  | loss  0.01 | err rate  0.00%\n",
            "Epoch 24/40, Validation Error Rate: 68.14%\n",
            "Minibatch    770  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    780  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    790  | loss  0.01 | err rate  0.00%\n",
            "Epoch 25/40, Validation Error Rate: 68.14%\n",
            "Minibatch    800  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    810  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    820  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    830  | loss  0.01 | err rate  0.00%\n",
            "Epoch 26/40, Validation Error Rate: 68.14%\n",
            "Minibatch    840  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    850  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    860  | loss  0.01 | err rate  0.00%\n",
            "Epoch 27/40, Validation Error Rate: 68.14%\n",
            "Minibatch    870  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    880  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    890  | loss  0.01 | err rate  0.00%\n",
            "Epoch 28/40, Validation Error Rate: 68.14%\n",
            "Minibatch    900  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    910  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    920  | loss  0.01 | err rate  0.00%\n",
            "Epoch 29/40, Validation Error Rate: 68.14%\n",
            "Minibatch    930  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    940  | loss  0.00 | err rate  0.00%\n",
            "Minibatch    950  | loss  0.01 | err rate  0.00%\n",
            "Epoch 30/40, Validation Error Rate: 68.14%\n",
            "Minibatch    960  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    970  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    980  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    990  | loss  0.01 | err rate  0.00%\n",
            "Epoch 31/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1000  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1010  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1020  | loss  0.01 | err rate  0.00%\n",
            "Epoch 32/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1030  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1040  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1050  | loss  0.01 | err rate  0.00%\n",
            "Epoch 33/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1060  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1070  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1080  | loss  0.01 | err rate  0.00%\n",
            "Epoch 34/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1090  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1100  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1110  | loss  0.01 | err rate  0.00%\n",
            "Epoch 35/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1120  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1130  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1140  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1150  | loss  0.01 | err rate  0.00%\n",
            "Epoch 36/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1160  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1170  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1180  | loss  0.01 | err rate  0.00%\n",
            "Epoch 37/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1190  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1200  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1210  | loss  0.01 | err rate  0.00%\n",
            "Epoch 38/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1220  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1230  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1240  | loss  0.01 | err rate  0.00%\n",
            "Epoch 39/40, Validation Error Rate: 68.14%\n",
            "Minibatch   1250  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1260  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1270  | loss  0.01 | err rate  0.00%\n",
            "Epoch 40/40, Validation Error Rate: 68.14%\n",
            "Test Error Rate: 71.21%\n"
          ]
        }
      ],
      "source": [
        "model = AlexNet()\n",
        "\n",
        "# init features\n",
        "with torch.no_grad():\n",
        "  for name, p in model.named_parameters():\n",
        "    if \"weight\" in name and len(p.shape) >= 2:\n",
        "        torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "    elif \"bias\" in name:\n",
        "        p.zero_()\n",
        "\n",
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"run-alexnet-overtrain-fix\",\n",
        "    config={\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 1e-4,\n",
        "        \"weight_decay\": 1e-3,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"epochs\": 40,\n",
        "        \"scheduler\": \"ReduceLROnPlateau, mode=min, factor=0.1, patience=3\"\n",
        "    }\n",
        ")\n",
        "\n",
        "#bigger weight decay, adam instead of sgd, reducelronpleateau scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "train_model(model, flowers102_loaders, optimizer, scheduler, 40, 'cuda')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L5NcyjwKeYr"
      },
      "source": [
        "## zad 4 - different input normalization techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPLARK7iodkM"
      },
      "outputs": [],
      "source": [
        "def train_model(model, data_loaders, optimizer, num_epochs, device):\n",
        "    model.to(device)\n",
        "    iter_ = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x,y in data_loaders['train']:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = model.loss(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predictions = out.max(dim=1)\n",
        "            batch_err_rate = (predictions != y).sum().item() / out.size(0)\n",
        "\n",
        "            if iter_ % 10 == 0:\n",
        "                print(\n",
        "                    \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%\".format(\n",
        "                        iter_,\n",
        "                        loss.item(),\n",
        "                        batch_err_rate * 100.0,\n",
        "                    )\n",
        "                )\n",
        "            iter_ += 1\n",
        "\n",
        "\n",
        "        val_err_rate = compute_err_rate(model, data_loaders['val'], device)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Error Rate: {val_err_rate*100:.2f}%\")\n",
        "        wandb.log({ \"epoch\": epoch+1, \"val/err\": val_err_rate*100, })\n",
        "\n",
        "    test_err_rate = compute_err_rate(model, data_loaders['test'], device)\n",
        "    print(f\"Test Error Rate: {test_err_rate*100:.2f}%\")\n",
        "    wandb.log({ \"test/err\": test_err_rate})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecxIpG29mRo2"
      },
      "outputs": [],
      "source": [
        "# Define a transform to resize and crop the images to a uniform size\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),  # Resize the shorter side to 256\n",
        "    transforms.CenterCrop(224),  # Crop the center to 224x224\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_dataset = torchvision.datasets.Flowers102(root='./data', split=\"test\", download=False, transform=transform)\n",
        "val_dataset = torchvision.datasets.Flowers102(root='./data', split=\"val\", download=False, transform=transform)\n",
        "train_dataset = torchvision.datasets.Flowers102(root='./data', split=\"train\", download=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "flowers102_loaders = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader,\n",
        "    'test': test_loader\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvOdL7YXm1C2",
        "outputId": "605c3026-f68e-4c6d-b180-83034c15bc14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset mean: [0.5113758444786072, 0.4159521758556366, 0.34067586064338684]\n",
            "Dataset std:  [0.2955602705478668, 0.2492465078830719, 0.2888020873069763]\n"
          ]
        }
      ],
      "source": [
        "temp_ds = torchvision.datasets.Flowers102(root='./data', split=\"train\", download=True, transform=transform)\n",
        "temp_loader = DataLoader(temp_ds, batch_size=32, shuffle=False)\n",
        "# 2) Obliczamy per-channel mean i std\n",
        "sum_ = torch.zeros(3)\n",
        "sum_sq = torch.zeros(3)\n",
        "n_samples = 0\n",
        "\n",
        "for x, _ in temp_loader:\n",
        "    # x: [B,3,H,W]\n",
        "    B = x.size(0)\n",
        "\n",
        "\n",
        "    # przepłaszczamy H×W -> -1, by móc łatwo liczyć średnie po pikselach\n",
        "    x = x.view(B, 3, -1)\n",
        "    # sumujemy średnie po każdym kanale w batchu\n",
        "    sum_ += x.mean(dim=2).sum(dim=0)\n",
        "    # sumujemy średnie z kwadratów (do wariancji)\n",
        "    sum_sq += (x ** 2).mean(dim=2).sum(dim=0)\n",
        "    n_samples += B\n",
        "\n",
        "mean = sum_ / n_samples\n",
        "var  = sum_sq / n_samples - mean**2\n",
        "std  = torch.sqrt(var)\n",
        "\n",
        "print(f\"Dataset mean: {mean.tolist()}\")    # np-like\n",
        "print(f\"Dataset std:  {std.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "objTz9EImfNo"
      },
      "outputs": [],
      "source": [
        "norm_strategies = {\n",
        "    'none': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    , 'mean_subtraction': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean.tolist(), [1.0, 1.0, 1.0]),\n",
        "    ]),\n",
        "    'standardization': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean.tolist(), std.tolist()),\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MDqDAcCRnN-y",
        "outputId": "84fd032e-5115-4a66-c4ac-c5a86028eb2e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simplecnn-different-norm-techs</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/0el5ieca' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/0el5ieca</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_083425-0el5ieca/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_083736-bm47sn3r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bm47sn3r' target=\"_blank\">run-simplecnn-different-norm-techs</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bm47sn3r' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bm47sn3r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss  5.67 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.17 | err rate 93.75%\n",
            "Minibatch     20  | loss  4.70 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.58 | err rate 96.88%\n",
            "Epoch 1/10, Validation Error Rate: 95.39%\n",
            "Minibatch     40  | loss  4.10 | err rate 96.88%\n",
            "Minibatch     50  | loss  4.38 | err rate 96.88%\n",
            "Minibatch     60  | loss  3.87 | err rate 90.62%\n",
            "Epoch 2/10, Validation Error Rate: 91.67%\n",
            "Minibatch     70  | loss  4.12 | err rate 93.75%\n",
            "Minibatch     80  | loss  3.70 | err rate 87.50%\n",
            "Minibatch     90  | loss  3.27 | err rate 78.12%\n",
            "Epoch 3/10, Validation Error Rate: 86.18%\n",
            "Minibatch    100  | loss  3.33 | err rate 90.62%\n",
            "Minibatch    110  | loss  2.92 | err rate 75.00%\n",
            "Minibatch    120  | loss  3.07 | err rate 75.00%\n",
            "Epoch 4/10, Validation Error Rate: 82.55%\n",
            "Minibatch    130  | loss  2.81 | err rate 78.12%\n",
            "Minibatch    140  | loss  2.51 | err rate 65.62%\n",
            "Minibatch    150  | loss  3.11 | err rate 71.88%\n",
            "Epoch 5/10, Validation Error Rate: 78.92%\n",
            "Minibatch    160  | loss  2.21 | err rate 62.50%\n",
            "Minibatch    170  | loss  2.11 | err rate 53.12%\n",
            "Minibatch    180  | loss  2.16 | err rate 56.25%\n",
            "Minibatch    190  | loss  2.45 | err rate 65.62%\n",
            "Epoch 6/10, Validation Error Rate: 79.41%\n",
            "Minibatch    200  | loss  2.28 | err rate 53.12%\n",
            "Minibatch    210  | loss  2.20 | err rate 59.38%\n",
            "Minibatch    220  | loss  1.57 | err rate 43.75%\n",
            "Epoch 7/10, Validation Error Rate: 75.98%\n",
            "Minibatch    230  | loss  1.37 | err rate 37.50%\n",
            "Minibatch    240  | loss  1.48 | err rate 40.62%\n",
            "Minibatch    250  | loss  1.08 | err rate 31.25%\n",
            "Epoch 8/10, Validation Error Rate: 76.37%\n",
            "Minibatch    260  | loss  1.22 | err rate 31.25%\n",
            "Minibatch    270  | loss  1.58 | err rate 46.88%\n",
            "Minibatch    280  | loss  0.93 | err rate 25.00%\n",
            "Epoch 9/10, Validation Error Rate: 75.20%\n",
            "Minibatch    290  | loss  1.37 | err rate 40.62%\n",
            "Minibatch    300  | loss  1.07 | err rate 34.38%\n",
            "Minibatch    310  | loss  0.88 | err rate 21.88%\n",
            "Epoch 10/10, Validation Error Rate: 75.88%\n",
            "Test Error Rate: 77.41%\n",
            "Minibatch      0  | loss  5.59 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.23 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.75 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.42 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 94.12%\n",
            "Minibatch     40  | loss  4.00 | err rate 84.38%\n",
            "Minibatch     50  | loss  3.85 | err rate 87.50%\n",
            "Minibatch     60  | loss  3.99 | err rate 87.50%\n",
            "Epoch 2/10, Validation Error Rate: 89.41%\n",
            "Minibatch     70  | loss  3.34 | err rate 87.50%\n",
            "Minibatch     80  | loss  3.44 | err rate 87.50%\n",
            "Minibatch     90  | loss  3.58 | err rate 81.25%\n",
            "Epoch 3/10, Validation Error Rate: 85.49%\n",
            "Minibatch    100  | loss  3.13 | err rate 75.00%\n",
            "Minibatch    110  | loss  3.14 | err rate 81.25%\n",
            "Minibatch    120  | loss  2.82 | err rate 75.00%\n",
            "Epoch 4/10, Validation Error Rate: 84.12%\n",
            "Minibatch    130  | loss  2.62 | err rate 78.12%\n",
            "Minibatch    140  | loss  2.44 | err rate 62.50%\n",
            "Minibatch    150  | loss  2.36 | err rate 62.50%\n",
            "Epoch 5/10, Validation Error Rate: 81.47%\n",
            "Minibatch    160  | loss  2.06 | err rate 50.00%\n",
            "Minibatch    170  | loss  1.99 | err rate 50.00%\n",
            "Minibatch    180  | loss  2.29 | err rate 56.25%\n",
            "Minibatch    190  | loss  2.13 | err rate 62.50%\n",
            "Epoch 6/10, Validation Error Rate: 78.82%\n",
            "Minibatch    200  | loss  1.60 | err rate 50.00%\n",
            "Minibatch    210  | loss  1.63 | err rate 50.00%\n",
            "Minibatch    220  | loss  1.60 | err rate 46.88%\n",
            "Epoch 7/10, Validation Error Rate: 79.41%\n",
            "Minibatch    230  | loss  1.51 | err rate 31.25%\n",
            "Minibatch    240  | loss  1.34 | err rate 40.62%\n",
            "Minibatch    250  | loss  1.41 | err rate 34.38%\n",
            "Epoch 8/10, Validation Error Rate: 76.27%\n",
            "Minibatch    260  | loss  1.11 | err rate 37.50%\n",
            "Minibatch    270  | loss  1.14 | err rate 37.50%\n",
            "Minibatch    280  | loss  0.97 | err rate 28.12%\n",
            "Epoch 9/10, Validation Error Rate: 77.84%\n",
            "Minibatch    290  | loss  0.44 | err rate 12.50%\n",
            "Minibatch    300  | loss  0.85 | err rate 21.88%\n",
            "Minibatch    310  | loss  0.90 | err rate 34.38%\n",
            "Epoch 10/10, Validation Error Rate: 77.55%\n",
            "Test Error Rate: 80.81%\n",
            "Minibatch      0  | loss  5.97 | err rate 100.00%\n",
            "Minibatch     10  | loss  4.63 | err rate 93.75%\n",
            "Minibatch     20  | loss  4.64 | err rate 93.75%\n",
            "Minibatch     30  | loss  4.53 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 95.39%\n",
            "Minibatch     40  | loss  4.41 | err rate 100.00%\n",
            "Minibatch     50  | loss  4.07 | err rate 93.75%\n",
            "Minibatch     60  | loss  4.03 | err rate 96.88%\n",
            "Epoch 2/10, Validation Error Rate: 92.06%\n",
            "Minibatch     70  | loss  3.74 | err rate 87.50%\n",
            "Minibatch     80  | loss  3.83 | err rate 90.62%\n",
            "Minibatch     90  | loss  3.65 | err rate 84.38%\n",
            "Epoch 3/10, Validation Error Rate: 87.94%\n",
            "Minibatch    100  | loss  2.83 | err rate 68.75%\n",
            "Minibatch    110  | loss  3.30 | err rate 90.62%\n",
            "Minibatch    120  | loss  3.18 | err rate 87.50%\n",
            "Epoch 4/10, Validation Error Rate: 82.35%\n",
            "Minibatch    130  | loss  3.03 | err rate 71.88%\n",
            "Minibatch    140  | loss  2.46 | err rate 59.38%\n",
            "Minibatch    150  | loss  2.68 | err rate 68.75%\n",
            "Epoch 5/10, Validation Error Rate: 80.20%\n",
            "Minibatch    160  | loss  2.12 | err rate 59.38%\n",
            "Minibatch    170  | loss  3.23 | err rate 78.12%\n",
            "Minibatch    180  | loss  2.27 | err rate 62.50%\n",
            "Minibatch    190  | loss  1.95 | err rate 56.25%\n",
            "Epoch 6/10, Validation Error Rate: 79.71%\n",
            "Minibatch    200  | loss  2.49 | err rate 62.50%\n",
            "Minibatch    210  | loss  2.05 | err rate 68.75%\n",
            "Minibatch    220  | loss  1.71 | err rate 56.25%\n",
            "Epoch 7/10, Validation Error Rate: 75.39%\n",
            "Minibatch    230  | loss  1.47 | err rate 46.88%\n",
            "Minibatch    240  | loss  1.91 | err rate 56.25%\n",
            "Minibatch    250  | loss  1.47 | err rate 43.75%\n",
            "Epoch 8/10, Validation Error Rate: 75.49%\n",
            "Minibatch    260  | loss  1.22 | err rate 28.12%\n",
            "Minibatch    270  | loss  1.29 | err rate 34.38%\n",
            "Minibatch    280  | loss  1.09 | err rate 37.50%\n",
            "Epoch 9/10, Validation Error Rate: 75.39%\n",
            "Minibatch    290  | loss  0.83 | err rate 31.25%\n",
            "Minibatch    300  | loss  1.06 | err rate 28.12%\n",
            "Minibatch    310  | loss  0.57 | err rate 15.62%\n",
            "Epoch 10/10, Validation Error Rate: 76.47%\n",
            "Test Error Rate: 76.39%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"run-simplecnn-different-norm-techs\",\n",
        "    config={\n",
        "        \"epochs\": 10,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "for name, strategy in norm_strategies.items():\n",
        "\n",
        "  train_ds = torchvision.datasets.Flowers102(root='./data', split='train', download=False, transform=strategy)\n",
        "  val_ds   = torchvision.datasets.Flowers102(root='./data', split='val',   download=False, transform=strategy)\n",
        "  test_ds  = torchvision.datasets.Flowers102(root='./data', split='test',  download=False, transform=strategy)\n",
        "\n",
        "  train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "  val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
        "  test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "  flowers102_loaders = {\n",
        "      'train': train_loader,\n",
        "      'val': val_loader,\n",
        "      'test': test_loader\n",
        "  }\n",
        "\n",
        "  model = SimpleConvAndMlp()\n",
        "\n",
        "  # init features\n",
        "  with torch.no_grad():\n",
        "    for name, p in model.named_parameters():\n",
        "      if \"weight\" in name and len(p.shape) >= 2:\n",
        "          torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "      elif \"bias\" in name:\n",
        "          p.zero_()\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "  train_model(model, flowers102_loaders, optimizer, 10, 'cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJqYouTIxFiy"
      },
      "source": [
        "## zad 5 - Experiment with different hyperparameters such as learning rate, batch size, number of epochs, and optimizer choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxT3G1nExHbv"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_ds = torchvision.datasets.Flowers102(root='./data', split='train', download=False, transform=transform)\n",
        "val_ds   = torchvision.datasets.Flowers102(root='./data', split='val',   download=False, transform=transform)\n",
        "test_ds  = torchvision.datasets.Flowers102(root='./data', split='test',  download=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "flowers102_loaders = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader,\n",
        "    'test': test_loader\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KLOMiit8xX6W",
        "outputId": "73de3898-49cb-4d8b-8d0d-1701580dcf95"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█▁▂▃▃▄▅▆▆▇█▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▃█▁</td></tr><tr><td>val/err</td><td>█▇▅▄▂▂▁▁▁▁█▆▅▄▃▂▂▁▂▂█▇▅▃▃▃▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.76386</td></tr><tr><td>val/err</td><td>76.47059</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simplecnn-different-norm-techs</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bm47sn3r' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/bm47sn3r</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_083736-bm47sn3r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_085400-yzi734d5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yzi734d5' target=\"_blank\">different-learning-rates</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yzi734d5' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yzi734d5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr:  0.01\n",
            "Minibatch      0  | loss  5.63 | err rate 96.88%\n",
            "Minibatch     10  | loss  7.80 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.61 | err rate 100.00%\n",
            "Minibatch     30  | loss  4.67 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 98.82%\n",
            "Minibatch     40  | loss  4.73 | err rate 100.00%\n",
            "Minibatch     50  | loss  4.54 | err rate 93.75%\n",
            "Minibatch     60  | loss  4.56 | err rate 96.88%\n",
            "Epoch 2/10, Validation Error Rate: 97.06%\n",
            "Minibatch     70  | loss  4.58 | err rate 96.88%\n",
            "Minibatch     80  | loss  4.41 | err rate 96.88%\n",
            "Minibatch     90  | loss  4.34 | err rate 100.00%\n",
            "Epoch 3/10, Validation Error Rate: 95.78%\n",
            "Minibatch    100  | loss  4.31 | err rate 96.88%\n",
            "Minibatch    110  | loss  4.24 | err rate 100.00%\n",
            "Minibatch    120  | loss  3.93 | err rate 93.75%\n",
            "Epoch 4/10, Validation Error Rate: 92.94%\n",
            "Minibatch    130  | loss  4.22 | err rate 100.00%\n",
            "Minibatch    140  | loss  3.94 | err rate 100.00%\n",
            "Minibatch    150  | loss  4.47 | err rate 93.75%\n",
            "Epoch 5/10, Validation Error Rate: 94.80%\n",
            "Minibatch    160  | loss  3.78 | err rate 96.88%\n",
            "Minibatch    170  | loss  3.49 | err rate 87.50%\n",
            "Minibatch    180  | loss  3.89 | err rate 96.88%\n",
            "Minibatch    190  | loss  3.55 | err rate 90.62%\n",
            "Epoch 6/10, Validation Error Rate: 93.04%\n",
            "Minibatch    200  | loss  3.97 | err rate 93.75%\n",
            "Minibatch    210  | loss  3.72 | err rate 87.50%\n",
            "Minibatch    220  | loss  3.75 | err rate 96.88%\n",
            "Epoch 7/10, Validation Error Rate: 90.10%\n",
            "Minibatch    230  | loss  3.45 | err rate 87.50%\n",
            "Minibatch    240  | loss  3.30 | err rate 84.38%\n",
            "Minibatch    250  | loss  3.22 | err rate 84.38%\n",
            "Epoch 8/10, Validation Error Rate: 91.37%\n",
            "Minibatch    260  | loss  3.06 | err rate 81.25%\n",
            "Minibatch    270  | loss  3.61 | err rate 96.88%\n",
            "Minibatch    280  | loss  3.29 | err rate 90.62%\n",
            "Epoch 9/10, Validation Error Rate: 90.29%\n",
            "Minibatch    290  | loss  3.31 | err rate 93.75%\n",
            "Minibatch    300  | loss  3.10 | err rate 84.38%\n",
            "Minibatch    310  | loss  3.24 | err rate 90.62%\n",
            "Epoch 10/10, Validation Error Rate: 90.00%\n",
            "Test Error Rate: 91.30%\n",
            "lr:  0.001\n",
            "Minibatch      0  | loss  5.53 | err rate 96.88%\n",
            "Minibatch     10  | loss  5.44 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.61 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.42 | err rate 96.88%\n",
            "Epoch 1/10, Validation Error Rate: 94.90%\n",
            "Minibatch     40  | loss  4.30 | err rate 93.75%\n",
            "Minibatch     50  | loss  3.87 | err rate 93.75%\n",
            "Minibatch     60  | loss  4.16 | err rate 96.88%\n",
            "Epoch 2/10, Validation Error Rate: 90.69%\n",
            "Minibatch     70  | loss  3.80 | err rate 90.62%\n",
            "Minibatch     80  | loss  3.38 | err rate 87.50%\n",
            "Minibatch     90  | loss  3.54 | err rate 84.38%\n",
            "Epoch 3/10, Validation Error Rate: 86.18%\n",
            "Minibatch    100  | loss  3.34 | err rate 78.12%\n",
            "Minibatch    110  | loss  3.05 | err rate 81.25%\n",
            "Minibatch    120  | loss  2.92 | err rate 78.12%\n",
            "Epoch 4/10, Validation Error Rate: 84.02%\n",
            "Minibatch    130  | loss  2.72 | err rate 62.50%\n",
            "Minibatch    140  | loss  2.78 | err rate 68.75%\n",
            "Minibatch    150  | loss  2.72 | err rate 71.88%\n",
            "Epoch 5/10, Validation Error Rate: 80.20%\n",
            "Minibatch    160  | loss  2.57 | err rate 68.75%\n",
            "Minibatch    170  | loss  2.43 | err rate 68.75%\n",
            "Minibatch    180  | loss  2.41 | err rate 65.62%\n",
            "Minibatch    190  | loss  2.18 | err rate 59.38%\n",
            "Epoch 6/10, Validation Error Rate: 77.06%\n",
            "Minibatch    200  | loss  1.93 | err rate 43.75%\n",
            "Minibatch    210  | loss  1.33 | err rate 37.50%\n",
            "Minibatch    220  | loss  1.80 | err rate 50.00%\n",
            "Epoch 7/10, Validation Error Rate: 75.88%\n",
            "Minibatch    230  | loss  1.42 | err rate 34.38%\n",
            "Minibatch    240  | loss  1.72 | err rate 43.75%\n",
            "Minibatch    250  | loss  1.34 | err rate 34.38%\n",
            "Epoch 8/10, Validation Error Rate: 76.27%\n",
            "Minibatch    260  | loss  1.25 | err rate 40.62%\n",
            "Minibatch    270  | loss  1.34 | err rate 40.62%\n",
            "Minibatch    280  | loss  1.58 | err rate 43.75%\n",
            "Epoch 9/10, Validation Error Rate: 76.86%\n",
            "Minibatch    290  | loss  1.08 | err rate 37.50%\n",
            "Minibatch    300  | loss  0.97 | err rate 28.12%\n",
            "Minibatch    310  | loss  1.38 | err rate 34.38%\n",
            "Epoch 10/10, Validation Error Rate: 72.65%\n",
            "Test Error Rate: 76.13%\n",
            "lr:  0.0001\n",
            "Minibatch      0  | loss  5.36 | err rate 96.88%\n",
            "Minibatch     10  | loss  5.10 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.69 | err rate 100.00%\n",
            "Minibatch     30  | loss  4.62 | err rate 93.75%\n",
            "Epoch 1/10, Validation Error Rate: 96.47%\n",
            "Minibatch     40  | loss  4.50 | err rate 93.75%\n",
            "Minibatch     50  | loss  4.30 | err rate 90.62%\n",
            "Minibatch     60  | loss  4.25 | err rate 87.50%\n",
            "Epoch 2/10, Validation Error Rate: 92.75%\n",
            "Minibatch     70  | loss  3.98 | err rate 87.50%\n",
            "Minibatch     80  | loss  3.84 | err rate 84.38%\n",
            "Minibatch     90  | loss  3.85 | err rate 84.38%\n",
            "Epoch 3/10, Validation Error Rate: 88.63%\n",
            "Minibatch    100  | loss  3.55 | err rate 84.38%\n",
            "Minibatch    110  | loss  3.46 | err rate 78.12%\n",
            "Minibatch    120  | loss  3.61 | err rate 84.38%\n",
            "Epoch 4/10, Validation Error Rate: 86.37%\n",
            "Minibatch    130  | loss  3.39 | err rate 75.00%\n",
            "Minibatch    140  | loss  3.41 | err rate 81.25%\n",
            "Minibatch    150  | loss  3.14 | err rate 71.88%\n",
            "Epoch 5/10, Validation Error Rate: 84.02%\n",
            "Minibatch    160  | loss  3.07 | err rate 78.12%\n",
            "Minibatch    170  | loss  2.87 | err rate 62.50%\n",
            "Minibatch    180  | loss  2.55 | err rate 59.38%\n",
            "Minibatch    190  | loss  2.81 | err rate 65.62%\n",
            "Epoch 6/10, Validation Error Rate: 81.08%\n",
            "Minibatch    200  | loss  2.66 | err rate 62.50%\n",
            "Minibatch    210  | loss  2.32 | err rate 62.50%\n",
            "Minibatch    220  | loss  2.15 | err rate 53.12%\n",
            "Epoch 7/10, Validation Error Rate: 80.78%\n",
            "Minibatch    230  | loss  2.33 | err rate 56.25%\n",
            "Minibatch    240  | loss  1.60 | err rate 40.62%\n",
            "Minibatch    250  | loss  1.94 | err rate 43.75%\n",
            "Epoch 8/10, Validation Error Rate: 80.39%\n",
            "Minibatch    260  | loss  1.79 | err rate 37.50%\n",
            "Minibatch    270  | loss  2.37 | err rate 59.38%\n",
            "Minibatch    280  | loss  1.93 | err rate 53.12%\n",
            "Epoch 9/10, Validation Error Rate: 77.55%\n",
            "Minibatch    290  | loss  1.86 | err rate 40.62%\n",
            "Minibatch    300  | loss  2.09 | err rate 53.12%\n",
            "Minibatch    310  | loss  1.69 | err rate 46.88%\n",
            "Epoch 10/10, Validation Error Rate: 77.75%\n",
            "Test Error Rate: 79.41%\n"
          ]
        }
      ],
      "source": [
        "learning_rates = [1e-2, 1e-3, 1e-4]\n",
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"different-learning-rates\",\n",
        "    config={\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": \"[1e-2, 1e-3, 1e-4]\",\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        ")\n",
        "\n",
        "for lr in learning_rates:\n",
        "  print(\"lr: \", lr)\n",
        "  wandb.log({ \"lr\": lr })\n",
        "  model = SimpleConvAndMlp()\n",
        "  with torch.no_grad():\n",
        "      for name, p in model.named_parameters():\n",
        "          if \"weight\" in name and len(p.shape) >= 2:\n",
        "              torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "          elif \"bias\" in name:\n",
        "              p.zero_()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "  train_model(model, flowers102_loaders, optimizer, 10, 'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "PrlxaRcLKEzQ",
        "outputId": "e7fc10bd-db1c-4a8e-a544-ec59e40bfbb3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█▁▂▃▃▄▅▆▆▇█▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>█▂▁</td></tr><tr><td>test/err</td><td>█▁▃</td></tr><tr><td>val/err</td><td>██▇▆▇▆▆▆▆▆▇▆▅▄▃▂▂▂▂▁▇▆▅▅▄▃▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>test/err</td><td>0.79411</td></tr><tr><td>val/err</td><td>77.7451</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">different-learning-rates</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yzi734d5' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yzi734d5</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_085400-yzi734d5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wDToVzudyXjk",
        "outputId": "8f329065-b61b-4224-eede-58e0cfbf95ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>10</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">different-epochs</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/7s1kbld5' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/7s1kbld5</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_090802-7s1kbld5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_091004-kavlb7ta</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/kavlb7ta' target=\"_blank\">different-epochs</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/kavlb7ta' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/kavlb7ta</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs:  10\n",
            "Minibatch      0  | loss  5.50 | err rate 96.88%\n",
            "Minibatch     10  | loss  5.62 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.62 | err rate 93.75%\n",
            "Minibatch     30  | loss  4.54 | err rate 93.75%\n",
            "Epoch 1/10, Validation Error Rate: 92.84%\n",
            "Minibatch     40  | loss  4.00 | err rate 93.75%\n",
            "Minibatch     50  | loss  4.16 | err rate 90.62%\n",
            "Minibatch     60  | loss  3.60 | err rate 81.25%\n",
            "Epoch 2/10, Validation Error Rate: 88.92%\n",
            "Minibatch     70  | loss  3.49 | err rate 87.50%\n",
            "Minibatch     80  | loss  3.69 | err rate 78.12%\n",
            "Minibatch     90  | loss  3.03 | err rate 71.88%\n",
            "Epoch 3/10, Validation Error Rate: 84.51%\n",
            "Minibatch    100  | loss  3.08 | err rate 84.38%\n",
            "Minibatch    110  | loss  3.17 | err rate 81.25%\n",
            "Minibatch    120  | loss  2.85 | err rate 71.88%\n",
            "Epoch 4/10, Validation Error Rate: 82.55%\n",
            "Minibatch    130  | loss  2.76 | err rate 56.25%\n",
            "Minibatch    140  | loss  2.50 | err rate 68.75%\n",
            "Minibatch    150  | loss  2.27 | err rate 62.50%\n",
            "Epoch 5/10, Validation Error Rate: 79.71%\n",
            "Minibatch    160  | loss  2.20 | err rate 50.00%\n",
            "Minibatch    170  | loss  2.53 | err rate 71.88%\n",
            "Minibatch    180  | loss  2.21 | err rate 62.50%\n",
            "Minibatch    190  | loss  2.15 | err rate 62.50%\n",
            "Epoch 6/10, Validation Error Rate: 79.51%\n",
            "Minibatch    200  | loss  1.57 | err rate 34.38%\n",
            "Minibatch    210  | loss  1.54 | err rate 46.88%\n",
            "Minibatch    220  | loss  1.68 | err rate 50.00%\n",
            "Epoch 7/10, Validation Error Rate: 79.12%\n",
            "Minibatch    230  | loss  1.04 | err rate 28.12%\n",
            "Minibatch    240  | loss  1.32 | err rate 25.00%\n",
            "Minibatch    250  | loss  1.29 | err rate 34.38%\n",
            "Epoch 8/10, Validation Error Rate: 77.35%\n",
            "Minibatch    260  | loss  0.95 | err rate 31.25%\n",
            "Minibatch    270  | loss  1.13 | err rate 43.75%\n",
            "Minibatch    280  | loss  0.95 | err rate 31.25%\n",
            "Epoch 9/10, Validation Error Rate: 78.43%\n",
            "Minibatch    290  | loss  0.65 | err rate 12.50%\n",
            "Minibatch    300  | loss  0.61 | err rate 21.88%\n",
            "Minibatch    310  | loss  1.03 | err rate 34.38%\n",
            "Epoch 10/10, Validation Error Rate: 77.65%\n",
            "Test Error Rate: 78.03%\n",
            "epochs:  20\n",
            "Minibatch      0  | loss  6.30 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.08 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.58 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.62 | err rate 96.88%\n",
            "Epoch 1/20, Validation Error Rate: 95.59%\n",
            "Minibatch     40  | loss  4.03 | err rate 93.75%\n",
            "Minibatch     50  | loss  4.25 | err rate 100.00%\n",
            "Minibatch     60  | loss  3.57 | err rate 75.00%\n",
            "Epoch 2/20, Validation Error Rate: 91.08%\n",
            "Minibatch     70  | loss  3.68 | err rate 96.88%\n",
            "Minibatch     80  | loss  3.39 | err rate 81.25%\n",
            "Minibatch     90  | loss  3.95 | err rate 90.62%\n",
            "Epoch 3/20, Validation Error Rate: 88.14%\n",
            "Minibatch    100  | loss  3.02 | err rate 87.50%\n",
            "Minibatch    110  | loss  3.20 | err rate 71.88%\n",
            "Minibatch    120  | loss  3.16 | err rate 84.38%\n",
            "Epoch 4/20, Validation Error Rate: 84.31%\n",
            "Minibatch    130  | loss  2.65 | err rate 71.88%\n",
            "Minibatch    140  | loss  2.63 | err rate 71.88%\n",
            "Minibatch    150  | loss  2.42 | err rate 65.62%\n",
            "Epoch 5/20, Validation Error Rate: 79.80%\n",
            "Minibatch    160  | loss  1.98 | err rate 46.88%\n",
            "Minibatch    170  | loss  1.87 | err rate 50.00%\n",
            "Minibatch    180  | loss  1.84 | err rate 53.12%\n",
            "Minibatch    190  | loss  2.81 | err rate 71.88%\n",
            "Epoch 6/20, Validation Error Rate: 80.10%\n",
            "Minibatch    200  | loss  1.90 | err rate 40.62%\n",
            "Minibatch    210  | loss  1.62 | err rate 37.50%\n",
            "Minibatch    220  | loss  2.44 | err rate 68.75%\n",
            "Epoch 7/20, Validation Error Rate: 78.14%\n",
            "Minibatch    230  | loss  1.46 | err rate 46.88%\n",
            "Minibatch    240  | loss  1.78 | err rate 43.75%\n",
            "Minibatch    250  | loss  2.07 | err rate 65.62%\n",
            "Epoch 8/20, Validation Error Rate: 76.27%\n",
            "Minibatch    260  | loss  0.90 | err rate 25.00%\n",
            "Minibatch    270  | loss  1.19 | err rate 25.00%\n",
            "Minibatch    280  | loss  0.95 | err rate 28.12%\n",
            "Epoch 9/20, Validation Error Rate: 74.41%\n",
            "Minibatch    290  | loss  0.81 | err rate 21.88%\n",
            "Minibatch    300  | loss  1.71 | err rate 50.00%\n",
            "Minibatch    310  | loss  0.86 | err rate 21.88%\n",
            "Epoch 10/20, Validation Error Rate: 75.39%\n",
            "Minibatch    320  | loss  0.43 | err rate 12.50%\n",
            "Minibatch    330  | loss  0.83 | err rate 28.12%\n",
            "Minibatch    340  | loss  0.71 | err rate 21.88%\n",
            "Minibatch    350  | loss  0.86 | err rate 31.25%\n",
            "Epoch 11/20, Validation Error Rate: 75.78%\n",
            "Minibatch    360  | loss  0.43 | err rate 12.50%\n",
            "Minibatch    370  | loss  0.79 | err rate 25.00%\n",
            "Minibatch    380  | loss  0.60 | err rate 18.75%\n",
            "Epoch 12/20, Validation Error Rate: 73.53%\n",
            "Minibatch    390  | loss  0.67 | err rate 21.88%\n",
            "Minibatch    400  | loss  0.52 | err rate 25.00%\n",
            "Minibatch    410  | loss  0.28 | err rate 12.50%\n",
            "Epoch 13/20, Validation Error Rate: 73.63%\n",
            "Minibatch    420  | loss  0.43 | err rate 12.50%\n",
            "Minibatch    430  | loss  0.51 | err rate 18.75%\n",
            "Minibatch    440  | loss  0.28 | err rate  3.12%\n",
            "Epoch 14/20, Validation Error Rate: 72.84%\n",
            "Minibatch    450  | loss  0.15 | err rate  0.00%\n",
            "Minibatch    460  | loss  0.10 | err rate  0.00%\n",
            "Minibatch    470  | loss  0.17 | err rate  6.25%\n",
            "Epoch 15/20, Validation Error Rate: 75.20%\n",
            "Minibatch    480  | loss  0.18 | err rate  3.12%\n",
            "Minibatch    490  | loss  0.21 | err rate  6.25%\n",
            "Minibatch    500  | loss  0.29 | err rate  9.38%\n",
            "Minibatch    510  | loss  0.24 | err rate  6.25%\n",
            "Epoch 16/20, Validation Error Rate: 74.02%\n",
            "Minibatch    520  | loss  0.10 | err rate  3.12%\n",
            "Minibatch    530  | loss  0.34 | err rate  6.25%\n",
            "Minibatch    540  | loss  0.09 | err rate  0.00%\n",
            "Epoch 17/20, Validation Error Rate: 72.75%\n",
            "Minibatch    550  | loss  0.20 | err rate  6.25%\n",
            "Minibatch    560  | loss  0.07 | err rate  3.12%\n",
            "Minibatch    570  | loss  0.02 | err rate  0.00%\n",
            "Epoch 18/20, Validation Error Rate: 74.71%\n",
            "Minibatch    580  | loss  0.19 | err rate  3.12%\n",
            "Minibatch    590  | loss  0.17 | err rate  3.12%\n",
            "Minibatch    600  | loss  0.28 | err rate  9.38%\n",
            "Epoch 19/20, Validation Error Rate: 74.90%\n",
            "Minibatch    610  | loss  0.21 | err rate  3.12%\n",
            "Minibatch    620  | loss  0.43 | err rate 12.50%\n",
            "Minibatch    630  | loss  0.18 | err rate  6.25%\n",
            "Epoch 20/20, Validation Error Rate: 73.92%\n",
            "Test Error Rate: 75.83%\n",
            "epochs:  30\n",
            "Minibatch      0  | loss  5.43 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.24 | err rate 96.88%\n",
            "Minibatch     20  | loss  4.85 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.54 | err rate 100.00%\n",
            "Epoch 1/30, Validation Error Rate: 94.31%\n",
            "Minibatch     40  | loss  4.25 | err rate 93.75%\n",
            "Minibatch     50  | loss  3.69 | err rate 90.62%\n",
            "Minibatch     60  | loss  3.63 | err rate 84.38%\n",
            "Epoch 2/30, Validation Error Rate: 87.25%\n",
            "Minibatch     70  | loss  3.18 | err rate 84.38%\n",
            "Minibatch     80  | loss  3.57 | err rate 87.50%\n",
            "Minibatch     90  | loss  3.19 | err rate 87.50%\n",
            "Epoch 3/30, Validation Error Rate: 85.10%\n",
            "Minibatch    100  | loss  3.14 | err rate 75.00%\n",
            "Minibatch    110  | loss  2.64 | err rate 68.75%\n",
            "Minibatch    120  | loss  2.73 | err rate 65.62%\n",
            "Epoch 4/30, Validation Error Rate: 80.49%\n",
            "Minibatch    130  | loss  2.33 | err rate 50.00%\n",
            "Minibatch    140  | loss  2.16 | err rate 62.50%\n",
            "Minibatch    150  | loss  2.57 | err rate 65.62%\n",
            "Epoch 5/30, Validation Error Rate: 76.76%\n",
            "Minibatch    160  | loss  1.97 | err rate 56.25%\n",
            "Minibatch    170  | loss  2.21 | err rate 62.50%\n",
            "Minibatch    180  | loss  2.04 | err rate 56.25%\n",
            "Minibatch    190  | loss  2.25 | err rate 56.25%\n",
            "Epoch 6/30, Validation Error Rate: 75.49%\n",
            "Minibatch    200  | loss  1.77 | err rate 43.75%\n",
            "Minibatch    210  | loss  1.67 | err rate 53.12%\n",
            "Minibatch    220  | loss  1.42 | err rate 53.12%\n",
            "Epoch 7/30, Validation Error Rate: 75.69%\n",
            "Minibatch    230  | loss  0.87 | err rate 28.12%\n",
            "Minibatch    240  | loss  1.53 | err rate 43.75%\n",
            "Minibatch    250  | loss  1.35 | err rate 31.25%\n",
            "Epoch 8/30, Validation Error Rate: 75.59%\n",
            "Minibatch    260  | loss  1.29 | err rate 46.88%\n",
            "Minibatch    270  | loss  0.90 | err rate 18.75%\n",
            "Minibatch    280  | loss  1.09 | err rate 37.50%\n",
            "Epoch 9/30, Validation Error Rate: 74.51%\n",
            "Minibatch    290  | loss  0.94 | err rate 31.25%\n",
            "Minibatch    300  | loss  1.17 | err rate 34.38%\n",
            "Minibatch    310  | loss  1.23 | err rate 40.62%\n",
            "Epoch 10/30, Validation Error Rate: 73.33%\n",
            "Minibatch    320  | loss  0.23 | err rate  3.12%\n",
            "Minibatch    330  | loss  0.48 | err rate 12.50%\n",
            "Minibatch    340  | loss  0.60 | err rate 25.00%\n",
            "Minibatch    350  | loss  0.56 | err rate 12.50%\n",
            "Epoch 11/30, Validation Error Rate: 71.18%\n",
            "Minibatch    360  | loss  0.46 | err rate 12.50%\n",
            "Minibatch    370  | loss  0.58 | err rate 21.88%\n",
            "Minibatch    380  | loss  0.43 | err rate  6.25%\n",
            "Epoch 12/30, Validation Error Rate: 72.06%\n",
            "Minibatch    390  | loss  0.76 | err rate 18.75%\n",
            "Minibatch    400  | loss  0.28 | err rate  9.38%\n",
            "Minibatch    410  | loss  0.55 | err rate 15.62%\n",
            "Epoch 13/30, Validation Error Rate: 73.63%\n",
            "Minibatch    420  | loss  0.43 | err rate 12.50%\n",
            "Minibatch    430  | loss  0.25 | err rate  6.25%\n",
            "Minibatch    440  | loss  0.77 | err rate 18.75%\n",
            "Epoch 14/30, Validation Error Rate: 71.27%\n",
            "Minibatch    450  | loss  0.14 | err rate  3.12%\n",
            "Minibatch    460  | loss  0.18 | err rate  6.25%\n",
            "Minibatch    470  | loss  0.05 | err rate  0.00%\n",
            "Epoch 15/30, Validation Error Rate: 72.35%\n",
            "Minibatch    480  | loss  0.28 | err rate  9.38%\n",
            "Minibatch    490  | loss  0.13 | err rate  3.12%\n",
            "Minibatch    500  | loss  0.11 | err rate  0.00%\n",
            "Minibatch    510  | loss  0.22 | err rate  3.12%\n",
            "Epoch 16/30, Validation Error Rate: 69.51%\n",
            "Minibatch    520  | loss  0.05 | err rate  0.00%\n",
            "Minibatch    530  | loss  0.11 | err rate  3.12%\n",
            "Minibatch    540  | loss  0.04 | err rate  0.00%\n",
            "Epoch 17/30, Validation Error Rate: 70.49%\n",
            "Minibatch    550  | loss  0.09 | err rate  3.12%\n",
            "Minibatch    560  | loss  0.10 | err rate  0.00%\n",
            "Minibatch    570  | loss  0.24 | err rate  9.38%\n",
            "Epoch 18/30, Validation Error Rate: 70.98%\n",
            "Minibatch    580  | loss  0.11 | err rate  0.00%\n",
            "Minibatch    590  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    600  | loss  0.17 | err rate  6.25%\n",
            "Epoch 19/30, Validation Error Rate: 72.25%\n",
            "Minibatch    610  | loss  0.05 | err rate  0.00%\n",
            "Minibatch    620  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    630  | loss  0.05 | err rate  0.00%\n",
            "Epoch 20/30, Validation Error Rate: 69.80%\n",
            "Minibatch    640  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    650  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    660  | loss  0.03 | err rate  0.00%\n",
            "Minibatch    670  | loss  0.00 | err rate  0.00%\n",
            "Epoch 21/30, Validation Error Rate: 68.43%\n",
            "Minibatch    680  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    690  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    700  | loss  0.06 | err rate  3.12%\n",
            "Epoch 22/30, Validation Error Rate: 69.71%\n",
            "Minibatch    710  | loss  0.30 | err rate  6.25%\n",
            "Minibatch    720  | loss  0.06 | err rate  3.12%\n",
            "Minibatch    730  | loss  0.01 | err rate  0.00%\n",
            "Epoch 23/30, Validation Error Rate: 71.27%\n",
            "Minibatch    740  | loss  0.12 | err rate  3.12%\n",
            "Minibatch    750  | loss  0.06 | err rate  3.12%\n",
            "Minibatch    760  | loss  0.03 | err rate  0.00%\n",
            "Epoch 24/30, Validation Error Rate: 71.08%\n",
            "Minibatch    770  | loss  0.05 | err rate  0.00%\n",
            "Minibatch    780  | loss  0.19 | err rate  3.12%\n",
            "Minibatch    790  | loss  0.01 | err rate  0.00%\n",
            "Epoch 25/30, Validation Error Rate: 70.39%\n",
            "Minibatch    800  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    810  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    820  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    830  | loss  0.04 | err rate  0.00%\n",
            "Epoch 26/30, Validation Error Rate: 70.00%\n",
            "Minibatch    840  | loss  0.06 | err rate  3.12%\n",
            "Minibatch    850  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    860  | loss  0.07 | err rate  0.00%\n",
            "Epoch 27/30, Validation Error Rate: 70.69%\n",
            "Minibatch    870  | loss  0.09 | err rate  3.12%\n",
            "Minibatch    880  | loss  0.03 | err rate  0.00%\n",
            "Minibatch    890  | loss  0.16 | err rate  3.12%\n",
            "Epoch 28/30, Validation Error Rate: 69.61%\n",
            "Minibatch    900  | loss  0.09 | err rate  6.25%\n",
            "Minibatch    910  | loss  0.08 | err rate  3.12%\n",
            "Minibatch    920  | loss  0.01 | err rate  0.00%\n",
            "Epoch 29/30, Validation Error Rate: 70.39%\n",
            "Minibatch    930  | loss  0.03 | err rate  0.00%\n",
            "Minibatch    940  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    950  | loss  0.01 | err rate  0.00%\n",
            "Epoch 30/30, Validation Error Rate: 71.18%\n",
            "Test Error Rate: 74.09%\n",
            "epochs:  40\n",
            "Minibatch      0  | loss  6.18 | err rate 100.00%\n",
            "Minibatch     10  | loss  4.87 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.71 | err rate 100.00%\n",
            "Minibatch     30  | loss  4.62 | err rate 100.00%\n",
            "Epoch 1/40, Validation Error Rate: 97.65%\n",
            "Minibatch     40  | loss  3.81 | err rate 90.62%\n",
            "Minibatch     50  | loss  3.86 | err rate 93.75%\n",
            "Minibatch     60  | loss  4.10 | err rate 96.88%\n",
            "Epoch 2/40, Validation Error Rate: 92.75%\n",
            "Minibatch     70  | loss  3.90 | err rate 90.62%\n",
            "Minibatch     80  | loss  3.18 | err rate 84.38%\n",
            "Minibatch     90  | loss  3.51 | err rate 93.75%\n",
            "Epoch 3/40, Validation Error Rate: 86.18%\n",
            "Minibatch    100  | loss  2.97 | err rate 68.75%\n",
            "Minibatch    110  | loss  2.79 | err rate 75.00%\n",
            "Minibatch    120  | loss  3.13 | err rate 75.00%\n",
            "Epoch 4/40, Validation Error Rate: 85.00%\n",
            "Minibatch    130  | loss  2.36 | err rate 68.75%\n",
            "Minibatch    140  | loss  2.69 | err rate 81.25%\n",
            "Minibatch    150  | loss  3.06 | err rate 84.38%\n",
            "Epoch 5/40, Validation Error Rate: 81.86%\n",
            "Minibatch    160  | loss  2.75 | err rate 75.00%\n",
            "Minibatch    170  | loss  2.09 | err rate 56.25%\n",
            "Minibatch    180  | loss  2.70 | err rate 68.75%\n",
            "Minibatch    190  | loss  2.13 | err rate 46.88%\n",
            "Epoch 6/40, Validation Error Rate: 79.90%\n",
            "Minibatch    200  | loss  1.79 | err rate 53.12%\n",
            "Minibatch    210  | loss  1.56 | err rate 56.25%\n",
            "Minibatch    220  | loss  2.18 | err rate 53.12%\n",
            "Epoch 7/40, Validation Error Rate: 78.14%\n",
            "Minibatch    230  | loss  1.13 | err rate 25.00%\n",
            "Minibatch    240  | loss  1.67 | err rate 40.62%\n",
            "Minibatch    250  | loss  1.93 | err rate 46.88%\n",
            "Epoch 8/40, Validation Error Rate: 77.65%\n",
            "Minibatch    260  | loss  1.53 | err rate 40.62%\n",
            "Minibatch    270  | loss  1.45 | err rate 37.50%\n",
            "Minibatch    280  | loss  1.10 | err rate 37.50%\n",
            "Epoch 9/40, Validation Error Rate: 77.65%\n",
            "Minibatch    290  | loss  0.92 | err rate 31.25%\n",
            "Minibatch    300  | loss  1.11 | err rate 40.62%\n",
            "Minibatch    310  | loss  0.89 | err rate 31.25%\n",
            "Epoch 10/40, Validation Error Rate: 75.59%\n",
            "Minibatch    320  | loss  0.56 | err rate 15.62%\n",
            "Minibatch    330  | loss  0.82 | err rate 25.00%\n",
            "Minibatch    340  | loss  0.79 | err rate 15.62%\n",
            "Minibatch    350  | loss  0.55 | err rate 15.62%\n",
            "Epoch 11/40, Validation Error Rate: 74.61%\n",
            "Minibatch    360  | loss  0.59 | err rate 15.62%\n",
            "Minibatch    370  | loss  0.38 | err rate  9.38%\n",
            "Minibatch    380  | loss  0.65 | err rate 18.75%\n",
            "Epoch 12/40, Validation Error Rate: 75.49%\n",
            "Minibatch    390  | loss  0.23 | err rate  9.38%\n",
            "Minibatch    400  | loss  0.53 | err rate 15.62%\n",
            "Minibatch    410  | loss  0.23 | err rate  3.12%\n",
            "Epoch 13/40, Validation Error Rate: 74.71%\n",
            "Minibatch    420  | loss  0.33 | err rate 12.50%\n",
            "Minibatch    430  | loss  0.21 | err rate  3.12%\n",
            "Minibatch    440  | loss  0.46 | err rate 15.62%\n",
            "Epoch 14/40, Validation Error Rate: 74.12%\n",
            "Minibatch    450  | loss  0.38 | err rate 12.50%\n",
            "Minibatch    460  | loss  0.21 | err rate  6.25%\n",
            "Minibatch    470  | loss  0.31 | err rate  9.38%\n",
            "Epoch 15/40, Validation Error Rate: 76.37%\n",
            "Minibatch    480  | loss  0.19 | err rate  6.25%\n",
            "Minibatch    490  | loss  0.36 | err rate  9.38%\n",
            "Minibatch    500  | loss  0.11 | err rate  6.25%\n",
            "Minibatch    510  | loss  0.15 | err rate  6.25%\n",
            "Epoch 16/40, Validation Error Rate: 74.31%\n",
            "Minibatch    520  | loss  0.22 | err rate  3.12%\n",
            "Minibatch    530  | loss  0.08 | err rate  0.00%\n",
            "Minibatch    540  | loss  0.36 | err rate  9.38%\n",
            "Epoch 17/40, Validation Error Rate: 72.75%\n",
            "Minibatch    550  | loss  0.06 | err rate  3.12%\n",
            "Minibatch    560  | loss  0.11 | err rate  3.12%\n",
            "Minibatch    570  | loss  0.11 | err rate  3.12%\n",
            "Epoch 18/40, Validation Error Rate: 73.63%\n",
            "Minibatch    580  | loss  0.05 | err rate  3.12%\n",
            "Minibatch    590  | loss  0.11 | err rate  3.12%\n",
            "Minibatch    600  | loss  0.19 | err rate  6.25%\n",
            "Epoch 19/40, Validation Error Rate: 72.65%\n",
            "Minibatch    610  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    620  | loss  0.21 | err rate  6.25%\n",
            "Minibatch    630  | loss  0.06 | err rate  0.00%\n",
            "Epoch 20/40, Validation Error Rate: 71.86%\n",
            "Minibatch    640  | loss  0.03 | err rate  0.00%\n",
            "Minibatch    650  | loss  0.06 | err rate  3.12%\n",
            "Minibatch    660  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    670  | loss  0.08 | err rate  3.12%\n",
            "Epoch 21/40, Validation Error Rate: 75.98%\n",
            "Minibatch    680  | loss  0.11 | err rate  6.25%\n",
            "Minibatch    690  | loss  0.06 | err rate  0.00%\n",
            "Minibatch    700  | loss  0.12 | err rate  3.12%\n",
            "Epoch 22/40, Validation Error Rate: 72.35%\n",
            "Minibatch    710  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    720  | loss  0.09 | err rate  3.12%\n",
            "Minibatch    730  | loss  0.09 | err rate  3.12%\n",
            "Epoch 23/40, Validation Error Rate: 71.27%\n",
            "Minibatch    740  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    750  | loss  0.22 | err rate  9.38%\n",
            "Minibatch    760  | loss  0.19 | err rate  6.25%\n",
            "Epoch 24/40, Validation Error Rate: 73.82%\n",
            "Minibatch    770  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    780  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    790  | loss  0.02 | err rate  0.00%\n",
            "Epoch 25/40, Validation Error Rate: 73.24%\n",
            "Minibatch    800  | loss  0.12 | err rate  3.12%\n",
            "Minibatch    810  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    820  | loss  0.10 | err rate  3.12%\n",
            "Minibatch    830  | loss  0.10 | err rate  3.12%\n",
            "Epoch 26/40, Validation Error Rate: 72.45%\n",
            "Minibatch    840  | loss  0.04 | err rate  3.12%\n",
            "Minibatch    850  | loss  0.08 | err rate  6.25%\n",
            "Minibatch    860  | loss  0.01 | err rate  0.00%\n",
            "Epoch 27/40, Validation Error Rate: 74.61%\n",
            "Minibatch    870  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    880  | loss  0.09 | err rate  3.12%\n",
            "Minibatch    890  | loss  0.01 | err rate  0.00%\n",
            "Epoch 28/40, Validation Error Rate: 72.25%\n",
            "Minibatch    900  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    910  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    920  | loss  0.01 | err rate  0.00%\n",
            "Epoch 29/40, Validation Error Rate: 71.18%\n",
            "Minibatch    930  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    940  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    950  | loss  0.15 | err rate  6.25%\n",
            "Epoch 30/40, Validation Error Rate: 72.84%\n",
            "Minibatch    960  | loss  0.03 | err rate  0.00%\n",
            "Minibatch    970  | loss  0.29 | err rate 12.50%\n",
            "Minibatch    980  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    990  | loss  0.26 | err rate  9.38%\n",
            "Epoch 31/40, Validation Error Rate: 73.63%\n",
            "Minibatch   1000  | loss  0.06 | err rate  0.00%\n",
            "Minibatch   1010  | loss  0.08 | err rate  6.25%\n",
            "Minibatch   1020  | loss  0.12 | err rate  6.25%\n",
            "Epoch 32/40, Validation Error Rate: 73.43%\n",
            "Minibatch   1030  | loss  0.10 | err rate  3.12%\n",
            "Minibatch   1040  | loss  0.48 | err rate  6.25%\n",
            "Minibatch   1050  | loss  0.31 | err rate 15.62%\n",
            "Epoch 33/40, Validation Error Rate: 73.14%\n",
            "Minibatch   1060  | loss  0.04 | err rate  0.00%\n",
            "Minibatch   1070  | loss  0.05 | err rate  3.12%\n",
            "Minibatch   1080  | loss  0.13 | err rate  3.12%\n",
            "Epoch 34/40, Validation Error Rate: 75.88%\n",
            "Minibatch   1090  | loss  0.12 | err rate  6.25%\n",
            "Minibatch   1100  | loss  0.12 | err rate  6.25%\n",
            "Minibatch   1110  | loss  0.10 | err rate  0.00%\n",
            "Epoch 35/40, Validation Error Rate: 71.96%\n",
            "Minibatch   1120  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1130  | loss  0.03 | err rate  0.00%\n",
            "Minibatch   1140  | loss  0.05 | err rate  0.00%\n",
            "Minibatch   1150  | loss  0.08 | err rate  3.12%\n",
            "Epoch 36/40, Validation Error Rate: 72.35%\n",
            "Minibatch   1160  | loss  0.11 | err rate  3.12%\n",
            "Minibatch   1170  | loss  0.03 | err rate  0.00%\n",
            "Minibatch   1180  | loss  0.02 | err rate  0.00%\n",
            "Epoch 37/40, Validation Error Rate: 74.41%\n",
            "Minibatch   1190  | loss  0.09 | err rate  3.12%\n",
            "Minibatch   1200  | loss  0.02 | err rate  0.00%\n",
            "Minibatch   1210  | loss  0.02 | err rate  0.00%\n",
            "Epoch 38/40, Validation Error Rate: 72.45%\n",
            "Minibatch   1220  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1230  | loss  0.05 | err rate  3.12%\n",
            "Minibatch   1240  | loss  0.09 | err rate  3.12%\n",
            "Epoch 39/40, Validation Error Rate: 72.65%\n",
            "Minibatch   1250  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1260  | loss  0.06 | err rate  3.12%\n",
            "Minibatch   1270  | loss  0.01 | err rate  0.00%\n",
            "Epoch 40/40, Validation Error Rate: 71.76%\n",
            "Test Error Rate: 74.86%\n",
            "epochs:  50\n",
            "Minibatch      0  | loss  6.08 | err rate 96.88%\n",
            "Minibatch     10  | loss  5.51 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.64 | err rate 93.75%\n",
            "Minibatch     30  | loss  4.42 | err rate 100.00%\n",
            "Epoch 1/50, Validation Error Rate: 96.86%\n",
            "Minibatch     40  | loss  4.43 | err rate 93.75%\n",
            "Minibatch     50  | loss  3.94 | err rate 93.75%\n",
            "Minibatch     60  | loss  4.51 | err rate 93.75%\n",
            "Epoch 2/50, Validation Error Rate: 90.59%\n",
            "Minibatch     70  | loss  3.47 | err rate 81.25%\n",
            "Minibatch     80  | loss  3.44 | err rate 84.38%\n",
            "Minibatch     90  | loss  3.27 | err rate 75.00%\n",
            "Epoch 3/50, Validation Error Rate: 88.43%\n",
            "Minibatch    100  | loss  3.42 | err rate 84.38%\n",
            "Minibatch    110  | loss  3.35 | err rate 81.25%\n",
            "Minibatch    120  | loss  3.11 | err rate 90.62%\n",
            "Epoch 4/50, Validation Error Rate: 84.90%\n",
            "Minibatch    130  | loss  2.55 | err rate 71.88%\n",
            "Minibatch    140  | loss  3.15 | err rate 71.88%\n",
            "Minibatch    150  | loss  2.35 | err rate 59.38%\n",
            "Epoch 5/50, Validation Error Rate: 81.76%\n",
            "Minibatch    160  | loss  1.65 | err rate 43.75%\n",
            "Minibatch    170  | loss  2.22 | err rate 53.12%\n",
            "Minibatch    180  | loss  2.59 | err rate 68.75%\n",
            "Minibatch    190  | loss  2.41 | err rate 71.88%\n",
            "Epoch 6/50, Validation Error Rate: 80.49%\n",
            "Minibatch    200  | loss  2.12 | err rate 59.38%\n",
            "Minibatch    210  | loss  2.15 | err rate 59.38%\n",
            "Minibatch    220  | loss  2.42 | err rate 65.62%\n",
            "Epoch 7/50, Validation Error Rate: 80.20%\n",
            "Minibatch    230  | loss  1.80 | err rate 62.50%\n",
            "Minibatch    240  | loss  0.94 | err rate 21.88%\n",
            "Minibatch    250  | loss  1.68 | err rate 53.12%\n",
            "Epoch 8/50, Validation Error Rate: 75.88%\n",
            "Minibatch    260  | loss  1.79 | err rate 50.00%\n",
            "Minibatch    270  | loss  1.36 | err rate 34.38%\n",
            "Minibatch    280  | loss  1.43 | err rate 46.88%\n",
            "Epoch 9/50, Validation Error Rate: 77.84%\n",
            "Minibatch    290  | loss  0.97 | err rate 25.00%\n",
            "Minibatch    300  | loss  0.90 | err rate 37.50%\n",
            "Minibatch    310  | loss  1.30 | err rate 40.62%\n",
            "Epoch 10/50, Validation Error Rate: 77.35%\n",
            "Minibatch    320  | loss  0.81 | err rate 25.00%\n",
            "Minibatch    330  | loss  0.72 | err rate 21.88%\n",
            "Minibatch    340  | loss  1.26 | err rate 43.75%\n",
            "Minibatch    350  | loss  0.67 | err rate 21.88%\n",
            "Epoch 11/50, Validation Error Rate: 77.16%\n",
            "Minibatch    360  | loss  0.75 | err rate 18.75%\n",
            "Minibatch    370  | loss  0.85 | err rate 25.00%\n",
            "Minibatch    380  | loss  0.75 | err rate 28.12%\n",
            "Epoch 12/50, Validation Error Rate: 76.18%\n",
            "Minibatch    390  | loss  0.41 | err rate  9.38%\n",
            "Minibatch    400  | loss  0.36 | err rate 12.50%\n",
            "Minibatch    410  | loss  0.78 | err rate 25.00%\n",
            "Epoch 13/50, Validation Error Rate: 74.41%\n",
            "Minibatch    420  | loss  0.12 | err rate  0.00%\n",
            "Minibatch    430  | loss  0.31 | err rate  6.25%\n",
            "Minibatch    440  | loss  0.38 | err rate 12.50%\n",
            "Epoch 14/50, Validation Error Rate: 74.02%\n",
            "Minibatch    450  | loss  0.52 | err rate 18.75%\n",
            "Minibatch    460  | loss  0.24 | err rate  3.12%\n",
            "Minibatch    470  | loss  0.37 | err rate 15.62%\n",
            "Epoch 15/50, Validation Error Rate: 76.27%\n",
            "Minibatch    480  | loss  0.12 | err rate  3.12%\n",
            "Minibatch    490  | loss  0.17 | err rate  0.00%\n",
            "Minibatch    500  | loss  0.14 | err rate  6.25%\n",
            "Minibatch    510  | loss  0.16 | err rate  3.12%\n",
            "Epoch 16/50, Validation Error Rate: 76.08%\n",
            "Minibatch    520  | loss  0.10 | err rate  3.12%\n",
            "Minibatch    530  | loss  0.10 | err rate  3.12%\n",
            "Minibatch    540  | loss  0.26 | err rate  9.38%\n",
            "Epoch 17/50, Validation Error Rate: 73.73%\n",
            "Minibatch    550  | loss  0.13 | err rate  3.12%\n",
            "Minibatch    560  | loss  0.15 | err rate  3.12%\n",
            "Minibatch    570  | loss  0.39 | err rate 12.50%\n",
            "Epoch 18/50, Validation Error Rate: 75.69%\n",
            "Minibatch    580  | loss  0.13 | err rate  3.12%\n",
            "Minibatch    590  | loss  0.06 | err rate  0.00%\n",
            "Minibatch    600  | loss  0.12 | err rate  3.12%\n",
            "Epoch 19/50, Validation Error Rate: 74.80%\n",
            "Minibatch    610  | loss  0.13 | err rate  6.25%\n",
            "Minibatch    620  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    630  | loss  0.12 | err rate  3.12%\n",
            "Epoch 20/50, Validation Error Rate: 74.02%\n",
            "Minibatch    640  | loss  0.05 | err rate  0.00%\n",
            "Minibatch    650  | loss  0.36 | err rate  6.25%\n",
            "Minibatch    660  | loss  0.13 | err rate  3.12%\n",
            "Minibatch    670  | loss  0.04 | err rate  0.00%\n",
            "Epoch 21/50, Validation Error Rate: 75.00%\n",
            "Minibatch    680  | loss  0.09 | err rate  0.00%\n",
            "Minibatch    690  | loss  0.13 | err rate  6.25%\n",
            "Minibatch    700  | loss  0.02 | err rate  0.00%\n",
            "Epoch 22/50, Validation Error Rate: 75.00%\n",
            "Minibatch    710  | loss  0.06 | err rate  0.00%\n",
            "Minibatch    720  | loss  0.11 | err rate  3.12%\n",
            "Minibatch    730  | loss  0.09 | err rate  3.12%\n",
            "Epoch 23/50, Validation Error Rate: 75.49%\n",
            "Minibatch    740  | loss  0.07 | err rate  0.00%\n",
            "Minibatch    750  | loss  0.09 | err rate  6.25%\n",
            "Minibatch    760  | loss  0.09 | err rate  3.12%\n",
            "Epoch 24/50, Validation Error Rate: 73.14%\n",
            "Minibatch    770  | loss  0.25 | err rate  6.25%\n",
            "Minibatch    780  | loss  0.20 | err rate  3.12%\n",
            "Minibatch    790  | loss  0.07 | err rate  3.12%\n",
            "Epoch 25/50, Validation Error Rate: 74.02%\n",
            "Minibatch    800  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    810  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    820  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    830  | loss  0.25 | err rate 12.50%\n",
            "Epoch 26/50, Validation Error Rate: 73.24%\n",
            "Minibatch    840  | loss  0.05 | err rate  3.12%\n",
            "Minibatch    850  | loss  0.02 | err rate  0.00%\n",
            "Minibatch    860  | loss  0.01 | err rate  0.00%\n",
            "Epoch 27/50, Validation Error Rate: 74.51%\n",
            "Minibatch    870  | loss  0.07 | err rate  0.00%\n",
            "Minibatch    880  | loss  0.23 | err rate  9.38%\n",
            "Minibatch    890  | loss  0.17 | err rate  3.12%\n",
            "Epoch 28/50, Validation Error Rate: 75.69%\n",
            "Minibatch    900  | loss  0.13 | err rate  6.25%\n",
            "Minibatch    910  | loss  0.04 | err rate  0.00%\n",
            "Minibatch    920  | loss  0.18 | err rate  3.12%\n",
            "Epoch 29/50, Validation Error Rate: 75.88%\n",
            "Minibatch    930  | loss  0.08 | err rate  6.25%\n",
            "Minibatch    940  | loss  0.08 | err rate  3.12%\n",
            "Minibatch    950  | loss  0.03 | err rate  0.00%\n",
            "Epoch 30/50, Validation Error Rate: 76.96%\n",
            "Minibatch    960  | loss  0.25 | err rate  3.12%\n",
            "Minibatch    970  | loss  0.01 | err rate  0.00%\n",
            "Minibatch    980  | loss  0.12 | err rate  6.25%\n",
            "Minibatch    990  | loss  0.04 | err rate  0.00%\n",
            "Epoch 31/50, Validation Error Rate: 75.59%\n",
            "Minibatch   1000  | loss  0.40 | err rate  9.38%\n",
            "Minibatch   1010  | loss  0.17 | err rate  3.12%\n",
            "Minibatch   1020  | loss  0.15 | err rate  3.12%\n",
            "Epoch 32/50, Validation Error Rate: 79.41%\n",
            "Minibatch   1030  | loss  0.05 | err rate  3.12%\n",
            "Minibatch   1040  | loss  0.12 | err rate  3.12%\n",
            "Minibatch   1050  | loss  0.25 | err rate 12.50%\n",
            "Epoch 33/50, Validation Error Rate: 76.57%\n",
            "Minibatch   1060  | loss  0.10 | err rate  3.12%\n",
            "Minibatch   1070  | loss  0.03 | err rate  0.00%\n",
            "Minibatch   1080  | loss  0.13 | err rate  3.12%\n",
            "Epoch 34/50, Validation Error Rate: 75.29%\n",
            "Minibatch   1090  | loss  0.09 | err rate  0.00%\n",
            "Minibatch   1100  | loss  0.24 | err rate  6.25%\n",
            "Minibatch   1110  | loss  0.07 | err rate  0.00%\n",
            "Epoch 35/50, Validation Error Rate: 75.29%\n",
            "Minibatch   1120  | loss  0.02 | err rate  0.00%\n",
            "Minibatch   1130  | loss  0.04 | err rate  0.00%\n",
            "Minibatch   1140  | loss  0.20 | err rate 12.50%\n",
            "Minibatch   1150  | loss  0.14 | err rate  3.12%\n",
            "Epoch 36/50, Validation Error Rate: 75.10%\n",
            "Minibatch   1160  | loss  0.14 | err rate  6.25%\n",
            "Minibatch   1170  | loss  0.13 | err rate  6.25%\n",
            "Minibatch   1180  | loss  0.12 | err rate  3.12%\n",
            "Epoch 37/50, Validation Error Rate: 74.71%\n",
            "Minibatch   1190  | loss  0.19 | err rate  3.12%\n",
            "Minibatch   1200  | loss  0.02 | err rate  0.00%\n",
            "Minibatch   1210  | loss  0.01 | err rate  0.00%\n",
            "Epoch 38/50, Validation Error Rate: 75.39%\n",
            "Minibatch   1220  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1230  | loss  0.04 | err rate  0.00%\n",
            "Minibatch   1240  | loss  0.00 | err rate  0.00%\n",
            "Epoch 39/50, Validation Error Rate: 75.29%\n",
            "Minibatch   1250  | loss  0.03 | err rate  0.00%\n",
            "Minibatch   1260  | loss  0.03 | err rate  0.00%\n",
            "Minibatch   1270  | loss  0.02 | err rate  0.00%\n",
            "Epoch 40/50, Validation Error Rate: 74.71%\n",
            "Minibatch   1280  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1290  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1300  | loss  0.01 | err rate  0.00%\n",
            "Minibatch   1310  | loss  0.00 | err rate  0.00%\n",
            "Epoch 41/50, Validation Error Rate: 74.41%\n",
            "Minibatch   1320  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1330  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1340  | loss  0.00 | err rate  0.00%\n",
            "Epoch 42/50, Validation Error Rate: 74.12%\n",
            "Minibatch   1350  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1360  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1370  | loss  0.00 | err rate  0.00%\n",
            "Epoch 43/50, Validation Error Rate: 73.73%\n",
            "Minibatch   1380  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1390  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1400  | loss  0.00 | err rate  0.00%\n",
            "Epoch 44/50, Validation Error Rate: 73.82%\n",
            "Minibatch   1410  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1420  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1430  | loss  0.00 | err rate  0.00%\n",
            "Epoch 45/50, Validation Error Rate: 73.63%\n",
            "Minibatch   1440  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1450  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1460  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1470  | loss  0.00 | err rate  0.00%\n",
            "Epoch 46/50, Validation Error Rate: 73.73%\n",
            "Minibatch   1480  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1490  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1500  | loss  0.00 | err rate  0.00%\n",
            "Epoch 47/50, Validation Error Rate: 73.73%\n",
            "Minibatch   1510  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1520  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1530  | loss  0.00 | err rate  0.00%\n",
            "Epoch 48/50, Validation Error Rate: 73.53%\n",
            "Minibatch   1540  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1550  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1560  | loss  0.00 | err rate  0.00%\n",
            "Epoch 49/50, Validation Error Rate: 73.53%\n",
            "Minibatch   1570  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1580  | loss  0.00 | err rate  0.00%\n",
            "Minibatch   1590  | loss  0.00 | err rate  0.00%\n",
            "Epoch 50/50, Validation Error Rate: 73.53%\n",
            "Test Error Rate: 75.39%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▁▂▃▃▄▁▂▃▃▃▄▄▅▅▁▁▁▃▃▄▄▅▅▆▆▁▂▃▃▄▄▄▆▆▇▇█</td></tr><tr><td>epochs</td><td>▁▃▅▆█</td></tr><tr><td>test/err</td><td>█▄▁▂▃</td></tr><tr><td>val/err</td><td>█▄▃▄▄▃▂▂▃█▃▂▁▂▂▁▆▅▃▃▂▂▅▄▃▃▃▂▃▃▄▃▃▃▃▃▃▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>epochs</td><td>50</td></tr><tr><td>test/err</td><td>0.75394</td></tr><tr><td>val/err</td><td>73.52941</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">different-epochs</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/kavlb7ta' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/kavlb7ta</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_091004-kavlb7ta/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs_list = [10,20,30,40,50]\n",
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"different-epochs\",\n",
        "    config={\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 1e-3,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"epochs\": \"10-50\",\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "for epochs in num_epochs_list:\n",
        "  print(\"epochs: \", epochs)\n",
        "  wandb.log({ \"epochs\": epochs})\n",
        "  model = SimpleConvAndMlp()\n",
        "  with torch.no_grad():\n",
        "      for name, p in model.named_parameters():\n",
        "          if \"weight\" in name and len(p.shape) >= 2:\n",
        "              torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "          elif \"bias\" in name:\n",
        "              p.zero_()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "  train_model(model, flowers102_loaders, optimizer, epochs, 'cuda')\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U4eNXn13MhSx",
        "outputId": "3cfa1227-ee3a-4fb3-b6e1-77bb9040127b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_094244-yrxtpdmt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yrxtpdmt' target=\"_blank\">different-batch-sizes</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yrxtpdmt' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yrxtpdmt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch size:  16\n",
            "Minibatch      0  | loss  6.15 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.59 | err rate 100.00%\n",
            "Minibatch     20  | loss  5.26 | err rate 100.00%\n",
            "Minibatch     30  | loss  4.54 | err rate 100.00%\n",
            "Minibatch     40  | loss  4.75 | err rate 100.00%\n",
            "Minibatch     50  | loss  4.77 | err rate 100.00%\n",
            "Minibatch     60  | loss  4.66 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 97.65%\n",
            "Minibatch     70  | loss  4.27 | err rate 100.00%\n",
            "Minibatch     80  | loss  4.47 | err rate 100.00%\n",
            "Minibatch     90  | loss  4.45 | err rate 100.00%\n",
            "Minibatch    100  | loss  4.46 | err rate 100.00%\n",
            "Minibatch    110  | loss  4.26 | err rate 93.75%\n",
            "Minibatch    120  | loss  4.21 | err rate 100.00%\n",
            "Epoch 2/10, Validation Error Rate: 92.94%\n",
            "Minibatch    130  | loss  3.61 | err rate 75.00%\n",
            "Minibatch    140  | loss  4.30 | err rate 93.75%\n",
            "Minibatch    150  | loss  3.55 | err rate 81.25%\n",
            "Minibatch    160  | loss  3.77 | err rate 93.75%\n",
            "Minibatch    170  | loss  3.47 | err rate 75.00%\n",
            "Minibatch    180  | loss  3.18 | err rate 75.00%\n",
            "Minibatch    190  | loss  3.32 | err rate 81.25%\n",
            "Epoch 3/10, Validation Error Rate: 86.18%\n",
            "Minibatch    200  | loss  2.70 | err rate 68.75%\n",
            "Minibatch    210  | loss  3.19 | err rate 81.25%\n",
            "Minibatch    220  | loss  3.44 | err rate 75.00%\n",
            "Minibatch    230  | loss  3.08 | err rate 87.50%\n",
            "Minibatch    240  | loss  3.25 | err rate 93.75%\n",
            "Minibatch    250  | loss  3.42 | err rate 81.25%\n",
            "Epoch 4/10, Validation Error Rate: 83.53%\n",
            "Minibatch    260  | loss  2.51 | err rate 75.00%\n",
            "Minibatch    270  | loss  2.78 | err rate 68.75%\n",
            "Minibatch    280  | loss  2.17 | err rate 50.00%\n",
            "Minibatch    290  | loss  2.50 | err rate 75.00%\n",
            "Minibatch    300  | loss  2.51 | err rate 81.25%\n",
            "Minibatch    310  | loss  2.37 | err rate 62.50%\n",
            "Epoch 5/10, Validation Error Rate: 80.88%\n",
            "Minibatch    320  | loss  2.25 | err rate 62.50%\n",
            "Minibatch    330  | loss  1.77 | err rate 50.00%\n",
            "Minibatch    340  | loss  1.69 | err rate 50.00%\n",
            "Minibatch    350  | loss  1.88 | err rate 62.50%\n",
            "Minibatch    360  | loss  1.91 | err rate 50.00%\n",
            "Minibatch    370  | loss  2.32 | err rate 50.00%\n",
            "Minibatch    380  | loss  1.91 | err rate 56.25%\n",
            "Epoch 6/10, Validation Error Rate: 77.45%\n",
            "Minibatch    390  | loss  2.12 | err rate 62.50%\n",
            "Minibatch    400  | loss  1.67 | err rate 37.50%\n",
            "Minibatch    410  | loss  2.55 | err rate 68.75%\n",
            "Minibatch    420  | loss  1.58 | err rate 50.00%\n",
            "Minibatch    430  | loss  2.85 | err rate 62.50%\n",
            "Minibatch    440  | loss  2.02 | err rate 56.25%\n",
            "Epoch 7/10, Validation Error Rate: 74.61%\n",
            "Minibatch    450  | loss  0.93 | err rate 25.00%\n",
            "Minibatch    460  | loss  1.77 | err rate 50.00%\n",
            "Minibatch    470  | loss  1.15 | err rate 37.50%\n",
            "Minibatch    480  | loss  1.07 | err rate 25.00%\n",
            "Minibatch    490  | loss  1.39 | err rate 37.50%\n",
            "Minibatch    500  | loss  1.90 | err rate 62.50%\n",
            "Minibatch    510  | loss  1.62 | err rate 56.25%\n",
            "Epoch 8/10, Validation Error Rate: 74.22%\n",
            "Minibatch    520  | loss  0.72 | err rate 12.50%\n",
            "Minibatch    530  | loss  1.06 | err rate 25.00%\n",
            "Minibatch    540  | loss  0.99 | err rate 37.50%\n",
            "Minibatch    550  | loss  1.57 | err rate 43.75%\n",
            "Minibatch    560  | loss  1.83 | err rate 43.75%\n",
            "Minibatch    570  | loss  2.05 | err rate 62.50%\n",
            "Epoch 9/10, Validation Error Rate: 76.86%\n",
            "Minibatch    580  | loss  1.17 | err rate 37.50%\n",
            "Minibatch    590  | loss  0.75 | err rate 18.75%\n",
            "Minibatch    600  | loss  1.05 | err rate 18.75%\n",
            "Minibatch    610  | loss  0.89 | err rate 31.25%\n",
            "Minibatch    620  | loss  0.73 | err rate 25.00%\n",
            "Minibatch    630  | loss  0.80 | err rate 25.00%\n",
            "Epoch 10/10, Validation Error Rate: 76.08%\n",
            "Test Error Rate: 75.65%\n",
            "batch size:  32\n",
            "Minibatch      0  | loss  5.95 | err rate 100.00%\n",
            "Minibatch     10  | loss  4.92 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.55 | err rate 90.62%\n",
            "Minibatch     30  | loss  4.58 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 94.80%\n",
            "Minibatch     40  | loss  4.38 | err rate 100.00%\n",
            "Minibatch     50  | loss  3.88 | err rate 100.00%\n",
            "Minibatch     60  | loss  4.25 | err rate 100.00%\n",
            "Epoch 2/10, Validation Error Rate: 91.67%\n",
            "Minibatch     70  | loss  3.64 | err rate 84.38%\n",
            "Minibatch     80  | loss  3.64 | err rate 87.50%\n",
            "Minibatch     90  | loss  3.80 | err rate 90.62%\n",
            "Epoch 3/10, Validation Error Rate: 86.86%\n",
            "Minibatch    100  | loss  3.20 | err rate 75.00%\n",
            "Minibatch    110  | loss  2.93 | err rate 87.50%\n",
            "Minibatch    120  | loss  3.36 | err rate 78.12%\n",
            "Epoch 4/10, Validation Error Rate: 83.43%\n",
            "Minibatch    130  | loss  2.38 | err rate 53.12%\n",
            "Minibatch    140  | loss  2.54 | err rate 75.00%\n",
            "Minibatch    150  | loss  3.13 | err rate 75.00%\n",
            "Epoch 5/10, Validation Error Rate: 79.90%\n",
            "Minibatch    160  | loss  2.33 | err rate 65.62%\n",
            "Minibatch    170  | loss  2.18 | err rate 65.62%\n",
            "Minibatch    180  | loss  2.46 | err rate 65.62%\n",
            "Minibatch    190  | loss  2.58 | err rate 65.62%\n",
            "Epoch 6/10, Validation Error Rate: 78.33%\n",
            "Minibatch    200  | loss  2.06 | err rate 56.25%\n",
            "Minibatch    210  | loss  2.36 | err rate 59.38%\n",
            "Minibatch    220  | loss  2.32 | err rate 65.62%\n",
            "Epoch 7/10, Validation Error Rate: 77.06%\n",
            "Minibatch    230  | loss  1.92 | err rate 59.38%\n",
            "Minibatch    240  | loss  1.94 | err rate 53.12%\n",
            "Minibatch    250  | loss  1.98 | err rate 56.25%\n",
            "Epoch 8/10, Validation Error Rate: 76.76%\n",
            "Minibatch    260  | loss  1.01 | err rate 18.75%\n",
            "Minibatch    270  | loss  1.71 | err rate 50.00%\n",
            "Minibatch    280  | loss  1.89 | err rate 53.12%\n",
            "Epoch 9/10, Validation Error Rate: 76.86%\n",
            "Minibatch    290  | loss  0.76 | err rate 18.75%\n",
            "Minibatch    300  | loss  1.16 | err rate 40.62%\n",
            "Minibatch    310  | loss  1.16 | err rate 28.12%\n",
            "Epoch 10/10, Validation Error Rate: 77.75%\n",
            "Test Error Rate: 81.57%\n",
            "batch size:  64\n",
            "Minibatch      0  | loss  5.76 | err rate 98.44%\n",
            "Minibatch     10  | loss  4.86 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 95.78%\n",
            "Minibatch     20  | loss  4.40 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.10 | err rate 95.31%\n",
            "Epoch 2/10, Validation Error Rate: 92.84%\n",
            "Minibatch     40  | loss  3.70 | err rate 87.50%\n",
            "Epoch 3/10, Validation Error Rate: 89.80%\n",
            "Minibatch     50  | loss  3.07 | err rate 75.00%\n",
            "Minibatch     60  | loss  3.27 | err rate 92.19%\n",
            "Epoch 4/10, Validation Error Rate: 84.80%\n",
            "Minibatch     70  | loss  2.87 | err rate 70.31%\n",
            "Epoch 5/10, Validation Error Rate: 83.33%\n",
            "Minibatch     80  | loss  2.50 | err rate 64.06%\n",
            "Minibatch     90  | loss  2.58 | err rate 67.19%\n",
            "Epoch 6/10, Validation Error Rate: 80.29%\n",
            "Minibatch    100  | loss  1.93 | err rate 43.75%\n",
            "Minibatch    110  | loss  1.96 | err rate 45.31%\n",
            "Epoch 7/10, Validation Error Rate: 79.12%\n",
            "Minibatch    120  | loss  1.85 | err rate 50.00%\n",
            "Epoch 8/10, Validation Error Rate: 77.45%\n",
            "Minibatch    130  | loss  1.26 | err rate 31.25%\n",
            "Minibatch    140  | loss  1.30 | err rate 42.19%\n",
            "Epoch 9/10, Validation Error Rate: 78.24%\n",
            "Minibatch    150  | loss  1.67 | err rate 42.19%\n",
            "Epoch 10/10, Validation Error Rate: 75.59%\n",
            "Test Error Rate: 80.06%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>▁▃█</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█▁▂▃▃▄▅▆▆▇█▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁█▆</td></tr><tr><td>val/err</td><td>█▇▅▄▃▂▁▁▂▂▇▆▅▄▃▂▂▂▂▂▇▇▆▄▄▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>64</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.80062</td></tr><tr><td>val/err</td><td>75.58824</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">different-batch-sizes</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yrxtpdmt' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/yrxtpdmt</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_094244-yrxtpdmt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_sizes = [16, 32, 64]\n",
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"different-batch-sizes\",\n",
        "    config={\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 1e-3,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": \"16,32,64\",\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "for batch in batch_sizes:\n",
        "  train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "  val_loader   = DataLoader(val_ds,   batch_size=batch, shuffle=False, num_workers=2, pin_memory=True)\n",
        "  test_loader  = DataLoader(test_ds,  batch_size=batch, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "  flowers102_loaders = {\n",
        "      'train': train_loader,\n",
        "      'val': val_loader,\n",
        "      'test': test_loader\n",
        "  }\n",
        "\n",
        "  print(\"batch size: \", batch)\n",
        "  wandb.log({ \"batch_size\": batch})\n",
        "\n",
        "  model = SimpleConvAndMlp()\n",
        "  with torch.no_grad():\n",
        "      for name, p in model.named_parameters():\n",
        "          if \"weight\" in name and len(p.shape) >= 2:\n",
        "              torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "          elif \"bias\" in name:\n",
        "              p.zero_()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "  train_model(model, flowers102_loaders, optimizer, 10, 'cuda')\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"simpleconv-sgd\",\n",
        "    config={\n",
        "        \"optimizer\": \"sgd\",\n",
        "        \"lr\": 1e-3,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"epochs\": 10,\n",
        "    }\n",
        ")\n",
        "\n",
        "model = SimpleConvAndMlp()\n",
        "with torch.no_grad():\n",
        "    for name, p in model.named_parameters():\n",
        "        if \"weight\" in name and len(p.shape) >= 2:\n",
        "            torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "        elif \"bias\" in name:\n",
        "            p.zero_()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-4, momentum=0.9)\n",
        "train_model(model, flowers102_loaders, optimizer, 10, 'cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "CKf8MAdP40W8",
        "outputId": "1abc1b18-670f-4afa-be57-e132483a87ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_122129-ljyytxf4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ljyytxf4' target=\"_blank\">simpleconv-sgd</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ljyytxf4' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ljyytxf4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch      0  | loss  5.72 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.11 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.76 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.74 | err rate 96.88%\n",
            "Epoch 1/10, Validation Error Rate: 95.98%\n",
            "Minibatch     40  | loss  4.45 | err rate 96.88%\n",
            "Minibatch     50  | loss  4.32 | err rate 93.75%\n",
            "Minibatch     60  | loss  4.37 | err rate 93.75%\n",
            "Epoch 2/10, Validation Error Rate: 92.16%\n",
            "Minibatch     70  | loss  4.11 | err rate 90.62%\n",
            "Minibatch     80  | loss  4.08 | err rate 93.75%\n",
            "Minibatch     90  | loss  3.86 | err rate 78.12%\n",
            "Epoch 3/10, Validation Error Rate: 89.41%\n",
            "Minibatch    100  | loss  3.76 | err rate 84.38%\n",
            "Minibatch    110  | loss  3.51 | err rate 75.00%\n",
            "Minibatch    120  | loss  3.72 | err rate 90.62%\n",
            "Epoch 4/10, Validation Error Rate: 87.16%\n",
            "Minibatch    130  | loss  3.39 | err rate 78.12%\n",
            "Minibatch    140  | loss  3.24 | err rate 84.38%\n",
            "Minibatch    150  | loss  3.21 | err rate 65.62%\n",
            "Epoch 5/10, Validation Error Rate: 84.80%\n",
            "Minibatch    160  | loss  3.50 | err rate 78.12%\n",
            "Minibatch    170  | loss  3.01 | err rate 75.00%\n",
            "Minibatch    180  | loss  2.87 | err rate 75.00%\n",
            "Minibatch    190  | loss  3.19 | err rate 68.75%\n",
            "Epoch 6/10, Validation Error Rate: 82.65%\n",
            "Minibatch    200  | loss  2.83 | err rate 75.00%\n",
            "Minibatch    210  | loss  2.59 | err rate 75.00%\n",
            "Minibatch    220  | loss  2.96 | err rate 68.75%\n",
            "Epoch 7/10, Validation Error Rate: 81.76%\n",
            "Minibatch    230  | loss  2.83 | err rate 78.12%\n",
            "Minibatch    240  | loss  2.39 | err rate 59.38%\n",
            "Minibatch    250  | loss  2.57 | err rate 68.75%\n",
            "Epoch 8/10, Validation Error Rate: 78.63%\n",
            "Minibatch    260  | loss  2.10 | err rate 43.75%\n",
            "Minibatch    270  | loss  2.29 | err rate 62.50%\n",
            "Minibatch    280  | loss  1.88 | err rate 46.88%\n",
            "Epoch 9/10, Validation Error Rate: 78.04%\n",
            "Minibatch    290  | loss  2.07 | err rate 53.12%\n",
            "Minibatch    300  | loss  1.93 | err rate 59.38%\n",
            "Minibatch    310  | loss  2.01 | err rate 56.25%\n",
            "Epoch 10/10, Validation Error Rate: 74.31%\n",
            "Test Error Rate: 79.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrKzBEDW0R8s"
      },
      "source": [
        "## zad 6 - dropout and batchnorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUVtvXreH6KO"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_ds = torchvision.datasets.Flowers102(root='./data', split='train', download=False, transform=transform)\n",
        "val_ds   = torchvision.datasets.Flowers102(root='./data', split='val',   download=False, transform=transform)\n",
        "test_ds  = torchvision.datasets.Flowers102(root='./data', split='test',  download=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceNYISGOGXRw"
      },
      "source": [
        "## zad 6.001 - without batchnorm and without dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "YVX6ircmGfy-",
        "outputId": "6a8f17e9-b536-4ff3-ed66-ed49d02d986f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_095108-c2vs5h2n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/c2vs5h2n' target=\"_blank\">run-simple-no-dropout-batch</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/c2vs5h2n' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/c2vs5h2n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss  4.88 | err rate 100.00%\n",
            "Minibatch     10  | loss  4.61 | err rate 98.44%\n",
            "Epoch 1/10, Validation Error Rate: 96.08%\n",
            "Minibatch     20  | loss  4.33 | err rate 93.75%\n",
            "Minibatch     30  | loss  4.37 | err rate 98.44%\n",
            "Epoch 2/10, Validation Error Rate: 93.82%\n",
            "Minibatch     40  | loss  3.58 | err rate 84.38%\n",
            "Epoch 3/10, Validation Error Rate: 88.82%\n",
            "Minibatch     50  | loss  3.60 | err rate 81.25%\n",
            "Minibatch     60  | loss  3.55 | err rate 82.81%\n",
            "Epoch 4/10, Validation Error Rate: 84.80%\n",
            "Minibatch     70  | loss  3.03 | err rate 71.88%\n",
            "Epoch 5/10, Validation Error Rate: 81.57%\n",
            "Minibatch     80  | loss  2.54 | err rate 60.94%\n",
            "Minibatch     90  | loss  2.70 | err rate 64.06%\n",
            "Epoch 6/10, Validation Error Rate: 79.12%\n",
            "Minibatch    100  | loss  1.87 | err rate 42.19%\n",
            "Minibatch    110  | loss  2.07 | err rate 50.00%\n",
            "Epoch 7/10, Validation Error Rate: 77.45%\n",
            "Minibatch    120  | loss  1.74 | err rate 45.31%\n",
            "Epoch 8/10, Validation Error Rate: 75.00%\n",
            "Minibatch    130  | loss  1.34 | err rate 39.06%\n",
            "Minibatch    140  | loss  1.54 | err rate 39.06%\n",
            "Epoch 9/10, Validation Error Rate: 75.10%\n",
            "Minibatch    150  | loss  1.05 | err rate 25.00%\n",
            "Epoch 10/10, Validation Error Rate: 73.24%\n",
            "Test Error Rate: 77.00%\n"
          ]
        }
      ],
      "source": [
        "class SimpleConvAndMlpNoBatchNoDropout(torch.nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # same as padding='same'\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, Out, Targets):\n",
        "        return F.cross_entropy(Out, Targets)\n",
        "\n",
        "model = SimpleConvAndMlpNoBatchNoDropout()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for name, p in model.named_parameters():\n",
        "    if \"weight\" in name and len(p.shape) >= 2:\n",
        "        torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "    elif \"bias\" in name:\n",
        "        p.zero_()\n",
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"run-simple-no-dropout-batch\",\n",
        "    config={\n",
        "        \"epochs\": 10,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "train_model(model, flowers102_loaders, optimizer, 10, 'cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozFGMSEw0bBi"
      },
      "source": [
        "### zad 6.1 - only batchnorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "S7sZWWRL0Uzf",
        "outputId": "6a670af7-e515-4975-f7a6-03a211aae74b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▇▆▅▄▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.77004</td></tr><tr><td>val/err</td><td>73.23529</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simple-no-dropout-batch</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/c2vs5h2n' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/c2vs5h2n</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_095108-c2vs5h2n/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_095355-xlsvy1sq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xlsvy1sq' target=\"_blank\">run-simple-only-batch</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xlsvy1sq' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xlsvy1sq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss  5.55 | err rate 100.00%\n",
            "Minibatch     10  | loss  3.60 | err rate 82.81%\n",
            "Epoch 1/10, Validation Error Rate: 86.76%\n",
            "Minibatch     20  | loss  3.33 | err rate 79.69%\n",
            "Minibatch     30  | loss  3.01 | err rate 65.62%\n",
            "Epoch 2/10, Validation Error Rate: 80.88%\n",
            "Minibatch     40  | loss  2.16 | err rate 60.94%\n",
            "Epoch 3/10, Validation Error Rate: 79.12%\n",
            "Minibatch     50  | loss  1.86 | err rate 50.00%\n",
            "Minibatch     60  | loss  1.92 | err rate 45.31%\n",
            "Epoch 4/10, Validation Error Rate: 73.14%\n",
            "Minibatch     70  | loss  1.23 | err rate 26.56%\n",
            "Epoch 5/10, Validation Error Rate: 71.76%\n",
            "Minibatch     80  | loss  1.12 | err rate 31.25%\n",
            "Minibatch     90  | loss  1.07 | err rate 25.00%\n",
            "Epoch 6/10, Validation Error Rate: 71.37%\n",
            "Minibatch    100  | loss  0.85 | err rate 23.44%\n",
            "Minibatch    110  | loss  0.69 | err rate 17.19%\n",
            "Epoch 7/10, Validation Error Rate: 71.76%\n",
            "Minibatch    120  | loss  0.55 | err rate 20.31%\n",
            "Epoch 8/10, Validation Error Rate: 70.39%\n",
            "Minibatch    130  | loss  0.31 | err rate  7.81%\n",
            "Minibatch    140  | loss  0.61 | err rate 20.31%\n",
            "Epoch 9/10, Validation Error Rate: 70.69%\n",
            "Minibatch    150  | loss  0.23 | err rate  6.25%\n",
            "Epoch 10/10, Validation Error Rate: 68.92%\n",
            "Test Error Rate: 72.30%\n"
          ]
        }
      ],
      "source": [
        "class SimpleConvAndMlp(torch.nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # same as padding='same'\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, Out, Targets):\n",
        "        return F.cross_entropy(Out, Targets)\n",
        "\n",
        "\n",
        "model = SimpleConvAndMlp()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for name, p in model.named_parameters():\n",
        "    if \"weight\" in name and len(p.shape) >= 2:\n",
        "        torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "    elif \"bias\" in name:\n",
        "        p.zero_()\n",
        "\n",
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"run-simple-only-batch\",\n",
        "    config={\n",
        "        \"epochs\": 10,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "train_model(model, flowers102_loaders, optimizer, 10, 'cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmuYOt3wByFx"
      },
      "source": [
        "## zad 6.2 - different dropout rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qpGAUn5IIiW"
      },
      "outputs": [],
      "source": [
        "class SimpleConvAndMlp(torch.nn.Module):\n",
        "    def __init__(self, dropout, num_classes=102):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # same as padding='same'\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, Out, Targets):\n",
        "        return F.cross_entropy(Out, Targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a20ld0VsCH-h",
        "outputId": "4f7dae2e-8370-4c0e-dd72-b5ed3c712172"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▆▅▃▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.72304</td></tr><tr><td>val/err</td><td>68.92157</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simple-only-batch</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xlsvy1sq' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/xlsvy1sq</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_095355-xlsvy1sq/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_095832-qk8gkd53</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/qk8gkd53' target=\"_blank\">run-simple-only-dropout-0.1</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/qk8gkd53' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/qk8gkd53</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss  5.80 | err rate 100.00%\n",
            "Minibatch     10  | loss  4.64 | err rate 98.44%\n",
            "Epoch 1/10, Validation Error Rate: 98.04%\n",
            "Minibatch     20  | loss  4.59 | err rate 98.44%\n",
            "Minibatch     30  | loss  4.55 | err rate 96.88%\n",
            "Epoch 2/10, Validation Error Rate: 97.06%\n",
            "Minibatch     40  | loss  4.36 | err rate 96.88%\n",
            "Epoch 3/10, Validation Error Rate: 94.71%\n",
            "Minibatch     50  | loss  3.91 | err rate 93.75%\n",
            "Minibatch     60  | loss  3.80 | err rate 90.62%\n",
            "Epoch 4/10, Validation Error Rate: 89.31%\n",
            "Minibatch     70  | loss  3.74 | err rate 87.50%\n",
            "Epoch 5/10, Validation Error Rate: 83.24%\n",
            "Minibatch     80  | loss  3.01 | err rate 67.19%\n",
            "Minibatch     90  | loss  2.86 | err rate 65.62%\n",
            "Epoch 6/10, Validation Error Rate: 83.53%\n",
            "Minibatch    100  | loss  2.35 | err rate 59.38%\n",
            "Minibatch    110  | loss  2.47 | err rate 60.94%\n",
            "Epoch 7/10, Validation Error Rate: 79.71%\n",
            "Minibatch    120  | loss  2.31 | err rate 59.38%\n",
            "Epoch 8/10, Validation Error Rate: 77.84%\n",
            "Minibatch    130  | loss  1.96 | err rate 43.75%\n",
            "Minibatch    140  | loss  1.88 | err rate 50.00%\n",
            "Epoch 9/10, Validation Error Rate: 74.80%\n",
            "Minibatch    150  | loss  1.07 | err rate 26.56%\n",
            "Epoch 10/10, Validation Error Rate: 76.37%\n",
            "Test Error Rate: 77.80%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>██▇▅▄▄▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.77801</td></tr><tr><td>val/err</td><td>76.37255</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simple-only-dropout-0.1</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/qk8gkd53' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/qk8gkd53</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_095832-qk8gkd53/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_100102-z6dtllvf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/z6dtllvf' target=\"_blank\">run-simple-only-dropout-0.2</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/z6dtllvf' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/z6dtllvf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss  6.26 | err rate 100.00%\n",
            "Minibatch     10  | loss  4.62 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 96.37%\n",
            "Minibatch     20  | loss  4.45 | err rate 98.44%\n",
            "Minibatch     30  | loss  4.28 | err rate 93.75%\n",
            "Epoch 2/10, Validation Error Rate: 95.39%\n",
            "Minibatch     40  | loss  3.97 | err rate 89.06%\n",
            "Epoch 3/10, Validation Error Rate: 90.88%\n",
            "Minibatch     50  | loss  3.61 | err rate 85.94%\n",
            "Minibatch     60  | loss  3.61 | err rate 85.94%\n",
            "Epoch 4/10, Validation Error Rate: 86.37%\n",
            "Minibatch     70  | loss  3.35 | err rate 82.81%\n",
            "Epoch 5/10, Validation Error Rate: 84.71%\n",
            "Minibatch     80  | loss  2.87 | err rate 75.00%\n",
            "Minibatch     90  | loss  2.60 | err rate 67.19%\n",
            "Epoch 6/10, Validation Error Rate: 81.27%\n",
            "Minibatch    100  | loss  2.62 | err rate 64.06%\n",
            "Minibatch    110  | loss  2.30 | err rate 56.25%\n",
            "Epoch 7/10, Validation Error Rate: 76.67%\n",
            "Minibatch    120  | loss  2.14 | err rate 56.25%\n",
            "Epoch 8/10, Validation Error Rate: 77.45%\n",
            "Minibatch    130  | loss  1.72 | err rate 51.56%\n",
            "Minibatch    140  | loss  1.85 | err rate 46.88%\n",
            "Epoch 9/10, Validation Error Rate: 74.02%\n",
            "Minibatch    150  | loss  1.27 | err rate 31.25%\n",
            "Epoch 10/10, Validation Error Rate: 74.51%\n",
            "Test Error Rate: 77.28%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>██▆▅▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.77281</td></tr><tr><td>val/err</td><td>74.5098</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simple-only-dropout-0.2</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/z6dtllvf' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/z6dtllvf</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_100102-z6dtllvf/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_100332-6uzwlpy5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/6uzwlpy5' target=\"_blank\">run-simple-only-dropout-0.3</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/6uzwlpy5' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/6uzwlpy5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss  6.49 | err rate 100.00%\n",
            "Minibatch     10  | loss  4.63 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 98.14%\n",
            "Minibatch     20  | loss  4.52 | err rate 100.00%\n",
            "Minibatch     30  | loss  4.43 | err rate 96.88%\n",
            "Epoch 2/10, Validation Error Rate: 95.59%\n",
            "Minibatch     40  | loss  4.14 | err rate 100.00%\n",
            "Epoch 3/10, Validation Error Rate: 94.12%\n",
            "Minibatch     50  | loss  3.92 | err rate 93.75%\n",
            "Minibatch     60  | loss  3.93 | err rate 92.19%\n",
            "Epoch 4/10, Validation Error Rate: 89.90%\n",
            "Minibatch     70  | loss  3.66 | err rate 85.94%\n",
            "Epoch 5/10, Validation Error Rate: 85.98%\n",
            "Minibatch     80  | loss  3.32 | err rate 79.69%\n",
            "Minibatch     90  | loss  3.02 | err rate 76.56%\n",
            "Epoch 6/10, Validation Error Rate: 83.73%\n",
            "Minibatch    100  | loss  2.67 | err rate 67.19%\n",
            "Minibatch    110  | loss  2.65 | err rate 70.31%\n",
            "Epoch 7/10, Validation Error Rate: 81.08%\n",
            "Minibatch    120  | loss  2.71 | err rate 67.19%\n",
            "Epoch 8/10, Validation Error Rate: 78.53%\n",
            "Minibatch    130  | loss  2.24 | err rate 59.38%\n",
            "Minibatch    140  | loss  1.79 | err rate 48.44%\n",
            "Epoch 9/10, Validation Error Rate: 76.37%\n",
            "Minibatch    150  | loss  1.79 | err rate 48.44%\n",
            "Epoch 10/10, Validation Error Rate: 75.49%\n",
            "Test Error Rate: 76.42%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>█▇▇▅▄▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.76419</td></tr><tr><td>val/err</td><td>75.4902</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simple-only-dropout-0.3</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/6uzwlpy5' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/6uzwlpy5</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_100332-6uzwlpy5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_100600-a8aokgu8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/a8aokgu8' target=\"_blank\">run-simple-only-dropout-0.4</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/a8aokgu8' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/a8aokgu8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss 16.94 | err rate 100.00%\n",
            "Minibatch     10  | loss  4.70 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 97.94%\n",
            "Minibatch     20  | loss  4.62 | err rate 96.88%\n",
            "Minibatch     30  | loss  4.61 | err rate 98.44%\n",
            "Epoch 2/10, Validation Error Rate: 97.35%\n",
            "Minibatch     40  | loss  4.59 | err rate 98.44%\n",
            "Epoch 3/10, Validation Error Rate: 96.67%\n",
            "Minibatch     50  | loss  4.49 | err rate 96.88%\n",
            "Minibatch     60  | loss  4.36 | err rate 95.31%\n",
            "Epoch 4/10, Validation Error Rate: 95.88%\n",
            "Minibatch     70  | loss  4.03 | err rate 92.19%\n",
            "Epoch 5/10, Validation Error Rate: 92.06%\n",
            "Minibatch     80  | loss  4.05 | err rate 93.75%\n",
            "Minibatch     90  | loss  3.58 | err rate 90.62%\n",
            "Epoch 6/10, Validation Error Rate: 86.67%\n",
            "Minibatch    100  | loss  3.52 | err rate 89.06%\n",
            "Minibatch    110  | loss  3.49 | err rate 87.50%\n",
            "Epoch 7/10, Validation Error Rate: 87.75%\n",
            "Minibatch    120  | loss  3.42 | err rate 82.81%\n",
            "Epoch 8/10, Validation Error Rate: 83.63%\n",
            "Minibatch    130  | loss  3.12 | err rate 78.12%\n",
            "Minibatch    140  | loss  2.67 | err rate 71.88%\n",
            "Epoch 9/10, Validation Error Rate: 82.94%\n",
            "Minibatch    150  | loss  2.98 | err rate 75.00%\n",
            "Epoch 10/10, Validation Error Rate: 79.41%\n",
            "Test Error Rate: 82.99%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>███▇▆▄▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.82989</td></tr><tr><td>val/err</td><td>79.41176</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simple-only-dropout-0.4</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/a8aokgu8' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/a8aokgu8</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_100600-a8aokgu8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_100828-ylukb2au</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ylukb2au' target=\"_blank\">run-simple-only-dropout-0.5</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ylukb2au' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ylukb2au</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minibatch      0  | loss 15.88 | err rate 98.44%\n",
            "Minibatch     10  | loss  4.67 | err rate 98.44%\n",
            "Epoch 1/10, Validation Error Rate: 97.75%\n",
            "Minibatch     20  | loss  4.61 | err rate 98.44%\n",
            "Minibatch     30  | loss  4.61 | err rate 98.44%\n",
            "Epoch 2/10, Validation Error Rate: 98.24%\n",
            "Minibatch     40  | loss  4.56 | err rate 96.88%\n",
            "Epoch 3/10, Validation Error Rate: 98.14%\n",
            "Minibatch     50  | loss  4.46 | err rate 96.88%\n",
            "Minibatch     60  | loss  4.27 | err rate 100.00%\n",
            "Epoch 4/10, Validation Error Rate: 95.59%\n",
            "Minibatch     70  | loss  4.05 | err rate 95.31%\n",
            "Epoch 5/10, Validation Error Rate: 93.24%\n",
            "Minibatch     80  | loss  3.56 | err rate 79.69%\n",
            "Minibatch     90  | loss  3.78 | err rate 95.31%\n",
            "Epoch 6/10, Validation Error Rate: 88.53%\n",
            "Minibatch    100  | loss  3.25 | err rate 65.62%\n",
            "Minibatch    110  | loss  3.57 | err rate 87.50%\n",
            "Epoch 7/10, Validation Error Rate: 85.78%\n",
            "Minibatch    120  | loss  3.07 | err rate 75.00%\n",
            "Epoch 8/10, Validation Error Rate: 83.82%\n",
            "Minibatch    130  | loss  2.78 | err rate 70.31%\n",
            "Minibatch    140  | loss  2.63 | err rate 71.88%\n",
            "Epoch 9/10, Validation Error Rate: 81.96%\n",
            "Minibatch    150  | loss  3.01 | err rate 76.56%\n",
            "Epoch 10/10, Validation Error Rate: 80.88%\n",
            "Test Error Rate: 84.24%\n"
          ]
        }
      ],
      "source": [
        "dropouts = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "for dropout in dropouts:\n",
        "  model = SimpleConvAndMlp(dropout=dropout)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for name, p in model.named_parameters():\n",
        "      if \"weight\" in name and len(p.shape) >= 2:\n",
        "          torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "      elif \"bias\" in name:\n",
        "          p.zero_()\n",
        "\n",
        "  wandb.init(\n",
        "      project=PROJECT_NAME,\n",
        "      name=f\"run-simple-only-dropout-{dropout}\",\n",
        "      config={\n",
        "          \"epochs\": 10,\n",
        "          \"optimizer\": \"Adam\",\n",
        "          \"lr\": 0.001,\n",
        "          \"weight_decay\": 1e-4,\n",
        "          \"initializer\": \"kaiming_normal\",\n",
        "          \"batch_size\": 32,\n",
        "      }\n",
        "  )\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "  train_model(model, flowers102_loaders, optimizer, 10, 'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "uiogEEUVed2M",
        "outputId": "54b7eb8f-d895-4cca-9965-c3d25c0bf28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>███▇▆▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.84241</td></tr><tr><td>val/err</td><td>80.88235</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simple-only-dropout-0.5</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ylukb2au' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/ylukb2au</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_100828-ylukb2au/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqbfDWZZI9pF"
      },
      "source": [
        "## zad 7 - transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1JW2WArJBPz"
      },
      "outputs": [],
      "source": [
        "mean= [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "test_dataset = torchvision.datasets.Flowers102(root='./data', split=\"test\", download=False, transform=val_test_transforms)\n",
        "val_dataset = torchvision.datasets.Flowers102(root='./data', split=\"val\", download=False, transform=val_test_transforms)\n",
        "train_dataset = torchvision.datasets.Flowers102(root='./data', split=\"train\", download=False, transform=train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "flowers102_loaders = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader,\n",
        "    'test': test_loader\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7UlVrRIJidu"
      },
      "outputs": [],
      "source": [
        "class SimpleConvAndMlp(torch.nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # same as padding='same'\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # add dropout to reduce overfitting\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, Out, Targets):\n",
        "        return F.cross_entropy(Out, Targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UdFun2aJPZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92ae644b-9d4a-4203-fb68-33d802218423"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_111312-1b34zdeu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/1b34zdeu' target=\"_blank\">run-simplecnn-transformations</a></strong> to <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/1b34zdeu' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/1b34zdeu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch      0  | loss  5.12 | err rate 100.00%\n",
            "Minibatch     10  | loss  5.05 | err rate 100.00%\n",
            "Minibatch     20  | loss  4.54 | err rate 100.00%\n",
            "Minibatch     30  | loss  4.64 | err rate 100.00%\n",
            "Epoch 1/10, Validation Error Rate: 96.37%\n",
            "Minibatch     40  | loss  4.47 | err rate 100.00%\n",
            "Minibatch     50  | loss  4.47 | err rate 96.88%\n",
            "Minibatch     60  | loss  4.47 | err rate 100.00%\n",
            "Epoch 2/10, Validation Error Rate: 95.39%\n",
            "Minibatch     70  | loss  4.41 | err rate 93.75%\n",
            "Minibatch     80  | loss  4.10 | err rate 100.00%\n",
            "Minibatch     90  | loss  3.97 | err rate 100.00%\n",
            "Epoch 3/10, Validation Error Rate: 92.16%\n",
            "Minibatch    100  | loss  3.57 | err rate 84.38%\n",
            "Minibatch    110  | loss  3.81 | err rate 93.75%\n",
            "Minibatch    120  | loss  3.97 | err rate 96.88%\n",
            "Epoch 4/10, Validation Error Rate: 89.61%\n",
            "Minibatch    130  | loss  3.48 | err rate 87.50%\n",
            "Minibatch    140  | loss  3.96 | err rate 93.75%\n",
            "Minibatch    150  | loss  3.78 | err rate 87.50%\n",
            "Epoch 5/10, Validation Error Rate: 86.47%\n",
            "Minibatch    160  | loss  3.58 | err rate 90.62%\n",
            "Minibatch    170  | loss  3.68 | err rate 75.00%\n",
            "Minibatch    180  | loss  3.36 | err rate 87.50%\n",
            "Minibatch    190  | loss  3.72 | err rate 90.62%\n",
            "Epoch 6/10, Validation Error Rate: 82.35%\n",
            "Minibatch    200  | loss  3.34 | err rate 93.75%\n",
            "Minibatch    210  | loss  3.32 | err rate 90.62%\n",
            "Minibatch    220  | loss  3.28 | err rate 75.00%\n",
            "Epoch 7/10, Validation Error Rate: 80.00%\n",
            "Minibatch    230  | loss  3.25 | err rate 81.25%\n",
            "Minibatch    240  | loss  3.32 | err rate 84.38%\n",
            "Minibatch    250  | loss  3.48 | err rate 81.25%\n",
            "Epoch 8/10, Validation Error Rate: 77.25%\n",
            "Minibatch    260  | loss  2.64 | err rate 62.50%\n",
            "Minibatch    270  | loss  3.00 | err rate 75.00%\n",
            "Minibatch    280  | loss  3.47 | err rate 90.62%\n",
            "Epoch 9/10, Validation Error Rate: 74.80%\n",
            "Minibatch    290  | loss  2.81 | err rate 75.00%\n",
            "Minibatch    300  | loss  3.06 | err rate 84.38%\n",
            "Minibatch    310  | loss  3.14 | err rate 75.00%\n",
            "Epoch 10/10, Validation Error Rate: 76.37%\n",
            "Test Error Rate: 80.40%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test/err</td><td>▁</td></tr><tr><td>val/err</td><td>██▇▆▅▃▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test/err</td><td>0.80403</td></tr><tr><td>val/err</td><td>76.37255</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-simplecnn-transformations</strong> at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/1b34zdeu' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3/runs/1b34zdeu</a><br> View project at: <a href='https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3' target=\"_blank\">https://wandb.ai/dawidpawliczek4-university-of-wroc-aw/assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250425_111312-1b34zdeu/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project=PROJECT_NAME,\n",
        "    name=\"run-simplecnn-transformations\",\n",
        "    config={\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"initializer\": \"kaiming_normal\",\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "model = SimpleConvAndMlp()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for name, p in model.named_parameters():\n",
        "        if \"weight\" in name and len(p.shape) >= 2:\n",
        "            torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "        elif \"bias\" in name:\n",
        "            p.zero_()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "train_model(model, flowers102_loaders, optimizer, 10, 'cuda')\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}